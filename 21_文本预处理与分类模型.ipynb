{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 自然语言处理（NLP）简介\n",
    "- 预处理文本输入，将其转换为数值输入\n",
    "- 构建简单的文本分类模型，为更复杂的Transformer模型做好准备"
   ],
   "id": "caeaf79ccdb7017e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备文本数据",
   "id": "84b5f7ce3071826f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "文本数据的障碍：输入并非数值型数据，需要将文字转换为数字张量，文本的数值可以通过多种方式构建：\n",
    "\n",
    "1. 将输入内容分割成一系列字符，并为每个字符分配一个唯一的索引\n",
    "2. 构建基于单词的表示：首先将句子按空格和标点符号拆分，然后将每个单词映射到唯一的数字表示\n",
    "\n",
    "两种都有用，所有文本预处理都会包含一个分割步骤，即将文本分割成称为\"词元\"的小单元。"
   ],
   "id": "864b99141e5ff94f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 字母和词的分词",
   "id": "8012ed0f759dfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:04:26.340695Z",
     "start_time": "2025-11-11T13:04:26.317385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import regex as re\n",
    "\n",
    "def split_chars(text):\n",
    "    return re.findall(r\".\", text)"
   ],
   "id": "c3c5b37cb47949e8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:04:28.318479Z",
     "start_time": "2025-11-11T13:04:28.294480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chars = split_chars(\"The quick brown fox jumps over the lazy dog\")\n",
    "chars[:12]"
   ],
   "id": "128abdc946dae25c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'h', 'e', ' ', 'q', 'u', 'i', 'c', 'k', ' ', 'b', 'r']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:04:30.468770Z",
     "start_time": "2025-11-11T13:04:30.453761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [\\w]+\" 正则表达式会匹配连续的非空白字符，并且 \"[.,!?;]\"能够匹配括号内的标点符号。可以将两者结合起来，得到一个能够将每个单词和标点符号拆分成一个标记的正则表达式：\n",
    "\n",
    "def split_words(text):\n",
    "    return re.findall(r\"[\\w]+|[.,!?;]\", text)"
   ],
   "id": "7c0bd6b9836069aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:04:32.097961Z",
     "start_time": "2025-11-11T13:04:32.078959Z"
    }
   },
   "cell_type": "code",
   "source": "split_words(\"The quick brown fox jumped over the dog.\")",
   "id": "df29b9b94068ff1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'dog', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "分词（splitting）将从一个完整的字符串转换为一个**词元序列（token sequence）**，但仍然需要把这些字符串词元转换成**数值输入（numeric inputs）**。\n",
    "目前最常见的方法是为每个词元分配一个**唯一的整数索引（integer index）**，这种过程通常称为**输入索引化（indexing our input）**。\n",
    "\n",
    "这种表示方法具有灵活且可逆的特性，能广泛应用于各种建模方式。\n",
    "之后，可以再决定如何将这些**词元索引（token indices）** 映射到模型可接收的 **潜在空间（latent space）** 中。\n",
    "\n",
    "对于字符级token，可以使用ASCII查询来建立索引——例如，ord('A')→65、ord('z')→122。但这种方法在涉及非英文时扩展性较差——Unicode标准包含超过一百万个字符！更稳健的技术是基于训练数据中的特定token构建索引映射，这种在自然语言处理中称为\"词汇表\"的技术，其优势在于能同等适用于单词级和字符级token的处理。"
   ],
   "id": "8350daaad62aea94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:09:58.357335Z",
     "start_time": "2025-11-11T13:09:58.345366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocabulary = {\n",
    "    \"[UNK]\": 0,\n",
    "    \"the\": 1,\n",
    "    \"quick\": 2,\n",
    "    \"brown\": 3,\n",
    "    \"fox\": 4,\n",
    "    \"jumped\": 5,\n",
    "    \"over\": 6,\n",
    "    \"dog\": 7,\n",
    "    \".\": 8,\n",
    "}\n",
    "words = split_words(\"The quick brown fox jumped over the lazy dog.\")\n",
    "indices = [vocabulary.get(word, 0) for word in words]\n",
    "\n",
    "indices"
   ],
   "id": "2e3a4628e88827b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 4, 5, 6, 1, 0, 7, 8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "UNK： 代表一个词汇表未知的token，处理所有输入，即使这个token只出现了测试集\n",
    "\n",
    "很多句子非常相似（几乎一样），只有字母大小写，有没有引号，缩写区别或者简体繁体的区别，但是模型并不知道他们没有什么区别，所以需要对文本做标准化避免几乎相同的句子编码差异。不要让模型去处理相同句子的不同表示\n",
    "\n",
    "标准化操作：转小写，去标点符号，繁体转简体\n",
    "\n",
    "文本预处理的三个阶段：\n",
    "1. **Standardization（标准化）** —— 对输入文本进行基本的文本到文本的规范化转换。\n",
    "2. **Splitting（分词）** —— 将文本切分为由词元（token）组成的序列。\n",
    "3. **Indexing（索引化）** —— 使用词汇表（vocabulary）将词元映射为索引。\n",
    "\n",
    "\n",
    "文本 -> 标准化文本 -> 词元 -> 词元索引\n",
    "\n",
    "人们通常把整个过程称为 tokenization（词元化），而把“将文本映射为词元索引序列的对象”称为 tokenizer（分词器）。\n",
    "\n",
    "![文本预处理](./images/text_preprocess.png)"
   ],
   "id": "5808a7ac3fb3ea54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:20:21.893118Z",
     "start_time": "2025-11-11T13:20:21.879595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# character-level 分词器\n",
    "class CharTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.unk_id = vocabulary[\"[UNK]\"]\n",
    "\n",
    "    def standardize(self, inputs):\n",
    "        return inputs.lower()\n",
    "\n",
    "    def split(self, inputs):\n",
    "        return re.findall(r\".\", inputs)\n",
    "\n",
    "    def index(self, tokens):\n",
    "        return [self.vocabulary.get(t, self.unk_id) for t in tokens]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        inputs = self.standardize(inputs)\n",
    "        tokens = self.split(inputs)\n",
    "        indices = self.index(tokens)\n",
    "        return indices\n"
   ],
   "id": "ef54455e21263960",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在使用这一方法之前，还需要编写一个函数，用于根据输入文本**构建词元（token）词表**。\n",
    "\n",
    "与其简单地把所有字符都映射到唯一的索引上，更希望能**限制词表的大小**，只保留输入数据中**最常见的词元**。\n",
    "\n",
    "当进入模型构建阶段时，**限制词表大小**将成为**控制模型参数数量**的重要手段。\n"
   ],
   "id": "b3f641bfa8515896"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:26:59.407140Z",
     "start_time": "2025-11-11T13:26:59.393628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "\n",
    "def compute_char_vocabulary(inputs, max_size):\n",
    "    char_counts = collections.Counter()\n",
    "    for x in inputs:\n",
    "        x = x.lower()\n",
    "        tokens = re.findall(r\".\", x)\n",
    "        char_counts.update(tokens)\n",
    "\n",
    "    vocabulary = [\"[UNK]\"]\n",
    "    most_common = char_counts.most_common(max_size - len(vocabulary))\n",
    "    for token, count in most_common:\n",
    "        vocabulary.append(token)\n",
    "    return dict((token, i) for i, token in enumerate(vocabulary))"
   ],
   "id": "e3db1e79eebd3cf2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:31:24.039151Z",
     "start_time": "2025-11-11T13:31:24.026183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 建立一个 word-level 分词器（tokenizer) , 只需要改分割的规则\n",
    "class WordTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.unk_id = vocabulary[\"[UNK]\"]\n",
    "\n",
    "    def standardize(self, inputs):\n",
    "        return inputs.lower()\n",
    "\n",
    "    def split(self, inputs):\n",
    "        return re.findall(r\"[\\w]+|[.,!?;]\", inputs)\n",
    "\n",
    "    def index(self, tokens):\n",
    "        return [self.vocabulary.get(t, self.unk_id) for t in tokens]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        inputs = self.standardize(inputs)\n",
    "        tokens = self.split(inputs)\n",
    "        indices = self.index(tokens)\n",
    "        return indices\n"
   ],
   "id": "bce4fe08230d8dcc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:34:12.356146Z",
     "start_time": "2025-11-11T13:34:12.342795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 换一个新的分割规则，变成计算word-level的词汇表\n",
    "def compute_word_vocabulary(inputs, max_size):\n",
    "    word_counts = collections.Counter()\n",
    "    for x in inputs:\n",
    "        x = x.lower()\n",
    "        tokens = re.findall(r\"[\\w]+|[.,!?;]\", x)\n",
    "        word_counts.update(tokens)\n",
    "\n",
    "    vocabulary = [\"[UNK]\"]\n",
    "    most_common = word_counts.most_common(max_size - len(vocabulary))\n",
    "    for token, count in most_common:\n",
    "        vocabulary.append(token)\n",
    "    return dict((token, i) for i, token in enumerate(vocabulary))\n"
   ],
   "id": "c097bd7dd77a5072",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![keras和它的后端](./images/RNN/keras.png)",
   "id": "a2eed052b1796fe3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:57:09.710485Z",
     "start_time": "2025-11-11T13:57:09.557398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "id": "405e47326e952bd8",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:57:10.564692Z",
     "start_time": "2025-11-11T13:57:10.334825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\"),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(units=10)\n",
    "])"
   ],
   "id": "b25fab517649791a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:57:23.703038Z",
     "start_time": "2025-11-11T13:57:23.673475Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "33bf31c9df8bd96e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m26\u001B[0m, \u001B[38;5;34m26\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │           \u001B[38;5;34m640\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m13\u001B[0m, \u001B[38;5;34m13\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m11\u001B[0m, \u001B[38;5;34m11\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │        \u001B[38;5;34m73,856\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │       \u001B[38;5;34m295,168\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m2,570\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m372,234\u001B[0m (1.42 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">372,234</span> (1.42 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m372,234\u001B[0m (1.42 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">372,234</span> (1.42 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:57:51.779100Z",
     "start_time": "2025-11-11T13:57:51.594674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ],
   "id": "22ef0e598b8226d6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:58:44.337875Z",
     "start_time": "2025-11-11T13:58:02.096737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ],
   "id": "b6c602102ba71369",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 9ms/step - accuracy: 0.9236 - loss: 0.2498\n",
      "Epoch 2/5\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 9ms/step - accuracy: 0.9779 - loss: 0.0705\n",
      "Epoch 3/5\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 9ms/step - accuracy: 0.9845 - loss: 0.0494\n",
      "Epoch 4/5\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 9ms/step - accuracy: 0.9880 - loss: 0.0375\n",
      "Epoch 5/5\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 9ms/step - accuracy: 0.9913 - loss: 0.0286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f3b79230d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:58:54.753575Z",
     "start_time": "2025-11-11T13:58:52.976048Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(test_images, test_labels)",
   "id": "874ca970a4a198bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - accuracy: 0.9918 - loss: 0.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.027248626574873924, 0.9918000102043152]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:55:53.843851Z",
     "start_time": "2025-11-11T13:55:43.015159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义分词器 用于现实中的文本输入\n",
    "\n",
    "\n",
    "filename = keras.utils.get_file(\n",
    "    origin=\"https://www.gutenberg.org/files/2701/old/moby10b.txt\",\n",
    ")\n",
    "moby_dick = list(open(filename, \"r\"))\n",
    "\n",
    "vocabulary = compute_char_vocabulary(moby_dick, max_size=100)\n",
    "char_tokenizer = CharTokenizer(vocabulary)\n"
   ],
   "id": "e68e0509314f4ac4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/2701/old/moby10b.txt\n",
      "\u001B[1m1256167/1256167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1us/step\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:39:01.636946Z",
     "start_time": "2025-11-11T13:38:58.520200Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Vocabulary length: \", )",
   "id": "4aeac026f433cf76",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:59:45.655057Z",
     "start_time": "2025-11-11T13:59:45.642789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Vocabulary length:\", len(vocabulary))\n",
    "print(\"Vocabulary start:\", list(vocabulary.keys())[:10])\n",
    "print(\"Vocabulary end:\", list(vocabulary.keys())[-10:])\n",
    "print(\"Line length:\", len(char_tokenizer( \"Call me Ishmael. Some years ago--never mind how long precisely.\")))"
   ],
   "id": "100c59a0910390b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 64\n",
      "Vocabulary start: ['[UNK]', ' ', 'e', 't', 'a', 'o', 'n', 'i', 's', 'h']\n",
      "Vocabulary end: ['@', '$', '%', '#', '=', '~', '&', '+', '<', '>']\n",
      "Line length: 63\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:01:24.549668Z",
     "start_time": "2025-11-11T14:01:24.284741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocabulary = compute_word_vocabulary(moby_dick, max_size=2_000)\n",
    "word_tokenizer = WordTokenizer(vocabulary)"
   ],
   "id": "4f8daaee4660509",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:02:08.309823Z",
     "start_time": "2025-11-11T14:02:08.295797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Vocabulary length:\", len(vocabulary))\n",
    "print(\"Vocabulary start:\", list(vocabulary.keys())[:5])\n",
    "print(\"Vocabulary end:\", list(vocabulary.keys())[-5:])\n",
    "print(\"Line length:\", len(word_tokenizer(\"Call me Ishmael. Some years ago--never mind how long precisely.\")))"
   ],
   "id": "fffb5c7b1188e281",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 2000\n",
      "Vocabulary start: ['[UNK]', ',', 'the', '.', 'of']\n",
      "Vocabulary end: ['tambourine', 'subtle', 'perseus', 'elevated', 'repose']\n",
      "Line length: 13\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "已经可以看到两种分词（tokenization）方法的优缺点。\n",
    "字符级分词器（character-level tokenizer） 只需要 64 个词汇项就能覆盖整本书，但会把每个输入编码成非常长的序列。\n",
    "词级分词器（word-level tokenizer） 很快就能填满一个包含 2000 个词的词表（如果想覆盖整本书中出现的所有词汇，你需要一个包含 17,000 个词的词典！），但词级分词器输出的序列会短得多。\n",
    "\n",
    "随着机器学习实践者使用越来越多的数据和参数来扩大模型规模，词级分词和字符级分词各自的缺陷也逐渐显现。\n",
    "词级分词带来的“压缩”效果实际上非常重要——它能让模型一次读取更长的文本序列。\n",
    "但是，如果你尝试为一个大型数据集（如今的数据集可能包含数万亿个单词）构建词级词表，那么这个词表将会大到难以处理，可能包含上亿个词条。\n",
    "而如果你为了限制词表大小而强行压缩它，那么会导致大量文本被编码成 \"[UNK]\"（未知词符），从而丢失宝贵的信息。\n",
    "\n",
    "这些问题促使一种新的分词方式流行起来——子词分词（subword tokenization），\n",
    "它试图在词级和字符级分词之间找到一个平衡点。"
   ],
   "id": "4629ef9296c4511f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 子词分词",
   "id": "1999a37e1e7a44d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "子词分词（Subword tokenization） 的目标是结合 字符级编码 和 词级编码 的优点。\n",
    "希望既能拥有 词级分词器（WordTokenizer） 那种输出简洁的特性，\n",
    "又能具备 字符级分词器（CharTokenizer） 那种用极小词表就能编码各种输入的能力。\n",
    "\n",
    "可以把寻找理想分词器的过程，看作是在寻找一种理想的数据压缩方式。\n",
    "减少词元（token）的数量，相当于压缩输入序列的总体长度；\n",
    "而使用更小的词表，则能减少表示每个词元所需的存储字节数。\n",
    "如果能同时做到这两点，就可以把短且信息密度高的序列输入到深度学习模型中。\n",
    "\n",
    "压缩与分词之间的这种类比并非一开始就显而易见，但事实证明它非常有用。\n",
    "在过去十年的自然语言处理研究中，最实用、最有效的技巧之一\n",
    "是重新利用 1990 年代的一种无损压缩算法——字节对编码（Byte-Pair Encoding, BPE） 来做分词。\n",
    "这一算法至今仍被 ChatGPT 以及许多其他模型所采用。\n",
    "\n",
    "字节对编码（BPE）的核心思想是：\n",
    "从最基础的字符级词表开始，\n",
    "逐步地将出现频率最高的字符对（pair）合并，形成越来越长的子词序列。（找出在语料中相邻出现最频繁的符号对（pair），逐步合并成更大的子词。）\n",
    "\n",
    "将实现一个使用 BPE 算法 的分词器。"
   ],
   "id": "deb60884188e37a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:11:02.503575Z",
     "start_time": "2025-11-11T14:11:02.489555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = [\n",
    "    \"the quick brown fox\",\n",
    "    \"the slow brown fox\",\n",
    "    \"the quick brown foxhound\",\n",
    "]  # 假设这是一个数据集"
   ],
   "id": "e7109812de579ef7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "与 WordTokenizer（词级分词器） 类似，首先要统计文本中所有单词的出现次数。\n",
    "在创建单词计数字典的过程中，会把所有文本拆分成单个字符，\n",
    "然后用空格将这些字符连接起来。\n",
    "\n",
    "这样处理的目的是：\n",
    "在接下来的步骤中，就能更方便地统计并合并字符对（character pairs）。"
   ],
   "id": "78eed18eceb38f00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:19:05.483717Z",
     "start_time": "2025-11-11T14:19:05.469690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_and_split_words(data):\n",
    "    counts = collections.Counter()\n",
    "    for line in data:\n",
    "        line = line.lower()\n",
    "        for word in re.findall(r\"[\\w]+|[.,!?;]\", line):\n",
    "            chars = re.findall(r\".\", word)\n",
    "            split_word = \" \".join(chars)\n",
    "            counts[split_word] += 1\n",
    "    return dict(counts)\n",
    "\n",
    "counts = count_and_split_words(data)"
   ],
   "id": "39ca663d0e53f93f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:19:16.782824Z",
     "start_time": "2025-11-11T14:19:16.769807Z"
    }
   },
   "cell_type": "code",
   "source": "counts",
   "id": "a885de51200383a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t h e': 3,\n",
       " 'q u i c k': 2,\n",
       " 'b r o w n': 3,\n",
       " 'f o x': 2,\n",
       " 's l o w': 1,\n",
       " 'f o x h o u n d': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "为了在拆分后的词频统计上应用 字节对编码（Byte-Pair Encoding, BPE），\n",
    "需要找到一对字符并将它们合并成一个新的符号。\n",
    "\n",
    "具体来说，会在所有单词中遍历所有可能的字符对（character pairs），\n",
    "然后只合并其中出现频率最高的一对。\n",
    "\n",
    "在前面的例子中，最常见的字符对是 (\"o\", \"w\")，\n",
    "它出现在单词 “brown”（在数据中出现了三次）和 “slow”（出现一次）中。\n",
    "因此将这对字符合并为一个新的符号 “ow”，\n",
    "并把所有出现的 “o w” 替换成 “ow”。\n",
    "\n",
    "接着继续重复这个过程：\n",
    "统计新的字符对频率、找到最常见的一对并进行合并。\n",
    "不同的是，现在 “ow” 被视为一个整体符号，\n",
    "它可能会再与 “l” 合并形成 “low”。\n",
    "\n",
    "通过这种不断合并出现频率最高的符号对的方式，\n",
    "逐步构建出一个越来越大的子词词表（subword vocabulary）。"
   ],
   "id": "3d8c3b89efd941fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:32:58.878792Z",
     "start_time": "2025-11-11T14:32:58.865761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_pairs(counts):\n",
    "    pairs = collections.Counter()\n",
    "    for word, freq in counts.items():\n",
    "        symbols = word.split()\n",
    "        for pair in zip(symbols[:-1], symbols[1:]):\n",
    "            pairs[pair] += freq\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def merge_pair(counts, first, second):\n",
    "    #  在“空格分隔的词元序列”中，前后都不是字母/数字的地方，找出 完整独立的“{first} {second}” 组合。\n",
    "    split = re.compile(f\"(?<!\\S){first} {second}(?!\\S)\")\n",
    "\n",
    "    # 把所有的组合 换成 合并的\n",
    "    merged = f\"{first}{second}\"\n",
    "    return {split.sub(merged, word): count for word, count in counts.items()}\n",
    "\n",
    "for i in range(10):\n",
    "    pairs = count_pairs(counts)\n",
    "    first, second = max(pairs, key=pairs.get)\n",
    "    counts = merge_pair(counts, first, second)\n",
    "    print(list(counts.keys()))"
   ],
   "id": "646845ff9c0ce674",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t h e', 'q u i c k', 'b r ow n', 'f o x', 's l ow', 'f o x h o u n d']\n",
      "['th e', 'q u i c k', 'b r ow n', 'f o x', 's l ow', 'f o x h o u n d']\n",
      "['the', 'q u i c k', 'b r ow n', 'f o x', 's l ow', 'f o x h o u n d']\n",
      "['the', 'q u i c k', 'br ow n', 'f o x', 's l ow', 'f o x h o u n d']\n",
      "['the', 'q u i c k', 'brow n', 'f o x', 's l ow', 'f o x h o u n d']\n",
      "['the', 'q u i c k', 'brown', 'f o x', 's l ow', 'f o x h o u n d']\n",
      "['the', 'q u i c k', 'brown', 'fo x', 's l ow', 'fo x h o u n d']\n",
      "['the', 'q u i c k', 'brown', 'fox', 's l ow', 'fox h o u n d']\n",
      "['the', 'qu i c k', 'brown', 'fox', 's l ow', 'fox h o u n d']\n",
      "['the', 'qui c k', 'brown', 'fox', 's l ow', 'fox h o u n d']\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以看到，高频词通常会被完全合并成一个整体，而低频词则只会被部分合并。\n",
    "\n",
    "接下来，可以把这一过程扩展为一个完整的函数，用于构建 字节对编码（Byte-Pair Encoding, BPE）词表。\n",
    "\n",
    "首先以输入文本中出现的所有字符作为初始词表，\n",
    "然后不断地将出现频率最高的符号对（pair）合并，\n",
    "逐步向词表中加入越来越长的子词（subword），\n",
    "直到词表的大小达到设定的目标。\n",
    "\n",
    "同时，还需要维护一个单独的合并规则字典（merge rules），\n",
    "记录每次合并的符号对及其合并顺序（rank order）。\n",
    "\n",
    "在下一步中，将利用这些合并规则来对新的输入文本进行分词。"
   ],
   "id": "12a62216b2272928"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:46:03.903916Z",
     "start_time": "2025-11-11T14:46:03.891397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_sub_word_vocabulary(dataset, vocab_size):\n",
    "    counts = count_and_split_words(dataset)\n",
    "\n",
    "    char_counts = collections.Counter()\n",
    "    for word in counts:\n",
    "        for char in word.split():\n",
    "            char_counts[char] += counts[word]\n",
    "\n",
    "    most_common = char_counts.most_common()\n",
    "    vocab = [\"[UNK]\"] + [char for char, freq in most_common]\n",
    "    merges = []\n",
    "\n",
    "    while len(vocab) < vocab_size:\n",
    "        pairs = count_pairs(counts)\n",
    "        if not pairs:\n",
    "            break\n",
    "        first, second = max(pairs, key=pairs.get)\n",
    "        counts = merge_pair(counts, first, second)\n",
    "        vocab.append(f\"{first}{second}\")\n",
    "        merges.append(f\"{first} {second}\")\n",
    "\n",
    "    vocab = dict((token, index) for index, token in enumerate(vocab))\n",
    "    merges = dict((token, rank) for rank, token in enumerate(merges))\n",
    "\n",
    "    return vocab, merges"
   ],
   "id": "1c68ad96ac6b6d13",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "让来构建一个 SubWordTokenizer（子词分词器），它能够根据学到的 **合并规则（merge rules)** 来对新的输入文本进行分词。\n",
    "\n",
    "其中，standardize() 和 index() 两个步骤可以与 WordTokenizer（词级分词器） 保持一致，所有的变化都将发生在 split() 方法 中。\n",
    "\n",
    "在分词步骤中，首先将输入文本按空格切分成单词，然后再将每个单词拆分成字符，接着应用训练得到的合并规则，逐步将相邻字符合并。\n",
    "\n",
    "经过这些合并后，剩下的就是子词（subwords） ——这些子词可能是完整的单词、单词的一部分，也可能只是单个字符，具体取决于该单词在训练数据中的出现频率。\n",
    "\n",
    "最终，这些子词（subwords）就构成了的输出词元（tokens）。"
   ],
   "id": "81b74fa6efc91165"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:03:54.747341Z",
     "start_time": "2025-11-11T16:03:54.714089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SubWordTokenizer:\n",
    "    def __init__(self, vocabulary, merges):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.merges = merges\n",
    "        self.unk_id = vocabulary[\"[UNK]\"]\n",
    "\n",
    "    def standardize(self, inputs):\n",
    "        return inputs.lower()\n",
    "\n",
    "    def bpe_merge(self, word):\n",
    "        while True:\n",
    "            # 匹配word里所有的符号对\n",
    "            pairs = re.findall(r\"(?<!\\S)\\S+ \\S+(?!\\S)\", word, overlapped=True)\n",
    "            if not pairs:\n",
    "                break\n",
    "\n",
    "            # 通过rank 执行merge规则，最频繁的 符号对最先合并\n",
    "            best = min(pairs, key=lambda pair: self.merges.get(pair, 1e9))\n",
    "            if best not in self.merges:\n",
    "                break\n",
    "\n",
    "            first, second = best.split()\n",
    "            split = re.compile(f\"(?<!\\S){first} {second}(?!\\S)\")\n",
    "            merged = f\"{first}{second}\"\n",
    "            word = split.sub(merged, word)\n",
    "        return word\n",
    "\n",
    "\n",
    "    def split(self, inputs):\n",
    "        tokens = []\n",
    "        # 切分单词\n",
    "        for word in re.findall(r\"[\\w]+|[.,!?;]\", inputs):\n",
    "            # 通过空格连接字母\n",
    "            word = \" \".join(re.findall(r\".\", word))\n",
    "\n",
    "            # 应用BPE编码规则\n",
    "            word = self.bpe_merge(word)\n",
    "            tokens.extend(word.split())\n",
    "        return tokens\n",
    "\n",
    "    def index(self, tokens):\n",
    "        return [self.vocabulary.get(t, self.unk_id) for t in tokens]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        inputs = self.standardize(inputs)\n",
    "        tokens = self.split(inputs)\n",
    "        indices = self.index(tokens)\n",
    "        return indices"
   ],
   "id": "93ed2ee1dc7bbcff",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:05:01.534116Z",
     "start_time": "2025-11-11T16:04:02.485875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocabulary, merges = compute_sub_word_vocabulary(moby_dick, 2_000)\n",
    "sub_word_tokenizer = SubWordTokenizer(vocabulary, merges)"
   ],
   "id": "a67123b2ed3d38b3",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T16:05:40.332459Z",
     "start_time": "2025-11-11T16:05:40.302921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Vocabulary length:\", len(vocabulary))\n",
    "print(\"Vocabulary start:\", list(vocabulary.keys())[:10])\n",
    "print(\"Vocabulary end:\", list(vocabulary.keys())[-7:])\n",
    "print(\"Line length:\", len(sub_word_tokenizer(\"Call me Ishmael. Some years ago--never mind how long precisely.\"\n",
    ")))"
   ],
   "id": "3cf1135ce4dd6f7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 2000\n",
      "Vocabulary start: ['[UNK]', 'e', 't', 'a', 'o', 'n', 'i', 's', 'h', 'r']\n",
      "Vocabulary end: ['bright', 'pilot', 'sco', 'ben', 'dem', 'gale', 'ilo']\n",
      "Line length: 16\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对于的测试句子来说，SubWordTokenizer（子词分词器） 的分词结果稍微比 WordTokenizer（词级分词器） 长一些（16 个词元 vs 13 个词元），\n",
    "但与 WordTokenizer 不同的是，SubWordTokenizer 能够对《白鲸记》（Moby Dick）中的每一个单词进行分词，而无需使用 \"[UNK]\"（未知词）标记。SubWordTokenizer 不需要 [UNK]，因为它的词表覆盖了所有字符（字符级基础），任何新词都能被拆分成已知的子词或字符组合。\n",
    "\n",
    "因为词表中包含了源文本中的所有字符，所以在最糟糕的情况下，模型也只是把一个单词拆成单个字符来处理。换句话说，在保持较短平均词元长度的同时，又能用一个较小的词表有效地处理罕见词。 这正是 **子词分词器（subword tokenizer**的优势所在。\n",
    "\n",
    "你可能会注意到，运行这段代码的速度要明显慢于字符级或词级分词器——大约需要一分钟左右。这是因为学习合并规则（merge rules）的过程远比简单地统计输入数据集中的单词频率复杂得多。虽然这是子词分词的一项缺点，但在实际应用中，这通常并不是什么严重问题：一个模型只需要学习一次词表，\n",
    "而子词词表学习的开销，相比于模型训练成本，几乎可以忽略不计。\n",
    "\n",
    "已经看到了三种不同的文本分词方法。现在，已经能够把文本转换为数值输入，接下来就可以进入模型训练阶段了。\n",
    "\n",
    "虽然理解分词器的工作原理非常重要，但在实际项目中，几乎不需要自己从零实现一个分词器。Keras（以及大多数深度学习框架）都提供了现成的文本分词工具。"
   ],
   "id": "bd99781f2acefac7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**应该使用哪种分词技术？**\n",
    "\n",
    "在处理一个新的文本建模问题时，首先需要回答的问题之一就是：\n",
    "\n",
    "> **该如何对输入文本进行分词（tokenization）？**\n",
    "\n",
    "如果使用的是**预训练模型（pretrained model）**，这个问题其实是**没有选择的**：\n",
    "你必须严格遵循模型在预训练阶段所使用的**完全相同的分词方式**，\n",
    "否则就会破坏模型权重中对输入词元所学习到的有用表示。\n",
    "\n",
    "\n",
    "\n",
    "如果是**从零开始训练模型**，则可以根据任务的特点灵活选择分词方式。\n",
    "一般来说，**词级（word-level）** 或 **子词级（subword-level）** 分词所带来的“压缩效果”极其重要，不可忽视。\n",
    "输入序列平均长度越短，模型就越容易捕捉文本中的**长距离依赖关系（long-range dependencies）**，\n",
    "从而提升整体性能。\n",
    "这正是为什么 **子词分词（subword tokenization）** 成为现代语言模型的主流选择：\n",
    "它既能处理罕见词或拼写错误的单词，\n",
    "又不会让常见词的 token 数量暴涨。\n",
    "\n",
    "\n",
    "\n",
    "不过，**没有一种分词方式是万能的**。\n",
    "在某些 NLP 任务中（例如**拼写纠错**），\n",
    "使用**字符级分词（character-level tokenization）** 可能更有优势，\n",
    "因为它能捕捉到更底层的细节。\n",
    "\n",
    "相反，**词级分词（word-level tokenization）** 的优势在于简单直观：\n",
    "每个模型输入都对应一个人类可读的单词。\n",
    "这不仅易于理解，还使得分析“哪些 token 对预测结果最重要”更加直观明了。\n",
    "\n"
   ],
   "id": "6230720ce294b6c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 文本分类",
   "id": "f7a066a7cd7ab2e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:20:13.345323Z",
     "start_time": "2025-11-13T15:20:09.461515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo： 有顺序的词元 和 没有顺序的词元\n",
    "import keras"
   ],
   "id": "39fe32b75086b6c1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:20:14.405013Z",
     "start_time": "2025-11-13T15:20:14.394013Z"
    }
   },
   "cell_type": "code",
   "source": "keras.__version__",
   "id": "b29182601c6b852e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:21:47.466878Z",
     "start_time": "2025-11-13T15:20:15.479140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "zip_path = keras.utils.get_file(\n",
    "    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    fname=\"imdb\",\n",
    "    extract=True,\n",
    ")"
   ],
   "id": "d8cfb22b6a537f5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:21:55.857631Z",
     "start_time": "2025-11-13T15:21:55.845633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imdb_extract_dir = pathlib.Path(zip_path) / \"..\" / \"aclImdb\"\n",
    "print(imdb_extract_dir)"
   ],
   "id": "cd728f2ec5ae7626",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.keras\\datasets\\imdb\\..\\aclImdb\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:21:57.499775Z",
     "start_time": "2025-11-13T15:21:57.487769Z"
    }
   },
   "cell_type": "code",
   "source": "print(open(imdb_extract_dir / \"train\" / \"pos\" / \"4077_10.txt\", \"r\").read())",
   "id": "162eafe0b360eb2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:22:02.068545Z",
     "start_time": "2025-11-13T15:22:02.056548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for path in imdb_extract_dir.glob(\"*/*\"):\n",
    "    if path.is_dir():\n",
    "        print(path)"
   ],
   "id": "fd407369884dcf08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\.keras\\datasets\\imdb\\..\\aclImdb\\test\\neg\n",
      "C:\\Users\\Administrator\\.keras\\datasets\\imdb\\..\\aclImdb\\test\\pos\n",
      "C:\\Users\\Administrator\\.keras\\datasets\\imdb\\..\\aclImdb\\train\\neg\n",
      "C:\\Users\\Administrator\\.keras\\datasets\\imdb\\..\\aclImdb\\train\\pos\n",
      "C:\\Users\\Administrator\\.keras\\datasets\\imdb\\..\\aclImdb\\train\\unsup\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:22:17.058653Z",
     "start_time": "2025-11-13T15:22:17.045654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splits the training data into a train set and a validation set\n",
    "train_dir = pathlib.Path(\"imdb_train\")\n",
    "test_dir = pathlib.Path(\"imdb_test\")\n",
    "val_dir = pathlib.Path(\"imdb_val\")\n",
    "\n",
    "# Moves the test data unaltered\n",
    "shutil.copytree(imdb_extract_dir / \"test\", test_dir)\n",
    "\n",
    "# train valid split\n",
    "val_percentage = 0.2\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    src_dir = imdb_extract_dir / \"train\" / category\n",
    "    src_files = os.listdir(src_dir)\n",
    "    random.Random(1337).shuffle(src_files)\n",
    "    num_val_samples = int(len(src_files) * val_percentage)\n",
    "\n",
    "    os.makedirs(val_dir / category)\n",
    "    for file in src_files[:num_val_samples]:\n",
    "        shutil.copy(src_dir / file, val_dir / category / file)\n",
    "    os.makedirs(train_dir / category)\n",
    "    for file in src_files[num_val_samples:]:\n",
    "        shutil.copy(src_dir / file, train_dir / category / file)"
   ],
   "id": "53d530844c9b89d3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:22:27.158789Z",
     "start_time": "2025-11-13T15:22:23.234802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.utils import text_dataset_from_directory\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = text_dataset_from_directory(train_dir, batch_size=batch_size)\n",
    "val_ds = text_dataset_from_directory(val_dir, batch_size=batch_size)\n",
    "test_ds = text_dataset_from_directory(test_dir, batch_size=batch_size)\n"
   ],
   "id": "b4190622ffa1af21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### bag of words",
   "id": "d548976a6c920143"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:22:44.776251Z",
     "start_time": "2025-11-13T15:22:40.320017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "\n",
    "max_tokens = 20_000\n",
    "\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    split='whitespace',\n",
    "    output_mode='multi_hot',\n",
    ")\n",
    "\n",
    "train_ds_no_labels = train_ds.map(lambda x,y: x)\n",
    "text_vectorization.adapt(train_ds_no_labels)\n",
    "\n",
    "bag_of_words_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")\n",
    "bag_of_words_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")\n",
    "bag_of_words_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")"
   ],
   "id": "eea6d0b04f29f09f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:03:21.969294Z",
     "start_time": "2025-11-13T13:03:21.880298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = next(bag_of_words_train_ds.as_numpy_iterator())\n",
    "x.shape\n",
    "y.shape\n"
   ],
   "id": "14d75b5be5c494",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:04:33.390908Z",
     "start_time": "2025-11-13T13:04:33.346079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_linear_classifier(max_tokens, name):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "    model = keras.Model(inputs, outputs, name=name)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_linear_classifier(max_tokens, \"bag_of_words_classifier\")"
   ],
   "id": "9e9073b85bb88846",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:04:51.833922Z",
     "start_time": "2025-11-13T13:04:51.819924Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "d918749f996c9b34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bag_of_words_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 20001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20001 (78.13 KB)\n",
      "Trainable params: 20001 (78.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:30:55.227526Z",
     "start_time": "2025-11-13T15:30:55.216528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    restore_best_weights=True,\n",
    "    patience=2,\n",
    ")\n",
    "history = model.fit(\n",
    "    bag_of_words_train_ds,\n",
    "    validation_data=bag_of_words_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ],
   "id": "b3091704938f0bf6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:06:59.322408Z",
     "start_time": "2025-11-13T13:06:58.345041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"r--\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "5ec7862d5cfd14e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:07:36.020722Z",
     "start_time": "2025-11-13T13:07:31.617844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = model.evaluate(bag_of_words_test_ds)\n",
    "test_acc"
   ],
   "id": "1f0bc76eba9c3c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.2809 - accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8867599964141846"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### bigram model",
   "id": "6f9f87e324b908d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:17:00.690681Z",
     "start_time": "2025-11-13T13:16:50.352257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_tokens = 30_000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    # Learns a word-level vocabulary\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"multi_hot\",\n",
    "    # Considers all unigrams and bigrams\n",
    "    ngrams=2,\n",
    ")\n",
    "text_vectorization.adapt(train_ds_no_labels)"
   ],
   "id": "9e2ad89a2086914b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:17:02.107903Z",
     "start_time": "2025-11-13T13:17:01.999903Z"
    }
   },
   "cell_type": "code",
   "source": "text_vectorization.get_vocabulary()",
   "id": "9d9c344c6ba4e628",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " 'the',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'it',\n",
       " 'i',\n",
       " 'this',\n",
       " 'that',\n",
       " 'br',\n",
       " 'was',\n",
       " 'as',\n",
       " 'with',\n",
       " 'for',\n",
       " 'movie',\n",
       " 'but',\n",
       " 'of the',\n",
       " 'film',\n",
       " 'on',\n",
       " 'not',\n",
       " 'you',\n",
       " 'his',\n",
       " 'are',\n",
       " 'have',\n",
       " 'he',\n",
       " 'be',\n",
       " 'one',\n",
       " 'in the',\n",
       " 'its',\n",
       " 'at',\n",
       " 'all',\n",
       " 'by',\n",
       " 'an',\n",
       " 'they',\n",
       " 'from',\n",
       " 'who',\n",
       " 'so',\n",
       " 'like',\n",
       " 'her',\n",
       " 'just',\n",
       " 'or',\n",
       " 'about',\n",
       " 'has',\n",
       " 'if',\n",
       " 'out',\n",
       " 'some',\n",
       " 'what',\n",
       " 'there',\n",
       " 'this movie',\n",
       " 'good',\n",
       " 'when',\n",
       " 'more',\n",
       " 'very',\n",
       " 'and the',\n",
       " 'is a',\n",
       " 'my',\n",
       " 'she',\n",
       " 'even',\n",
       " 'no',\n",
       " 'up',\n",
       " 'the film',\n",
       " 'would',\n",
       " 'to the',\n",
       " 'which',\n",
       " 'time',\n",
       " 'only',\n",
       " 'to be',\n",
       " 'really',\n",
       " 'their',\n",
       " 'story',\n",
       " 'see',\n",
       " 'had',\n",
       " 'were',\n",
       " 'the movie',\n",
       " 'can',\n",
       " 'me',\n",
       " 'this film',\n",
       " 'than',\n",
       " 'it is',\n",
       " 'we',\n",
       " 'much',\n",
       " 'well',\n",
       " 'get',\n",
       " 'this is',\n",
       " 'been',\n",
       " 'will',\n",
       " 'into',\n",
       " 'also',\n",
       " 'on the',\n",
       " 'people',\n",
       " 'bad',\n",
       " 'do',\n",
       " 'other',\n",
       " 'in a',\n",
       " 'great',\n",
       " 'how',\n",
       " 'because',\n",
       " 'first',\n",
       " 'most',\n",
       " 'him',\n",
       " 'dont',\n",
       " 'it was',\n",
       " 'then',\n",
       " 'one of',\n",
       " 'for the',\n",
       " 'made',\n",
       " 'with the',\n",
       " 'movies',\n",
       " 'way',\n",
       " 'make',\n",
       " 'of a',\n",
       " 'films',\n",
       " 'could',\n",
       " 'br the',\n",
       " 'them',\n",
       " 'any',\n",
       " 'too',\n",
       " 'after',\n",
       " 'characters',\n",
       " 'think',\n",
       " 'is the',\n",
       " 'at the',\n",
       " 'as a',\n",
       " 'watch',\n",
       " 'being',\n",
       " 'seen',\n",
       " 'two',\n",
       " 'many',\n",
       " 'character',\n",
       " 'never',\n",
       " 'little',\n",
       " 'best',\n",
       " 'plot',\n",
       " 'acting',\n",
       " 'br br',\n",
       " 'where',\n",
       " 'love',\n",
       " 'did',\n",
       " 'in this',\n",
       " 'from the',\n",
       " 'life',\n",
       " 'know',\n",
       " 'with a',\n",
       " 'show',\n",
       " 'as the',\n",
       " 'does',\n",
       " 'ever',\n",
       " 'if you',\n",
       " 'your',\n",
       " 'still',\n",
       " 'better',\n",
       " 'over',\n",
       " 'these',\n",
       " 'off',\n",
       " 'say',\n",
       " 'end',\n",
       " 'i was',\n",
       " 'while',\n",
       " 'scene',\n",
       " 'here',\n",
       " 'man',\n",
       " 'why',\n",
       " 'to see',\n",
       " 'that the',\n",
       " 'the story',\n",
       " 'out of',\n",
       " 'scenes',\n",
       " 'such',\n",
       " 'something',\n",
       " 'go',\n",
       " 'should',\n",
       " 'by the',\n",
       " 'im',\n",
       " 'through',\n",
       " 'back',\n",
       " 'those',\n",
       " 'and i',\n",
       " 'the first',\n",
       " 'was a',\n",
       " 'movie is',\n",
       " 'doesnt',\n",
       " 'watching',\n",
       " 'i have',\n",
       " 'real',\n",
       " 'for a',\n",
       " 'years',\n",
       " 'actors',\n",
       " 'all the',\n",
       " 'thing',\n",
       " 'though',\n",
       " 'there is',\n",
       " 'now',\n",
       " 'didnt',\n",
       " 'new',\n",
       " 'have been',\n",
       " 'makes',\n",
       " 'actually',\n",
       " 'nothing',\n",
       " 'of this',\n",
       " 'another',\n",
       " 'before',\n",
       " 'work',\n",
       " 'find',\n",
       " 'and a',\n",
       " 'film is',\n",
       " 'old',\n",
       " 'funny',\n",
       " 'same',\n",
       " 'going',\n",
       " 'look',\n",
       " 'few',\n",
       " 'is not',\n",
       " 'every',\n",
       " 'lot',\n",
       " 'part',\n",
       " 'us',\n",
       " 'director',\n",
       " 'br i',\n",
       " 'again',\n",
       " 'thats',\n",
       " 'cant',\n",
       " 'the same',\n",
       " 'a good',\n",
       " 'want',\n",
       " 'cast',\n",
       " 'quite',\n",
       " 'there are',\n",
       " 'things',\n",
       " 'the end',\n",
       " 'seems',\n",
       " 'pretty',\n",
       " 'got',\n",
       " 'a lot',\n",
       " 'young',\n",
       " 'fact',\n",
       " 'the most',\n",
       " 'around',\n",
       " 'down',\n",
       " 'take',\n",
       " 'however',\n",
       " 'the best',\n",
       " 'world',\n",
       " 'but the',\n",
       " 'give',\n",
       " 'both',\n",
       " 'enough',\n",
       " 'between',\n",
       " 'own',\n",
       " 'may',\n",
       " 'ive',\n",
       " 'big',\n",
       " 'horror',\n",
       " 'original',\n",
       " 'about the',\n",
       " 'thought',\n",
       " 'to make',\n",
       " 'of his',\n",
       " 'always',\n",
       " 'without',\n",
       " 'series',\n",
       " 'the only',\n",
       " 'gets',\n",
       " 'i think',\n",
       " 'right',\n",
       " 'on a',\n",
       " 'but i',\n",
       " 'he is',\n",
       " 'long',\n",
       " 'saw',\n",
       " 'almost',\n",
       " 'isnt',\n",
       " 'that is',\n",
       " 'come',\n",
       " 'least',\n",
       " 'role',\n",
       " 'times',\n",
       " 'action',\n",
       " 'whole',\n",
       " 'theres',\n",
       " 'that i',\n",
       " 'a movie',\n",
       " 'point',\n",
       " 'interesting',\n",
       " 'comedy',\n",
       " 'must',\n",
       " 'family',\n",
       " 'a great',\n",
       " 'bit',\n",
       " 'to watch',\n",
       " 'the plot',\n",
       " 'hes',\n",
       " 'this one',\n",
       " 'done',\n",
       " 'music',\n",
       " 'script',\n",
       " 'but it',\n",
       " 'the characters',\n",
       " 'a very',\n",
       " 'to a',\n",
       " 'anything',\n",
       " 'feel',\n",
       " 'since',\n",
       " 'minutes',\n",
       " 'might',\n",
       " 'last',\n",
       " 'far',\n",
       " 'that it',\n",
       " 'performance',\n",
       " 'probably',\n",
       " 'guy',\n",
       " 'a few',\n",
       " 'be a',\n",
       " 'am',\n",
       " 'some of',\n",
       " 'kind',\n",
       " 'and it',\n",
       " 'was the',\n",
       " 'i dont',\n",
       " 'rather',\n",
       " 'have to',\n",
       " 'away',\n",
       " 'to get',\n",
       " 'worst',\n",
       " 'yet',\n",
       " 'sure',\n",
       " 'its a',\n",
       " 'woman',\n",
       " 'having',\n",
       " 'a little',\n",
       " 'tv',\n",
       " 'each',\n",
       " 'want to',\n",
       " 'girl',\n",
       " 'found',\n",
       " 'making',\n",
       " 'they are',\n",
       " 'anyone',\n",
       " 'would have',\n",
       " 'played',\n",
       " 'fun',\n",
       " 'is that',\n",
       " 'trying',\n",
       " 'into the',\n",
       " 'at least',\n",
       " 'course',\n",
       " 'comes',\n",
       " 'like a',\n",
       " 'our',\n",
       " 'the acting',\n",
       " 'i am',\n",
       " 'although',\n",
       " 'to do',\n",
       " 'the other',\n",
       " 'has a',\n",
       " 'believe',\n",
       " 'especially',\n",
       " 'the way',\n",
       " 'lot of',\n",
       " 'hard',\n",
       " 'day',\n",
       " 'goes',\n",
       " 'looks',\n",
       " 'wasnt',\n",
       " 'shows',\n",
       " 'different',\n",
       " 'a film',\n",
       " 'is one',\n",
       " 'kind of',\n",
       " 'maybe',\n",
       " 'would be',\n",
       " 'i would',\n",
       " 'set',\n",
       " 'this was',\n",
       " 'br this',\n",
       " 'place',\n",
       " 'someone',\n",
       " 'true',\n",
       " 'to have',\n",
       " 'put',\n",
       " 'watched',\n",
       " 'sense',\n",
       " 'have a',\n",
       " 'worth',\n",
       " 'main',\n",
       " '2',\n",
       " 'reason',\n",
       " 'trying to',\n",
       " 'money',\n",
       " 'ending',\n",
       " 'book',\n",
       " 'actor',\n",
       " 'once',\n",
       " 'the whole',\n",
       " 'everything',\n",
       " 'looking',\n",
       " 'job',\n",
       " 'plays',\n",
       " 'he was',\n",
       " 'seem',\n",
       " 'of course',\n",
       " 'dvd',\n",
       " 'that this',\n",
       " 'as well',\n",
       " 'said',\n",
       " 'three',\n",
       " 'john',\n",
       " 'like the',\n",
       " 'and his',\n",
       " 'later',\n",
       " 'instead',\n",
       " 'takes',\n",
       " 'screen',\n",
       " '10',\n",
       " 'effects',\n",
       " 'left',\n",
       " 'together',\n",
       " 'in his',\n",
       " 'himself',\n",
       " 'beautiful',\n",
       " 'during',\n",
       " 'a bit',\n",
       " 'version',\n",
       " 'you can',\n",
       " 'seeing',\n",
       " 'movie was',\n",
       " 'play',\n",
       " 'everyone',\n",
       " 'house',\n",
       " 'most of',\n",
       " 'the original',\n",
       " 'audience',\n",
       " 'the worst',\n",
       " 'special',\n",
       " 'excellent',\n",
       " 'idea',\n",
       " 'night',\n",
       " 'is an',\n",
       " 'that he',\n",
       " 'american',\n",
       " 'not a',\n",
       " 'could have',\n",
       " 'simply',\n",
       " 'which is',\n",
       " 'i can',\n",
       " 'the time',\n",
       " 'nice',\n",
       " 'more than',\n",
       " 'shot',\n",
       " 'completely',\n",
       " 'to say',\n",
       " 'read',\n",
       " 'going to',\n",
       " 'wife',\n",
       " 'second',\n",
       " 'i had',\n",
       " 'less',\n",
       " 'star',\n",
       " 'high',\n",
       " 'help',\n",
       " 'black',\n",
       " 'by a',\n",
       " 'kids',\n",
       " 'who is',\n",
       " 'youre',\n",
       " 'else',\n",
       " 'poor',\n",
       " 'fan',\n",
       " 'year',\n",
       " 'used',\n",
       " 'all of',\n",
       " 'at all',\n",
       " 'given',\n",
       " 'war',\n",
       " 'enjoy',\n",
       " 'i saw',\n",
       " 'home',\n",
       " 'when i',\n",
       " 'performances',\n",
       " 'father',\n",
       " 'try',\n",
       " 'but this',\n",
       " 'until',\n",
       " 'death',\n",
       " 'use',\n",
       " 'friends',\n",
       " 'need',\n",
       " 'rest',\n",
       " 'when the',\n",
       " 'classic',\n",
       " 'into a',\n",
       " 'of all',\n",
       " 'either',\n",
       " 'seems to',\n",
       " 'short',\n",
       " 'is so',\n",
       " 'such a',\n",
       " 'and then',\n",
       " 'truly',\n",
       " 'wrong',\n",
       " 'mind',\n",
       " 'men',\n",
       " 'along',\n",
       " 'next',\n",
       " 'of it',\n",
       " 'it has',\n",
       " 'half',\n",
       " 'the fact',\n",
       " 'production',\n",
       " 'its not',\n",
       " 'of them',\n",
       " 'hollywood',\n",
       " 'boring',\n",
       " 'dead',\n",
       " 'tell',\n",
       " 'women',\n",
       " 'movie and',\n",
       " 'remember',\n",
       " 'perhaps',\n",
       " 'part of',\n",
       " 'line',\n",
       " 'couple',\n",
       " 'start',\n",
       " 'came',\n",
       " 'recommend',\n",
       " 'in my',\n",
       " 'is just',\n",
       " 'full',\n",
       " 'let',\n",
       " 'i thought',\n",
       " 'episode',\n",
       " 'she is',\n",
       " 'moments',\n",
       " 'with his',\n",
       " 'like this',\n",
       " 'the rest',\n",
       " 'understand',\n",
       " 'movie i',\n",
       " 'mean',\n",
       " 'getting',\n",
       " 'awful',\n",
       " 'stupid',\n",
       " 'wonderful',\n",
       " 'camera',\n",
       " 'doing',\n",
       " 'fact that',\n",
       " 'the main',\n",
       " 'others',\n",
       " 'as it',\n",
       " 'often',\n",
       " 'early',\n",
       " 'terrible',\n",
       " 'playing',\n",
       " 'video',\n",
       " 'definitely',\n",
       " 'keep',\n",
       " 'gives',\n",
       " 'small',\n",
       " 'you have',\n",
       " 'is very',\n",
       " 'for this',\n",
       " 'finally',\n",
       " 'sex',\n",
       " 'from a',\n",
       " 'the world',\n",
       " 'stars',\n",
       " 'become',\n",
       " 'film and',\n",
       " 'perfect',\n",
       " 'the actors',\n",
       " 'school',\n",
       " 'name',\n",
       " 'that was',\n",
       " 'itself',\n",
       " 'felt',\n",
       " 'couldnt',\n",
       " 'yes',\n",
       " 'they were',\n",
       " 'over the',\n",
       " 'has been',\n",
       " 'case',\n",
       " 'absolutely',\n",
       " 'supposed',\n",
       " 'that they',\n",
       " 'face',\n",
       " 'lost',\n",
       " 'top',\n",
       " 'human',\n",
       " 'the two',\n",
       " 'you are',\n",
       " 'piece',\n",
       " 'person',\n",
       " 'lines',\n",
       " 'went',\n",
       " 'liked',\n",
       " 'dialogue',\n",
       " 'title',\n",
       " 'the director',\n",
       " 'through the',\n",
       " 'had a',\n",
       " 'there was',\n",
       " 'written',\n",
       " 'live',\n",
       " 'against',\n",
       " 'it and',\n",
       " 'sort',\n",
       " 'shes',\n",
       " 'certainly',\n",
       " 'the last',\n",
       " 'entire',\n",
       " 'it to',\n",
       " 'and that',\n",
       " 'in fact',\n",
       " 'problem',\n",
       " 'budget',\n",
       " 'of her',\n",
       " 'be the',\n",
       " '3',\n",
       " 'worse',\n",
       " 'the script',\n",
       " 'style',\n",
       " 'several',\n",
       " 'it a',\n",
       " 'head',\n",
       " 'mr',\n",
       " 'see the',\n",
       " 'fans',\n",
       " 'hope',\n",
       " 'at a',\n",
       " 'of my',\n",
       " 'id',\n",
       " 'waste',\n",
       " 'loved',\n",
       " 'and is',\n",
       " 'the show',\n",
       " 'overall',\n",
       " 'picture',\n",
       " 'story is',\n",
       " 'already',\n",
       " 'cinema',\n",
       " 'it would',\n",
       " 'example',\n",
       " 'so much',\n",
       " 'will be',\n",
       " 'he has',\n",
       " 'and he',\n",
       " 'to find',\n",
       " 'entertaining',\n",
       " 'evil',\n",
       " 'about this',\n",
       " 'care',\n",
       " 'seemed',\n",
       " 'despite',\n",
       " 'boy',\n",
       " '\\x96',\n",
       " 'oh',\n",
       " 'based',\n",
       " 'friend',\n",
       " 'i cant',\n",
       " 'white',\n",
       " 'rest of',\n",
       " 'can be',\n",
       " 'beginning',\n",
       " 'becomes',\n",
       " 'wanted',\n",
       " 'lives',\n",
       " 'killer',\n",
       " 'final',\n",
       " 'unfortunately',\n",
       " 'is in',\n",
       " 'supposed to',\n",
       " 'direction',\n",
       " 'dark',\n",
       " 'not to',\n",
       " 'turn',\n",
       " 'guys',\n",
       " 'does not',\n",
       " 'just a',\n",
       " 'is no',\n",
       " 'totally',\n",
       " 'mother',\n",
       " 'movie that',\n",
       " 'and its',\n",
       " 'fine',\n",
       " 'film was',\n",
       " 'throughout',\n",
       " 'sort of',\n",
       " 'should be',\n",
       " 'the cast',\n",
       " 'wants',\n",
       " 'with this',\n",
       " 'film that',\n",
       " '1',\n",
       " 'to this',\n",
       " 'to go',\n",
       " 'lead',\n",
       " 'sound',\n",
       " 'humor',\n",
       " 'children',\n",
       " 'wont',\n",
       " 'history',\n",
       " 'guess',\n",
       " 'as i',\n",
       " 'under',\n",
       " 'writing',\n",
       " 'tries',\n",
       " 'because of',\n",
       " 'girls',\n",
       " 'called',\n",
       " 'michael',\n",
       " 'laugh',\n",
       " 'works',\n",
       " 'about a',\n",
       " 'not the',\n",
       " 'i could',\n",
       " 'drama',\n",
       " 'than the',\n",
       " 'enjoyed',\n",
       " 'and this',\n",
       " 'you will',\n",
       " 'i found',\n",
       " 'turns',\n",
       " 'amazing',\n",
       " 'past',\n",
       " 'able',\n",
       " 'watch it',\n",
       " 'theyre',\n",
       " 'hard to',\n",
       " 'days',\n",
       " 'youll',\n",
       " 'act',\n",
       " 'watch this',\n",
       " 'low',\n",
       " 'the book',\n",
       " 'has to',\n",
       " 'the films',\n",
       " 'behind',\n",
       " 'quality',\n",
       " 'end of',\n",
       " 'ever seen',\n",
       " 'gave',\n",
       " 'favorite',\n",
       " 'kill',\n",
       " 'i didnt',\n",
       " 'to his',\n",
       " 'was not',\n",
       " 'when he',\n",
       " 'the audience',\n",
       " 'see this',\n",
       " 'son',\n",
       " 'game',\n",
       " 'able to',\n",
       " 'is also',\n",
       " 'sometimes',\n",
       " 'make a',\n",
       " 'had to',\n",
       " 'starts',\n",
       " 'side',\n",
       " 'town',\n",
       " 'such as',\n",
       " 'see it',\n",
       " 'car',\n",
       " 'horrible',\n",
       " 'art',\n",
       " 'after the',\n",
       " 'because it',\n",
       " 'up to',\n",
       " 'actress',\n",
       " 'for me',\n",
       " 'say that',\n",
       " 'parts',\n",
       " 'where the',\n",
       " 'viewer',\n",
       " 'eyes',\n",
       " 'as an',\n",
       " 'should have',\n",
       " 'i really',\n",
       " 'expect',\n",
       " 'but its',\n",
       " 'do not',\n",
       " 'acting is',\n",
       " 'not only',\n",
       " 'have seen',\n",
       " 'well as',\n",
       " 'themselves',\n",
       " 'stories',\n",
       " 'a bad',\n",
       " 'i just',\n",
       " 'ones',\n",
       " 'obviously',\n",
       " 'the ending',\n",
       " 'and not',\n",
       " 'of their',\n",
       " 'child',\n",
       " 'run',\n",
       " 'flick',\n",
       " 'thinking',\n",
       " 'it i',\n",
       " 'in which',\n",
       " 'soon',\n",
       " 'seem to',\n",
       " 'feeling',\n",
       " 'very good',\n",
       " 'heart',\n",
       " 'to me',\n",
       " 'so i',\n",
       " 'on this',\n",
       " 'directed',\n",
       " 'back to',\n",
       " 'of those',\n",
       " 'did not',\n",
       " 'decent',\n",
       " 'in an',\n",
       " 'ill',\n",
       " 'ive seen',\n",
       " 'i know',\n",
       " 'took',\n",
       " 'except',\n",
       " 'late',\n",
       " 'that you',\n",
       " 'highly',\n",
       " 'genre',\n",
       " 'myself',\n",
       " 'cannot',\n",
       " 'better than',\n",
       " 'are the',\n",
       " 'you want',\n",
       " 'to take',\n",
       " 'close',\n",
       " 'heard',\n",
       " 'up with',\n",
       " 'city',\n",
       " 'brilliant',\n",
       " 'stuff',\n",
       " 'says',\n",
       " 'fight',\n",
       " 'blood',\n",
       " 'hell',\n",
       " 'in their',\n",
       " 'enough to',\n",
       " 'are a',\n",
       " 'a couple',\n",
       " 'extremely',\n",
       " 'wouldnt',\n",
       " 'killed',\n",
       " 'so many',\n",
       " 'the entire',\n",
       " 'each other',\n",
       " 'kid',\n",
       " 'and they',\n",
       " 'played by',\n",
       " 'matter',\n",
       " 'in all',\n",
       " 'lack',\n",
       " 'it the',\n",
       " 'of an',\n",
       " 'during the',\n",
       " 'special effects',\n",
       " 'leave',\n",
       " 'moment',\n",
       " 'what i',\n",
       " 'hand',\n",
       " 'told',\n",
       " 'roles',\n",
       " 'particularly',\n",
       " 'hour',\n",
       " 'the one',\n",
       " 'happened',\n",
       " 'strong',\n",
       " 'wonder',\n",
       " 'with her',\n",
       " 'happens',\n",
       " 'tries to',\n",
       " 'obvious',\n",
       " 'based on',\n",
       " 'a big',\n",
       " 'involved',\n",
       " 'this show',\n",
       " 'attempt',\n",
       " 'police',\n",
       " 'etc',\n",
       " 'violence',\n",
       " 'when it',\n",
       " 'film i',\n",
       " 'are not',\n",
       " 'was so',\n",
       " 'about it',\n",
       " 'too much',\n",
       " 'if the',\n",
       " 'what the',\n",
       " 'she was',\n",
       " 'story of',\n",
       " 'including',\n",
       " 'is about',\n",
       " 'save',\n",
       " 'please',\n",
       " 'dont know',\n",
       " 'and even',\n",
       " 'living',\n",
       " 'instead of',\n",
       " 'murder',\n",
       " 'piece of',\n",
       " 'number',\n",
       " 'i love',\n",
       " 'and in',\n",
       " 'chance',\n",
       " 'anyway',\n",
       " 'itbr br',\n",
       " 'itbr',\n",
       " 'age',\n",
       " 'movie the',\n",
       " 'in it',\n",
       " 'as he',\n",
       " 'a man',\n",
       " 'score',\n",
       " 'group',\n",
       " 'br it',\n",
       " 'looked',\n",
       " 'lets',\n",
       " 'complete',\n",
       " 'coming',\n",
       " 'experience',\n",
       " 'james',\n",
       " 'it all',\n",
       " 'shown',\n",
       " 'happen',\n",
       " 'alone',\n",
       " 'usually',\n",
       " 'i watched',\n",
       " 'what is',\n",
       " 'none',\n",
       " 'running',\n",
       " 'out the',\n",
       " 'simple',\n",
       " 'ago',\n",
       " 'a real',\n",
       " 'taken',\n",
       " 'god',\n",
       " 'film the',\n",
       " 'type',\n",
       " 'his own',\n",
       " 'ends',\n",
       " 'of these',\n",
       " 'even the',\n",
       " 'slow',\n",
       " 'stop',\n",
       " 'ok',\n",
       " 'serious',\n",
       " 'exactly',\n",
       " 'and you',\n",
       " 'who has',\n",
       " 'the very',\n",
       " 'of its',\n",
       " 'im not',\n",
       " 'if it',\n",
       " 'song',\n",
       " 'even though',\n",
       " 'daughter',\n",
       " 'br in',\n",
       " 'wish',\n",
       " 'whose',\n",
       " 'musical',\n",
       " 'david',\n",
       " 'people who',\n",
       " 'sense of',\n",
       " 'released',\n",
       " 'watching this',\n",
       " 'sad',\n",
       " 'career',\n",
       " 'been a',\n",
       " 'known',\n",
       " 'usual',\n",
       " 'but not',\n",
       " 'hours',\n",
       " 'fan of',\n",
       " 'cinematography',\n",
       " 'try to',\n",
       " 'interest',\n",
       " 'the music',\n",
       " 'seriously',\n",
       " 'i mean',\n",
       " 'have the',\n",
       " 'finds',\n",
       " 'novel',\n",
       " 'across',\n",
       " 'wanted to',\n",
       " 'huge',\n",
       " 'crap',\n",
       " 'what a',\n",
       " 'br if',\n",
       " 'voice',\n",
       " 'the beginning',\n",
       " 'scary',\n",
       " 'as if',\n",
       " '4',\n",
       " 'opening',\n",
       " 'major',\n",
       " 'jokes',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:20:06.295926Z",
     "start_time": "2025-11-13T13:20:06.170932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bigram_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "bigram_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y))\n",
    "bigram_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y))"
   ],
   "id": "ecbb77b75911af4e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:20:27.143798Z",
     "start_time": "2025-11-13T13:20:27.041798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = next(bigram_train_ds.as_numpy_iterator())\n",
    "x.shape"
   ],
   "id": "f06ec00b680331d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 30000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:22:03.878266Z",
     "start_time": "2025-11-13T13:21:23.662541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = build_linear_classifier(max_tokens, \"bigram_classifier\")\n",
    "model.fit(\n",
    "    bigram_train_ds,\n",
    "    validation_data=bigram_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ],
   "id": "52c300b169be7955",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 0.3988 - accuracy: 0.8654 - val_loss: 0.3062 - val_accuracy: 0.8940\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.2232 - accuracy: 0.9356 - val_loss: 0.2673 - val_accuracy: 0.9022\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.1639 - accuracy: 0.9605 - val_loss: 0.2529 - val_accuracy: 0.9060\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.1274 - accuracy: 0.9749 - val_loss: 0.2475 - val_accuracy: 0.9074\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.1015 - accuracy: 0.9841 - val_loss: 0.2459 - val_accuracy: 0.9072\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 0.0822 - accuracy: 0.9895 - val_loss: 0.2472 - val_accuracy: 0.9072\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 0.0671 - accuracy: 0.9937 - val_loss: 0.2501 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22b8c3d91e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:22:40.893021Z",
     "start_time": "2025-11-13T13:22:35.437631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = model.evaluate(bigram_test_ds)\n",
    "test_acc"
   ],
   "id": "de0b2bfd0c7ed3ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.2506 - accuracy: 0.9010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9010000228881836"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 序列模型",
   "id": "86b8d561bc734f83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# \"the quick brown fox jumped over the lazy dog\"\n",
    "#\n",
    "# \"the slow brown badger\"\n",
    "#\n",
    "# [\"the\", \"quick\", \"brown\", \"fox\", \"jumped\", \"over\", \"the\", \"lazy\"]\n",
    "# [\"the\", \"slow\", \"brown\", \"badger\", \"[PAD]\", \"[PAD]\", \"[PAD]\", \"[PAD]\"]"
   ],
   "id": "90af96b74f278529"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:36:27.573582Z",
     "start_time": "2025-11-13T15:36:23.193769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 600\n",
    "max_tokens = 30_000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens =max_tokens,\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"int\",\n",
    "\n",
    "    # pads / truncates to 600 tokens\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "\n",
    "text_vectorization.adapt(train_ds_no_labels)\n",
    "\n",
    "sequence_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")\n",
    "sequence_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")\n",
    "sequence_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y)\n",
    ")"
   ],
   "id": "b98e7270928a7052",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:36:31.297255Z",
     "start_time": "2025-11-13T15:36:31.206249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = next(sequence_test_ds.as_numpy_iterator())\n",
    "x.shape\n",
    "x"
   ],
   "id": "7a9afc3bddbc6a44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 600)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 训练循环网络",
   "id": "859eca169861c182"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在每个时间步，常规循环层在生成输出之前只查看过去和现在的输入，这意味着无法看到未来。为了依据未来的输入去决定现在的编码，一种解决方案是在相同的输入上运行两个循环层（一个从左到右读取单词，另一个从右到左读取它们），然后在每个时间步组合它们的输出（直接连接起来，直接参与该时间步的预测）\n",
    "\n",
    "![双向RNN](./images/RNN/p8.png)"
   ],
   "id": "668c57f279582b6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:18:57.353947Z",
     "start_time": "2025-11-13T14:18:57.339949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "class OneHotEncoding(Layer):\n",
    "    def __init__(self, depth, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "\n",
    "    def call(self, inputs):\n",
    "       return K.one_hot(K.cast(inputs, \"int32\"), self.depth)\n",
    "\n",
    "one_hot_encoding = OneHotEncoding(max_tokens)"
   ],
   "id": "4627c439c3552e74",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:18:58.399852Z",
     "start_time": "2025-11-13T14:18:57.799974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x, y = next(sequence_train_ds.as_numpy_iterator())\n",
    "one_hot_encoding(x).shape"
   ],
   "id": "a5b4f592ed57ddc1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 600, 30000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:19:00.491225Z",
     "start_time": "2025-11-13T14:18:59.958475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_dim = 64\n",
    "inputs = keras.Input(shape=(max_length,), dtype=\"int32\")\n",
    "x= one_hot_encoding(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(hidden_dim))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs, name=\"lstm_with_one_hot\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "id": "2f6ac1d8e7c882a0",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:19:13.536465Z",
     "start_time": "2025-11-13T14:19:13.507321Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "70566e88b775337b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_with_one_hot\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 600)]             0         \n",
      "                                                                 \n",
      " one_hot_encoding_3 (OneHot  (None, 600, 30000)        0         \n",
      " Encoding)                                                       \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 128)               15393280  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15393409 (58.72 MB)\n",
      "Trainable params: 15393409 (58.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-11-13T15:19:20.883853Z",
     "start_time": "2025-11-13T14:19:28.513703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# WARNING: 训练时间非常长\n",
    "model.fit(\n",
    "    sequence_train_ds,\n",
    "    validation_data=sequence_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ],
   "id": "de6346c855fcf7f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "169/625 [=======>......................] - ETA: 2:40:05 - loss: 0.6832 - accuracy: 0.5636"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_acc = model.evaluate(sequence_test_ds)\n",
    "test_acc"
   ],
   "id": "b4f1a8b2515f37d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It’s common to see word embeddings that are 256-dimensional, 512-dimensional, or 1,024-dimensional when dealing with very large vocabularies. On the other hand, one-hot encoding words generally leads to vectors that are 30,000-dimensional in the case of our current vocabulary. So word embeddings pack more information into far fewer dimensions.\n",
    "\n",
    "![token到embedding](./images/RNN/p9.png)\n",
    "\n",
    "The Embedding layer takes as input a rank-2 tensor with shape (batch_size, sequence_length), where each entry is a sequence of integers. The layer returns a floating-point tensor of shape (batch_size, sequence_length, embedding_size)."
   ],
   "id": "9f43dfad09e04eb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:36:58.039418Z",
     "start_time": "2025-11-13T15:36:57.109015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_dim = 64\n",
    "\n",
    "inputs = keras.Input(shape=(max_length,), dtype=\"int32\")\n",
    "\n",
    "x = keras.layers.Embedding(\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=hidden_dim,\n",
    "    mask_zero=True, # mask all elements that initially conatained a zero\n",
    ")(inputs)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(hidden_dim))(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs, name=\"lstm_with_embedding\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "id": "903b9b7a7ba3dcf4",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:46:52.642395Z",
     "start_time": "2025-11-13T15:36:59.751444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(\n",
    "    sequence_train_ds,\n",
    "    validation_data=sequence_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ],
   "id": "41dc53fd33c448c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 121s 188ms/step - loss: 0.4470 - accuracy: 0.7876 - val_loss: 0.3513 - val_accuracy: 0.8472\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 116s 186ms/step - loss: 0.2420 - accuracy: 0.9062 - val_loss: 0.3396 - val_accuracy: 0.8718\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 118s 188ms/step - loss: 0.1161 - accuracy: 0.9586 - val_loss: 0.3314 - val_accuracy: 0.8704\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 119s 190ms/step - loss: 0.0626 - accuracy: 0.9801 - val_loss: 0.4099 - val_accuracy: 0.8620\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 118s 189ms/step - loss: 0.0404 - accuracy: 0.9872 - val_loss: 0.4685 - val_accuracy: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x188af35ba60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_acc = model.evaluate(sequence_test_ds)\n",
    "test_acc"
   ],
   "id": "c1cfcf1234ee806f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 预训练词嵌入",
   "id": "abe26f988fd5070f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:50:32.363490Z",
     "start_time": "2025-11-13T15:50:32.147381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "imdb_vocabulary = text_vectorization.get_vocabulary()\n",
    "tokenize_no_padding = keras.layers.TextVectorization(\n",
    "    vocabulary=imdb_vocabulary,\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"int\"\n",
    ")"
   ],
   "id": "2f75f4b5598b8694",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:53:14.638435Z",
     "start_time": "2025-11-13T15:53:09.322758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Words to the left or right of label\n",
    "context_size = 4\n",
    "# Total window size\n",
    "window_size = 9\n",
    "\n",
    "def window_data(token_ids):\n",
    "    num_windows = tf.maximum(tf.size(token_ids) - context_size * 2, 0)\n",
    "    windows = tf.range(window_size)[None, :]\n",
    "    windows = windows + tf.range(num_windows)[:, None]\n",
    "    windowed_tokens = tf.gather(token_ids, windows)\n",
    "    return tf.data.Dataset.from_tensor_slices(windowed_tokens)\n",
    "\n",
    "def split_label(window):\n",
    "    left = window[:context_size]\n",
    "    right = window[context_size + 1 :]\n",
    "    bag = tf.concat((left, right), axis=0)\n",
    "    label = window[context_size]\n",
    "    return bag, label\n",
    "\n",
    "# Uses all training data, including the unsup/ directory\n",
    "dataset = keras.utils.text_dataset_from_directory(\n",
    "    imdb_extract_dir / \"train\", batch_size=None\n",
    ")\n",
    "# Drops label\n",
    "dataset = dataset.map(lambda x, y: x, num_parallel_calls=8)\n",
    "# Tokenizes\n",
    "dataset = dataset.map(tokenize_no_padding, num_parallel_calls=8)\n",
    "# Creates context windows\n",
    "dataset = dataset.interleave(window_data, cycle_length=8, num_parallel_calls=8)\n",
    "# Splits middle wonder into a label\n",
    "dataset = dataset.map(split_label, num_parallel_calls=8)"
   ],
   "id": "aa0ec15b54176f9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:58:27.010121Z",
     "start_time": "2025-11-13T15:58:26.966220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_dim = 64\n",
    "inputs = keras.Input(shape=(2 * context_size,))\n",
    "cbow_embedding = layers.Embedding(\n",
    "    max_tokens,\n",
    "    hidden_dim,\n",
    ")\n",
    "x = cbow_embedding(inputs)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(max_tokens, activation=\"sigmoid\")(x)\n",
    "cbow_model = keras.Model(inputs, outputs)\n",
    "cbow_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ],
   "id": "fcba7dee4ae790f5",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T15:58:32.020700Z",
     "start_time": "2025-11-13T15:58:31.994773Z"
    }
   },
   "cell_type": "code",
   "source": "cbow_model.summary()",
   "id": "ecbe1ed912943ca1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 8, 64)             1920000   \n",
      "                                                                 \n",
      " global_average_pooling1d_1  (None, 64)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30000)             1950000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3870000 (14.76 MB)\n",
      "Trainable params: 3870000 (14.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-13T15:58:38.720399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.batch(1024).cache()\n",
    "cbow_model.fit(dataset, epochs=4)"
   ],
   "id": "e2bca54171db2a02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "   3087/Unknown - 695s 225ms/step - loss: 6.9662 - sparse_categorical_accuracy: 0.0613"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inputs = keras.Input(shape=(max_length,))\n",
    "lstm_embedding = layers.Embedding(\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=hidden_dim,\n",
    "    mask_zero=True,\n",
    ")\n",
    "x = lstm_embedding(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(hidden_dim))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs, name=\"lstm_with_cbow\")\n",
    "\n",
    "lstm_embedding.embeddings.assign(cbow_embedding.embeddings)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    sequence_train_ds,\n",
    "    validation_data=sequence_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ],
   "id": "8d8e680ce271e8e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
