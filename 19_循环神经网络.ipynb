{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "RNN能够分析时间序列数据，例如网站上每天活跃用户的数量、城市每小时的温度、家里每日耗电量、附近汽车的轨迹等。一旦RNN学习了数据中过去的模式，它便能够利用这些知识来预测未来，当然，前提是过去的模式仍然在未来成立。\n",
    "\n",
    "更一般地说，RNN能够针对任意长度的序列进行处理，而不是针对固定大小的输入。例如，它们可以将句子、文档或音频样本作为输入，因此在自然语言处理应用（比如自动翻译或语音识别）中非常有用。\n",
    "\n",
    "介绍RNN的基本概念以及如何使用时域反向传播来对它们进行训练。\n",
    "\n",
    "此外，将探讨RNN面临的两个主要问题：\n",
    "\n",
    "- 不稳定的梯度，可以通过各种技术（包括循环Dropout和循环层归一化）来缓解。\n",
    "- 非常有限的短期记忆，可以使用LSTM和GRU单元进行扩展。\n",
    "\n",
    "然后，将使用它们来预测时间序列"
   ],
   "id": "808d36ca77c3c02c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 循环神经元和层",
   "id": "fa20bbab8e389b83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "前馈神经网络，其中激活仅在一个方向上流动，从输入层流向输出层。循环神经网络看起来非常像前馈神经网络，只不过它还具有反向的连接。\n",
    "\n",
    "最简单的RNN：它由一个接收输入、产生输出并将输出反送回自身的神经元组成，如图（左）所示。在每个时间步长t（也称为帧），该循环神经元接收输入x(t)和前一个时间步长的输出ŷ(t-1)。由于在第一个时间步长中不涉及先前的输出，因此通常将其设置为0。可以沿时间轴来展开这个小网络，如图1（右）所示。这被称为时间展开网络（它是同一循环神经元在每个时间步长的表示）。\n",
    "\n",
    "![循环神经元](./images/RNN/p1.png)\n",
    "\n",
    "如下图所示，可以轻松地创建一个循环神经元层。在每个时间步长t，每个神经元接收输入向量x(t)和前一个时间步长的输出向量ŷ(t-1)。请注意，现在输入和输出都是向量（当只有一个神经元时，输出是标量）。\n",
    "\n",
    "![一层循环神经元随时间展开](./images/RNN/p2.png)"
   ],
   "id": "1d1a9d0561af440f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "每个循环神经元都有两组权重：一组用于输入x(t)，另一组用于前一个时间步长的输出ŷ(t-1)。我们称这些权重向量为wx和wŷ。如果考虑整个循环神经元层（简称“循环层”）而不仅仅是一个循环神经元，则可以将所有权重向量放在wx和wŷ这两个权重矩阵中。然后，可以如预期的那样计算整个循环层的输出向量，如公式所示，其中b是偏置向量，φ(·)是激活函数（例如ReLU)\n",
    "\n",
    "- 公式：单个实例的循环层输出\n",
    "\n",
    "$$\n",
    "\\hat{y}_{(t)} = \\phi(W_x^{T}x_{(t)} + W_{\\hat{y}}^{T}\\hat{y}_{(t-1)} + b)\n",
    "$$\n",
    "\n",
    "就像前馈神经网络一样，可以通过将时间步长处的所有输入放在输入矩阵 $X_{(t)}$ 中，\n",
    "来一次性计算出整个小批量的循环层输出（见下面公式 ）。\n",
    "\n",
    "- 公式：一次传递中所有实例（小批量）的循环神经元层输出\n",
    "\n",
    "$$\n",
    "\\hat{Y}_{(t)} = \\phi(X_{(t)}W_x + \\hat{Y}_{(t-1)}W_{\\hat{y}} + b)\n",
    "$$\n",
    "\n",
    "也可以写成：\n",
    "\n",
    "$$\n",
    "\\hat{Y}_{(t)} = \\phi(([X_{(t)} \\ \\hat{Y}_{(t-1)}]W + b)), \\quad\n",
    "W =\n",
    "\\begin{bmatrix}\n",
    "W_x \\\\\n",
    "W_{\\hat{y}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "在此等式中：\n",
    "\n",
    "- $\\hat{Y}_{(t)}$ ：是一个 $m \\times n_{\\text{neurons}}$ 矩阵，包含小批量中每个实例在时间步长 $t$ 处该层的输出。\n",
    "  （$m$ 是小批量中的实例数量，$n_{\\text{neurons}}$ 是神经元数量。）\n",
    "\n",
    "- $X_{(t)}$ ：是一个 $m \\times n_{\\text{inputs}}$ 矩阵，包含所有实例的输入。\n",
    "  （$n_{\\text{inputs}}$ 是输入特征的数量。）\n",
    "\n",
    "- $W_x$ ：是一个 $n_{\\text{inputs}} \\times n_{\\text{neurons}}$ 矩阵，包含当前时间步长的输入连接权重。\n",
    "\n",
    "- $W_{\\hat{y}}$ ：是一个 $n_{\\text{neurons}} \\times n_{\\text{neurons}}$ 矩阵，包含前一时间步长的输出连接权重。\n",
    "\n",
    "- $b$ ：是大小为 $n_{\\text{neurons}}$ 的向量，包含每个神经元的偏置项。\n",
    "\n",
    "- 权重矩阵 $W_x$ 和 $W_{\\hat{y}}$ 经竖直重合并形成形状为 $(n_{\\text{inputs}} + n_{\\text{neurons}}) \\times n_{\\text{neurons}}$ 的单个权重矩阵 $W$（见公式 15-2 的第二行）。\n",
    "\n",
    "- 符号 $[X_{(t)} \\ \\hat{Y}_{(t-1)}]$ 表示矩阵 $X_{(t)}$ 和 $\\hat{Y}_{(t-1)}$ 的水平合并。\n",
    "\n",
    "\n",
    "请注意：\n",
    "\n",
    "- $\\hat{Y}_{(t)}$ 是 $X_{(t)}$ 和 $\\hat{Y}_{(t-1)}$ 的函数；\n",
    "- 而 $\\hat{Y}_{(t-1)}$ 是 $X_{(t-1)}$ 和 $\\hat{Y}_{(t-2)}$ 的函数；\n",
    "- $\\hat{Y}_{(t-2)}$ 是 $X_{(t-2)}$ 和 $\\hat{Y}_{(t-3)}$ 的函数；\n",
    "以此类推。\n",
    "\n",
    "这使 $\\hat{Y}_{(t)}$ 成为自时间 $t=0$ 以来所有输入（即 $X_{(0)}, X_{(1)}, \\ldots, X_{(t)}$）的函数。在第一个时间步长 $t=0$ 时，没有先前的输出，因此通常假定它们均为零。\n"
   ],
   "id": "f375c580767f160"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 记忆单元",
   "id": "256930bf6b0e0dbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "由于在时间步长t时循环神经元的输出是先前时间步长中所有输入的函数，因此可以说它具有记忆的形式。神经网络中跨时间步长保留某些状态的部分称为记忆单元（简称单元）。单个循环神经元或循环神经元层是非常基本的单元，它只能学习短模式（通常约为10个步长）。后面将介绍一些能够学习更长模式（大约要长10倍）的更复杂、功能更强大的单元类型。单元在时间步长t的状态表示为h(t)［“h”代表“隐藏”(hidden)］，是该时间步长的某些输入和其前一个时间步长状态的函数：h(t)=f(h(t-1)，x(t))。它在时间步长t的输出表示为ŷ(t)，也是先前状态和当前输入的函数。就目前为止我们讨论的基本单元而言，输出等于状态。",
   "id": "5138dab4232226d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 输入序列和输出序列",
   "id": "afa4c069b38b82c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "RNN可以同时接收一个输入序列并产生一个输出序列。这种序列到序列的网络对于预测时间序列很有用，例如预测家里每日耗电量：将过去N天的数据输入它，然后训练它输出未来一天的耗电量（即从N-1天前到明天）。\n",
    "\n",
    "或者，可以向网络提供一个输入序列，并忽略除了最后一个输出外的所有输出，这是一个序列到向量的网络。例如，可以向网络提供与电影评论相对应的单词序列，然后网络将输出一个情感得分［例如，从0（代表不喜欢）到1（代表喜欢）］。\n",
    "\n",
    "相反，可以在每个时间步长中一次又一次地向网络提供相同的输入向量，并让其输出一个序列，这是一个向量到序列的网络。例如，输入可以是图像（或CNN的输出），而输出可以是该图像的描述文字。最后，可能有一个称为编码器的序列到向量的网络，后跟一个称为解码器的向量到序列的网络。例如，这可以用于将句子从一种语言翻译成另一种语言。可以用一种语言向网络输入一个句子，编码器会将其转换为单个向量表示，然后解码器会将此向量解码为另一种语言的句子。这种称为“编码器—解码器”(Encoder-Decoder)的两步模型比使用单个序列到序列的RNN进行即时翻译要好得多：句子的最后一个单词会影响翻译的第一个单词，因此在翻译之前需要等待，直到看完整个句子。\n",
    "\n",
    "![序列到序列，序列到向量， 向量到序列，编码器-解码器](./images/RNN/p3.png)"
   ],
   "id": "7db240aa7b65e6af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 随堂练习：简单RNN的前向传播",
   "id": "3db98d8e62a1fe83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "见其他文件夹",
   "id": "7e9c13b25cf2da1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练RNN",
   "id": "859edb6c88f0c88d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "要训练RNN，诀窍是将其按照时间逐步展开，然后使用常规的反向传播。这种策略称为“时间反向传播”(BackPropagation Through Time，BPTT)。\n",
    "\n",
    "就像在常规的反向传播中一样，首先通过展开的网络进行第一次前向传递（由虚线箭头表示）。然后，使用损失函数Loss(Y(0)，Y(1)，…，Y(T)；)（其中Y(i)）是第i个目标，Ŷ(i)是第i个预测结果，而T是最大时间步）评估输出序列。注意，此损失函数可能会忽略某些输出。例如，在序列到向量的RNN中，除了最后一个之外，所有输出都被忽略。在图中，仅基于最后三个输出计算损失函数。然后，将该损失函数的梯度通过展开的网络向后传播（由实线箭头表示）。在此示例中，由于输出Ŷ(0)和Ŷ(0)未用于计算损失，因此梯度不会向后流动，它们仅通过Ŷ(2)、Ŷ(3)和Ŷ(4)流动。此外，由于在每个时间步骤中使用相同的参数W和b，因此它们的梯度将在反向传播期间进行多次调整。完成反向阶段并计算出所有梯度后，BPTT可以执行梯度下降步骤来更新参数（这与常规反向传播没有区别）。\n",
    "\n",
    "![RNN反向传播](./images/RNN/p1.jpg)\n",
    "\n",
    "幸运的是，Keras为我们处理了所有这些复杂度"
   ],
   "id": "17921c3fe4dd76c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RNN预测时间序列",
   "id": "fe31fe51c65c47c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在用RNN预测之前，先加载时间序列并使用经典工具开始分析它，以更好地理解要处理的问题，并获得一些基准指标。",
   "id": "fa437223bb610ae0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:44:43.942046Z",
     "start_time": "2025-10-10T06:44:21.477886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "filepath = tf.keras.utils.get_file(\n",
    "    \"ridership.tgz\",\n",
    "    \"https://github.com/ageron/data/raw/main/ridership.tgz\",\n",
    "    cache_dir=\".\",\n",
    "    extract=True\n",
    ")\n",
    "if \"_extracted\" in filepath:\n",
    "    ridership_path = Path(filepath) / \"ridership\"\n",
    "else:\n",
    "    ridership_path = Path(filepath).with_name(\"ridership\")"
   ],
   "id": "91224f88d5fb4558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/ageron/data/raw/main/ridership.tgz\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://github.com/ageron/data/raw/main/ridership.tgz: None -- [Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mgaierror\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:1348\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[1;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[0;32m   1347\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1348\u001B[0m     \u001B[43mh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1349\u001B[0m \u001B[43m              \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhas_header\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTransfer-encoding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1350\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:1283\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1282\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1283\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:1329\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1328\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1329\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mendheaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:1278\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1277\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[1;32m-> 1278\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencode_chunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencode_chunked\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:1038\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[1;32m-> 1038\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1041\u001B[0m \n\u001B[0;32m   1042\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:976\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    975\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[1;32m--> 976\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:1448\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1446\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnect to a host on a given (SSL) port.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1448\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tunnel_host:\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\http\\client.py:942\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    941\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp.client.connect\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport)\n\u001B[1;32m--> 942\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_connection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mport\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\socket.py:836\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address)\u001B[0m\n\u001B[0;32m    835\u001B[0m err \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 836\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[43mgetaddrinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSOCK_STREAM\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    837\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\socket.py:967\u001B[0m, in \u001B[0;36mgetaddrinfo\u001B[1;34m(host, port, family, type, proto, flags)\u001B[0m\n\u001B[0;32m    966\u001B[0m addrlist \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 967\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m \u001B[43m_socket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetaddrinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfamily\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproto\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    968\u001B[0m     af, socktype, proto, canonname, sa \u001B[38;5;241m=\u001B[39m res\n",
      "\u001B[1;31mgaierror\u001B[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\site-packages\\keras\\src\\utils\\data_utils.py:347\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 347\u001B[0m     \u001B[43murlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDLProgbar\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mHTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\site-packages\\keras\\src\\utils\\data_utils.py:85\u001B[0m, in \u001B[0;36murlretrieve\u001B[1;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[0;32m     83\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fd:\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:216\u001B[0m, in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    215\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[1;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mopener\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:519\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    518\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[1;32m--> 519\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:536\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[1;34m(self, req, data)\u001B[0m\n\u001B[0;32m    535\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[1;32m--> 536\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_open\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\n\u001B[0;32m    537\u001B[0m \u001B[43m                          \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_open\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:496\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    495\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[1;32m--> 496\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:1391\u001B[0m, in \u001B[0;36mHTTPSHandler.https_open\u001B[1;34m(self, req)\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mhttps_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[1;32m-> 1391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mHTTPSConnection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1392\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_hostname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\urllib\\request.py:1351\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[1;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[0;32m   1350\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[1;32m-> 1351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[0;32m   1352\u001B[0m r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n",
      "\u001B[1;31mURLError\u001B[0m: <urlopen error [Errno 11001] getaddrinfo failed>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpathlib\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m----> 4\u001B[0m filepath \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mridership.tgz\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://github.com/ageron/data/raw/main/ridership.tgz\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_extracted\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m filepath:\n\u001B[0;32m     11\u001B[0m     ridership_path \u001B[38;5;241m=\u001B[39m Path(filepath) \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mridership\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mD:\\Downloads\\anaconda3\\envs\\homl3\\lib\\site-packages\\keras\\src\\utils\\data_utils.py:351\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    349\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg\u001B[38;5;241m.\u001B[39mformat(origin, e\u001B[38;5;241m.\u001B[39mcode, e\u001B[38;5;241m.\u001B[39mmsg))\n\u001B[0;32m    350\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mURLError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 351\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg\u001B[38;5;241m.\u001B[39mformat(origin, e\u001B[38;5;241m.\u001B[39merrno, e\u001B[38;5;241m.\u001B[39mreason))\n\u001B[0;32m    352\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(fpath):\n",
      "\u001B[1;31mException\u001B[0m: URL fetch failure on https://github.com/ageron/data/raw/main/ridership.tgz: None -- [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:44:48.617256Z",
     "start_time": "2025-10-10T06:44:48.390886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
    "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
    "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  #  更短的名字\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "df = df.drop(\"total\", axis=1)  # 不需要全部，只需要bus + rail\n",
    "df = df.drop_duplicates()  # 删掉重复的月份 (2011-10 and 2014-07)"
   ],
   "id": "7ebf5c2e7c9dbb8a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2001年1月1日，芝加哥有297192人乘坐公共汽车，126455人乘坐火车。day_type列包含W（表示工作日）、A（表示星期六），以及U（表示星期日或节假日）。",
   "id": "aa9c6ab09d044fed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:44:52.951275Z",
     "start_time": "2025-10-10T06:44:52.884108Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "ba6972a82c162b6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           day_type     bus    rail\n",
       "date                               \n",
       "2001-01-01        U  297192  126455\n",
       "2001-01-02        W  780827  501952\n",
       "2001-01-03        W  824923  536432\n",
       "2001-01-04        W  870021  550011\n",
       "2001-01-05        W  890426  557917"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_type</th>\n",
       "      <th>bus</th>\n",
       "      <th>rail</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>U</td>\n",
       "      <td>297192</td>\n",
       "      <td>126455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>W</td>\n",
       "      <td>780827</td>\n",
       "      <td>501952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>W</td>\n",
       "      <td>824923</td>\n",
       "      <td>536432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>W</td>\n",
       "      <td>870021</td>\n",
       "      <td>550011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>W</td>\n",
       "      <td>890426</td>\n",
       "      <td>557917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:44:57.586953Z",
     "start_time": "2025-10-10T06:44:55.128502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2019年几个月的公共汽车和铁路客运量数据\n",
    "df.loc[\"2019-03\":\"2019-05\"].plot(grid=True, marker=\".\", figsize=(8, 3.5))\n",
    "plt.show()"
   ],
   "id": "97ccb913caf1b5da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "这是一个时间序列：具有不同时间步的值的数据，通常间隔固定。更具体地说，由于每个时间步有多个值，因此这称为多元时间序列。如果只查看bus列，它将是一元时间序列，每个时间步都有一个值。预测未来值（即预测）是处理时间序列时最典型的任务。其他任务包括插补（填补过去的缺失值）、分类、异常检测等。",
   "id": "da4ed5da29a57efb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "从图中可以看到每周都有明显类似的模式。这称为每周季节性(seasonality)。\n",
    "\n",
    "这个模式很强大，以至于仅通过复制一周前的值来预测明天的乘客量便可产生相当不错的结果。这称为朴素预测：通过简单地复制过去的值来做出预测。朴素预测通常是一个很好的基准，在某些情况下甚至很难被击败。\n",
    "\n",
    "为了可视化这些朴素预测，我们用虚线叠加两个时间序列（bus和rail）以及滞后一周（即向右移动）的相同时间序列。还将绘制两者之间的差异（即时间t处的值减去时间t-7处的值），这称为差分"
   ],
   "id": "8ff7a01f0c7012bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:45:00.433055Z",
     "start_time": "2025-10-10T06:45:00.004492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "diff_7 = df[[\"bus\", \"rail\"]].diff(7)[\"2019-03\":\"2019-05\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(8, 5))\n",
    "df.plot(ax=axs[0], legend=False, marker=\".\")  #  原始时间序列\n",
    "df.shift(7).plot(ax=axs[0], grid=True, legend=False, linestyle=\":\")  # 往后推的时间序列\n",
    "diff_7.plot(ax=axs[1], grid=True, marker=\".\")  # 7天 差分的时间序列\n",
    "axs[0].set_ylim([170_000, 900_000])  # 美化绘图\n",
    "plt.show()"
   ],
   "id": "884906b2f6273d36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:45:02.956863Z",
     "start_time": "2025-10-10T06:45:02.946309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "diff_7.abs().mean() # Mean absolute error (MAE), 或者是 mean absolute deviation (MAD)\n",
    "\n",
    "# targets = df[[\"bus\", \"rail\"]][\"2019-03\":\"2019-05\"]\n",
    "# (diff_7 / targets).abs().mean() # Mean absolute percentage error (MAPE)"
   ],
   "id": "a58a1265d8f55ed4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bus     43915.608696\n",
       "rail    42143.271739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "现在我们有个基准（即朴素预测), 尝试使用到目前为止介绍的机器学习模型来预测这个时间序列，先从一个基本的线性模型开始。目标是根据过去8周（56天）的客运量数据来预测“明天”的客运量。因此，模型的输入将是序列（一旦模型投入生产，通常每天一个序列），每个序列包含从时间步t-55到t的56个值。对于每个输入序列，模型将输出一个值：时间步t+1的预测值。\n",
    "\n",
    "如何准备训练数据：将使用过去的每个56天（作为窗口）作为训练数据，每个窗口对应的目标值将是紧随其后的值。\n",
    "\n",
    "Keras实际上有一个很好的实用函数（叫作tf.keras.utils.timeseries_dataset_from_array()），它可以帮助准备训练集。它以时间序列作为输入，并构建一个包含所需长度的所有窗口及其相应目标值的tf.data.Dataset"
   ],
   "id": "e82892b520726b7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:45:05.221125Z",
     "start_time": "2025-10-10T06:45:05.014860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "my_series = [0,1,2,3,4,5]\n",
    "my_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    my_series,\n",
    "    targets=my_series[3:],\n",
    "    sequence_length=3,\n",
    "    batch_size=2\n",
    ")\n",
    "my_dataset\n",
    "\n",
    "# 0 1 2 -> 3\n",
    "# 1 2 3 ->  4\n",
    "# 2 3 4  -> 5"
   ],
   "id": "6b894fbf8992e82e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:45:08.042148Z",
     "start_time": "2025-10-10T06:45:07.491214Z"
    }
   },
   "cell_type": "code",
   "source": "list(my_dataset)  #",
   "id": "3ec4c73db164e7ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "  array([[0, 1, 2],\n",
       "         [1, 2, 3]])>,\n",
       "  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4])>),\n",
       " (<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[2, 3, 4]])>,\n",
       "  <tf.Tensor: shape=(1,), dtype=int32, numpy=array([5])>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "数据集中的每个样本都是一个长度为3的窗口，以及它对应的目标值（即紧接在窗口之后的值）。窗口是[0，1，2]、[1，2，3]和[2，3，4]，它们的目标值分别是3、4、5。由于一共有3个窗口，它不是批量大小的倍数，因此最后一个批次只包含一个窗口而不是两个。\n",
    "\n",
    "获得相同结果的另一种方法是使用tf.data的Dataset类的window()方法。它更复杂，但它给了完全的控制权，window()方法返回窗口数据集的数据集"
   ],
   "id": "70e99c7d602720d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T09:26:32.458731Z",
     "start_time": "2025-10-09T09:26:30.824998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for window_dataset in tf.data.Dataset.range(6).window(4, shift=1):\n",
    "    for element in window_dataset:\n",
    "        print(f\"{element}\", end=\" \")\n",
    "    print()"
   ],
   "id": "ad638e7e35a5935b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 \n",
      "1 2 3 4 \n",
      "2 3 4 5 \n",
      "3 4 5 \n",
      "4 5 \n",
      "5 \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在此示例中，数据集包含6个窗口，每个窗口都比前一个窗口多移动一步，最后3个窗口较小，因为它们已到达序列的末尾\n",
    "\n",
    "通常，将drop_remainder=True传递给window()方法来摆脱这些较小的窗口。window()方法返回一个嵌套的数据集，类似于列表的列表。当想要通过调用其数据集方法来转换每个窗口（例如，对它们进行乱序处理或对它们进行批处理）时，这很有用。但是，不能直接使用嵌套数据集进行训练，因为模型以张量而不是数据集为输入。因此，我们必须调用flat_map()方法：它将嵌套数据集转换为平面数据集（包含张量而不是数据集的数据集）。例如，假设{1，2，3}表示包含张量1、2和3序列的数据集，如果将嵌套数据集{{1，2}，{3，4，5，6}}展平，将得到平面数据集{1，2，3，4，5，6}。此外，flat_map()方法将一个函数作为参数，它允许在展平之前转换嵌套数据集中的每个数据集。例如，如果将函数lambda ds：ds.batch(2)传递给flat_map()，那么它会将嵌套数据集{{1，2}，{3，4，5，6}}转换为平面数据集{[1，2]，[3，4]，[5，6]}：它是一个包含3个张量的数据集，每个张量的大小为2。"
   ],
   "id": "d1a46a791f3fcb95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:52:54.504345Z",
     "start_time": "2025-10-10T06:52:54.463803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.range(6).window(4, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window_dataset: window_dataset.batch(4))\n",
    "for window_tensor in dataset:\n",
    "    print(f\"{window_tensor}\")"
   ],
   "id": "994b70abc7d61341",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[1 2 3 4]\n",
      "[2 3 4 5]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:53:52.433728Z",
     "start_time": "2025-10-10T06:53:52.420693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建辅助函数，更方便地从数据集提取窗口\n",
    "def to_windows(dataset, length):\n",
    "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
    "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
   ],
   "id": "fef207403720b908",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T06:56:30.828570Z",
     "start_time": "2025-10-10T06:56:30.522133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用map方法将每个窗口拆分为输入和目标值，然后将生成的窗口分组为大小为2的批次\n",
    "dataset = to_windows(tf.data.Dataset.range(6), 4) # 0 1 2 3, 1 2 3 4, 2 3 4 5\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "list(dataset.batch(2))"
   ],
   "id": "1c873de8f35dae0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
       "  array([[0, 1, 2],\n",
       "         [1, 2, 3]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(2,), dtype=int64, numpy=array([3, 4], dtype=int64)>),\n",
       " (<tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[2, 3, 4]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(1,), dtype=int64, numpy=array([5], dtype=int64)>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:03:30.135611Z",
     "start_time": "2025-10-10T07:03:30.123600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 拆分训练，验证和测试，并归一化\n",
    "rail_train = df[\"rail\"][\"2016-01\":\"2018-12\"] / 1e6\n",
    "rail_valid = df[\"rail\"][\"2019-01\":\"2019-05\"] / 1e6\n",
    "rail_test = df[\"rail\"][\"2019-06\":] / 1e6"
   ],
   "id": "2d04851224b9c150",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "接下来，使用timeseries_dataset_from_array()创建用于训练和验证的数据集。由于梯度下降期望训练集中的实例独立同分布(IID)，因此必须设置参数shuffle=True来打乱训练窗口",
   "id": "7f6b8f6cfa9c8db0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:03:31.841893Z",
     "start_time": "2025-10-10T07:03:31.613873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seq_length = 56\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    rail_train.to_numpy(),\n",
    "    targets=rail_train[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    rail_valid.to_numpy(),\n",
    "    targets=rail_valid[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "# train_ds : [32个，(x(y-55), ... x(t)), y(t+1)), 32个 (x(y-55), ... x(t)), y(t+1)) ... ]"
   ],
   "id": "f69cbba10abe48d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用线性模型进行预测",
   "id": "557173ca7425e7c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:09:57.194379Z",
     "start_time": "2025-10-10T07:09:15.271602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[seq_length])\n",
    "])\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=500, callbacks=[early_stopping_cb])"
   ],
   "id": "2f9a756c9f1a56d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 1s 8ms/step - loss: 0.1225 - mae: 0.3892 - val_loss: 0.0224 - val_mae: 0.1740\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.1261 - val_loss: 0.0068 - val_mae: 0.0882\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0095 - mae: 0.1001 - val_loss: 0.0061 - val_mae: 0.0821\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0089 - mae: 0.0981 - val_loss: 0.0057 - val_mae: 0.0777\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0899 - val_loss: 0.0048 - val_mae: 0.0701\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0795 - val_loss: 0.0048 - val_mae: 0.0685\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0779 - val_loss: 0.0043 - val_mae: 0.0634\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0055 - mae: 0.0733 - val_loss: 0.0043 - val_mae: 0.0633\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0054 - mae: 0.0741 - val_loss: 0.0039 - val_mae: 0.0589\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0052 - mae: 0.0711 - val_loss: 0.0056 - val_mae: 0.0784\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0056 - mae: 0.0776 - val_loss: 0.0061 - val_mae: 0.0900\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0721 - val_loss: 0.0035 - val_mae: 0.0538\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0043 - mae: 0.0622 - val_loss: 0.0037 - val_mae: 0.0591\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0621 - val_loss: 0.0033 - val_mae: 0.0511\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0615 - val_loss: 0.0034 - val_mae: 0.0547\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0042 - mae: 0.0631 - val_loss: 0.0035 - val_mae: 0.0529\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0623 - val_loss: 0.0031 - val_mae: 0.0488\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0596 - val_loss: 0.0031 - val_mae: 0.0523\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0575 - val_loss: 0.0032 - val_mae: 0.0509\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0039 - mae: 0.0600 - val_loss: 0.0031 - val_mae: 0.0496\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0560 - val_loss: 0.0030 - val_mae: 0.0473\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0587 - val_loss: 0.0029 - val_mae: 0.0480\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0564 - val_loss: 0.0029 - val_mae: 0.0470\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0560 - val_loss: 0.0028 - val_mae: 0.0460\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0561 - val_loss: 0.0029 - val_mae: 0.0470\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0585 - val_loss: 0.0028 - val_mae: 0.0477\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0534 - val_loss: 0.0030 - val_mae: 0.0537\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0549 - val_loss: 0.0032 - val_mae: 0.0526\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0547 - val_loss: 0.0027 - val_mae: 0.0477\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0548 - val_loss: 0.0027 - val_mae: 0.0462\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0535 - val_loss: 0.0027 - val_mae: 0.0447\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0569 - val_loss: 0.0027 - val_mae: 0.0445\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0544 - val_loss: 0.0026 - val_mae: 0.0442\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0512 - val_loss: 0.0030 - val_mae: 0.0491\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0555 - val_loss: 0.0026 - val_mae: 0.0437\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0557 - val_loss: 0.0026 - val_mae: 0.0465\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0504 - val_loss: 0.0028 - val_mae: 0.0470\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0527 - val_loss: 0.0025 - val_mae: 0.0442\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0499 - val_loss: 0.0025 - val_mae: 0.0438\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0526 - val_loss: 0.0035 - val_mae: 0.0569\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0505 - val_loss: 0.0028 - val_mae: 0.0476\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0515 - val_loss: 0.0025 - val_mae: 0.0439\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0521 - val_loss: 0.0025 - val_mae: 0.0446\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0487 - val_loss: 0.0024 - val_mae: 0.0423\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0546 - val_loss: 0.0025 - val_mae: 0.0432\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0033 - val_mae: 0.0616\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0500 - val_loss: 0.0031 - val_mae: 0.0583\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0520 - val_loss: 0.0024 - val_mae: 0.0420\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0516 - val_loss: 0.0031 - val_mae: 0.0520\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0556 - val_loss: 0.0025 - val_mae: 0.0425\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0489 - val_loss: 0.0025 - val_mae: 0.0456\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0477 - val_loss: 0.0026 - val_mae: 0.0433\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0479 - val_loss: 0.0029 - val_mae: 0.0499\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0497 - val_loss: 0.0026 - val_mae: 0.0483\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0512 - val_loss: 0.0024 - val_mae: 0.0425\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0493 - val_loss: 0.0024 - val_mae: 0.0424\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0475 - val_loss: 0.0024 - val_mae: 0.0440\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0484 - val_loss: 0.0029 - val_mae: 0.0494\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0511 - val_loss: 0.0025 - val_mae: 0.0424\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0459 - val_loss: 0.0024 - val_mae: 0.0419\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0463 - val_loss: 0.0027 - val_mae: 0.0463\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0483 - val_loss: 0.0024 - val_mae: 0.0413\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0540 - val_loss: 0.0025 - val_mae: 0.0456\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0472 - val_loss: 0.0027 - val_mae: 0.0457\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0588 - val_loss: 0.0029 - val_mae: 0.0545\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0469 - val_loss: 0.0029 - val_mae: 0.0476\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0483 - val_loss: 0.0028 - val_mae: 0.0474\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0478 - val_loss: 0.0024 - val_mae: 0.0407\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0458 - val_loss: 0.0024 - val_mae: 0.0413\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0024 - val_mae: 0.0424\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0024 - val_mae: 0.0406\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0453 - val_loss: 0.0025 - val_mae: 0.0414\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0467 - val_loss: 0.0026 - val_mae: 0.0439\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0024 - val_mae: 0.0439\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0499 - val_loss: 0.0024 - val_mae: 0.0416\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0509 - val_loss: 0.0027 - val_mae: 0.0449\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0513 - val_loss: 0.0026 - val_mae: 0.0472\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0031 - val_mae: 0.0522\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0465 - val_loss: 0.0032 - val_mae: 0.0538\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0484 - val_loss: 0.0024 - val_mae: 0.0436\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0449 - val_loss: 0.0024 - val_mae: 0.0432\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0464 - val_loss: 0.0023 - val_mae: 0.0402\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0493 - val_loss: 0.0027 - val_mae: 0.0457\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0486 - val_loss: 0.0023 - val_mae: 0.0401\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0025 - val_mae: 0.0452\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0441 - val_loss: 0.0025 - val_mae: 0.0416\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0462 - val_loss: 0.0026 - val_mae: 0.0432\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0027 - val_mae: 0.0456\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0519 - val_loss: 0.0025 - val_mae: 0.0419\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0486 - val_loss: 0.0025 - val_mae: 0.0446\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0435 - val_loss: 0.0026 - val_mae: 0.0432\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0024 - val_mae: 0.0436\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0024 - val_mae: 0.0407\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0456 - val_loss: 0.0023 - val_mae: 0.0399\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0023 - val_mae: 0.0404\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0438 - val_loss: 0.0024 - val_mae: 0.0407\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0025 - val_mae: 0.0417\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0464 - val_loss: 0.0023 - val_mae: 0.0398\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0484 - val_loss: 0.0023 - val_mae: 0.0397\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0024 - val_mae: 0.0399\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0026 - val_mae: 0.0427\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0450 - val_loss: 0.0023 - val_mae: 0.0405\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0471 - val_loss: 0.0024 - val_mae: 0.0435\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0025 - val_mae: 0.0445\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0453 - val_loss: 0.0023 - val_mae: 0.0400\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0458 - val_loss: 0.0024 - val_mae: 0.0418\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0450 - val_loss: 0.0024 - val_mae: 0.0401\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0023 - val_mae: 0.0399\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0437 - val_loss: 0.0026 - val_mae: 0.0426\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0478 - val_loss: 0.0024 - val_mae: 0.0418\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0023 - val_mae: 0.0397\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0024 - val_mae: 0.0400\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0438 - val_loss: 0.0024 - val_mae: 0.0407\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0025 - val_mae: 0.0472\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0445 - val_loss: 0.0026 - val_mae: 0.0423\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0023 - val_mae: 0.0394\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0453 - val_loss: 0.0030 - val_mae: 0.0509\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0433 - val_loss: 0.0023 - val_mae: 0.0404\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0433 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0023 - val_mae: 0.0391\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0425 - val_loss: 0.0024 - val_mae: 0.0399\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0025 - val_mae: 0.0414\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0437 - val_loss: 0.0024 - val_mae: 0.0402\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0023 - val_mae: 0.0408\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0446 - val_loss: 0.0028 - val_mae: 0.0470\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0489 - val_loss: 0.0026 - val_mae: 0.0437\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0023 - val_mae: 0.0391\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0026 - val_mae: 0.0427\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0032 - val_mae: 0.0533\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0494 - val_loss: 0.0023 - val_mae: 0.0394\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0449 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0412\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0437 - val_loss: 0.0024 - val_mae: 0.0418\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0438 - val_loss: 0.0024 - val_mae: 0.0404\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0427 - val_loss: 0.0023 - val_mae: 0.0396\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0435 - val_loss: 0.0025 - val_mae: 0.0419\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0474 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0445 - val_loss: 0.0025 - val_mae: 0.0457\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0433 - val_loss: 0.0023 - val_mae: 0.0392\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0024 - val_mae: 0.0398\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0476 - val_loss: 0.0025 - val_mae: 0.0412\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0577 - val_loss: 0.0023 - val_mae: 0.0394\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0477 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0025 - val_mae: 0.0416\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0026 - val_mae: 0.0483\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0458 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0493 - val_loss: 0.0024 - val_mae: 0.0438\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0469 - val_loss: 0.0024 - val_mae: 0.0394\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0452 - val_loss: 0.0023 - val_mae: 0.0389\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0024 - val_mae: 0.0422\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0032 - val_mae: 0.0540\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0465 - val_loss: 0.0023 - val_mae: 0.0389\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0432 - val_loss: 0.0023 - val_mae: 0.0397\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0485 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0441 - val_loss: 0.0026 - val_mae: 0.0491\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0477 - val_loss: 0.0026 - val_mae: 0.0433\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0438 - val_loss: 0.0025 - val_mae: 0.0412\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0451 - val_loss: 0.0025 - val_mae: 0.0411\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0450 - val_loss: 0.0024 - val_mae: 0.0423\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0467 - val_loss: 0.0023 - val_mae: 0.0402\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0023 - val_mae: 0.0386\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0428 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0023 - val_mae: 0.0386\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0483 - val_loss: 0.0051 - val_mae: 0.0812\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0627 - val_loss: 0.0024 - val_mae: 0.0430\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0451 - val_loss: 0.0024 - val_mae: 0.0396\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0024 - val_mae: 0.0399\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0466 - val_loss: 0.0023 - val_mae: 0.0407\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0447 - val_loss: 0.0026 - val_mae: 0.0428\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0033 - val_mae: 0.0559\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0517 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0446 - val_loss: 0.0023 - val_mae: 0.0389\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0441 - val_loss: 0.0023 - val_mae: 0.0416\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0024 - val_mae: 0.0403\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0459 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0438 - val_loss: 0.0023 - val_mae: 0.0391\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0389\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0024 - val_mae: 0.0445\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0025 - val_mae: 0.0405\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0435 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0431 - val_loss: 0.0024 - val_mae: 0.0424\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0441 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0528 - val_loss: 0.0024 - val_mae: 0.0404\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0417 - val_loss: 0.0023 - val_mae: 0.0393\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0441 - val_loss: 0.0023 - val_mae: 0.0407\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0421 - val_loss: 0.0023 - val_mae: 0.0384\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0429 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0024 - val_mae: 0.0402\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0027 - val_mae: 0.0447\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0452 - val_loss: 0.0023 - val_mae: 0.0392\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0451 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0022 - val_mae: 0.0383\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0436 - val_loss: 0.0027 - val_mae: 0.0451\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0455 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0453 - val_loss: 0.0027 - val_mae: 0.0437\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0435 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0393\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0507 - val_loss: 0.0024 - val_mae: 0.0433\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0476 - val_loss: 0.0023 - val_mae: 0.0397\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0024 - val_mae: 0.0393\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0027 - val_mae: 0.0451\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0428 - val_loss: 0.0023 - val_mae: 0.0384\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0452 - val_loss: 0.0024 - val_mae: 0.0447\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0454 - val_loss: 0.0025 - val_mae: 0.0418\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0494 - val_loss: 0.0032 - val_mae: 0.0524\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0491 - val_loss: 0.0024 - val_mae: 0.0416\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0384\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0023 - val_mae: 0.0396\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0435 - val_loss: 0.0030 - val_mae: 0.0491\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0449 - val_loss: 0.0023 - val_mae: 0.0420\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0450 - val_loss: 0.0023 - val_mae: 0.0389\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0461 - val_loss: 0.0030 - val_mae: 0.0499\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0473 - val_loss: 0.0027 - val_mae: 0.0512\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0454 - val_loss: 0.0023 - val_mae: 0.0382\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0450 - val_loss: 0.0027 - val_mae: 0.0435\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0473 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0023 - val_mae: 0.0382\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0536 - val_loss: 0.0036 - val_mae: 0.0601\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0542 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0500 - val_loss: 0.0022 - val_mae: 0.0384\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0026 - val_mae: 0.0431\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0474 - val_loss: 0.0027 - val_mae: 0.0437\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0493 - val_loss: 0.0024 - val_mae: 0.0427\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0465 - val_loss: 0.0028 - val_mae: 0.0470\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0450 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0455 - val_loss: 0.0023 - val_mae: 0.0380\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0458 - val_loss: 0.0025 - val_mae: 0.0414\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0407\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0461 - val_loss: 0.0031 - val_mae: 0.0523\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0508 - val_loss: 0.0023 - val_mae: 0.0378\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0024 - val_mae: 0.0400\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0441 - val_loss: 0.0022 - val_mae: 0.0388\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0480 - val_loss: 0.0022 - val_mae: 0.0378\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0463 - val_loss: 0.0025 - val_mae: 0.0476\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0484 - val_loss: 0.0025 - val_mae: 0.0413\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0486 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0030 - val_mae: 0.0508\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0491 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0488 - val_loss: 0.0022 - val_mae: 0.0382\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0421 - val_loss: 0.0023 - val_mae: 0.0411\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0429 - val_loss: 0.0023 - val_mae: 0.0403\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0452 - val_loss: 0.0023 - val_mae: 0.0399\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0023 - val_mae: 0.0380\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0482 - val_loss: 0.0023 - val_mae: 0.0378\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0468 - val_loss: 0.0030 - val_mae: 0.0569\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0484 - val_loss: 0.0027 - val_mae: 0.0436\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0469 - val_loss: 0.0022 - val_mae: 0.0380\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0433 - val_loss: 0.0023 - val_mae: 0.0378\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0455 - val_loss: 0.0026 - val_mae: 0.0475\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0497 - val_loss: 0.0022 - val_mae: 0.0374\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0029 - val_mae: 0.0491\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0478 - val_loss: 0.0024 - val_mae: 0.0388\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0463 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0430 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0023 - val_mae: 0.0386\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0023 - val_mae: 0.0380\n",
      "Epoch 272/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0432 - val_loss: 0.0024 - val_mae: 0.0395\n",
      "Epoch 273/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0023 - val_mae: 0.0386\n",
      "Epoch 274/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0466 - val_loss: 0.0024 - val_mae: 0.0419\n",
      "Epoch 275/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0434 - val_loss: 0.0024 - val_mae: 0.0396\n",
      "Epoch 276/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0432 - val_loss: 0.0023 - val_mae: 0.0393\n",
      "Epoch 277/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0023 - val_mae: 0.0387\n",
      "Epoch 278/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0499 - val_loss: 0.0026 - val_mae: 0.0424\n",
      "Epoch 279/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0468 - val_loss: 0.0022 - val_mae: 0.0380\n",
      "Epoch 280/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0479 - val_loss: 0.0028 - val_mae: 0.0466\n",
      "Epoch 281/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0460 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 282/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0444 - val_loss: 0.0025 - val_mae: 0.0449\n",
      "Epoch 283/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0023 - val_mae: 0.0404\n",
      "Epoch 284/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0027 - val_mae: 0.0441\n",
      "Epoch 285/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 286/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 287/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0425 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 288/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0469 - val_loss: 0.0022 - val_mae: 0.0384\n",
      "Epoch 289/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0031 - val_mae: 0.0520\n",
      "Epoch 290/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0480 - val_loss: 0.0024 - val_mae: 0.0392\n",
      "Epoch 291/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0445 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 292/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0024 - val_mae: 0.0443\n",
      "Epoch 293/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0025 - val_mae: 0.0466\n",
      "Epoch 294/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0466 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 295/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0023 - val_mae: 0.0411\n",
      "Epoch 296/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0426 - val_loss: 0.0025 - val_mae: 0.0405\n",
      "Epoch 297/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0452 - val_loss: 0.0023 - val_mae: 0.0378\n",
      "Epoch 298/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0023 - val_mae: 0.0384\n",
      "Epoch 299/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0464 - val_loss: 0.0023 - val_mae: 0.0382\n",
      "Epoch 300/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0435 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 301/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0428 - val_loss: 0.0023 - val_mae: 0.0380\n",
      "Epoch 302/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0426 - val_loss: 0.0026 - val_mae: 0.0421\n",
      "Epoch 303/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0026 - val_mae: 0.0489\n",
      "Epoch 304/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0463 - val_loss: 0.0025 - val_mae: 0.0456\n",
      "Epoch 305/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0445 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 306/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0481 - val_loss: 0.0024 - val_mae: 0.0393\n",
      "Epoch 307/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0026 - val_mae: 0.0422\n",
      "Epoch 308/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0442 - val_loss: 0.0027 - val_mae: 0.0444\n",
      "Epoch 309/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0028 - val_mae: 0.0469\n",
      "Epoch 310/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0429 - val_loss: 0.0023 - val_mae: 0.0403\n",
      "Epoch 311/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0455 - val_loss: 0.0022 - val_mae: 0.0386\n",
      "Epoch 312/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0428 - val_loss: 0.0023 - val_mae: 0.0390\n",
      "Epoch 313/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0419 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 314/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0457 - val_loss: 0.0024 - val_mae: 0.0433\n",
      "Epoch 315/500\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0429 - val_loss: 0.0022 - val_mae: 0.0380\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:12:32.887315Z",
     "start_time": "2025-10-10T07:12:32.786256Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(valid_ds)[-1] * 1e6",
   "id": "5c128a8175c5789a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37405.166774988174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用简单的RNN进行预测",
   "id": "3b62b37f911968b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:41:30.854562Z",
     "start_time": "2025-10-10T07:41:30.719153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n"
   ],
   "id": "a8bc86b0ed2ecac3",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Keras中的所有循环层都期望形状为［批量大小、时间步、维度］的三维输入，其中一元时间序列的维度为1，多元时间序列的维度更高。回想一下，input_shape参数忽略了第一个维度（即批量大小），并且由于循环层可以接受任何长度的输入序列，因此可以将第二个维度设置为None，这意味着“任何大小”。\n",
    "\n",
    "最后，由于我们处理的是一元时间序列，因此最后一个维度的大小应为1。这就是我们指定输入形状[None，1]的原因：它表示“任意长度的一元序列”。请注意，数据集实际上包含形状为［批量大小，时间步］的输入，因此缺少最后一个维度（大小为1），但在这种情况下Keras非常友好地为我们添加了它。\n",
    "\n",
    "该模型的工作原理与之前看到RNN的完全一样：初始状态h(init)设置为0，并与第一个时间步的值x(0)一起被传递给单个循环神经元。神经元计算这些值的加权和加上偏置项，并将激活函数（默认情况下使用双曲正切函数(tanh）)应用于结果。结果是第一个输出y0。在简单的RNN中，这个输出也是新的状态h0。这个新状态与下一个输入值x(1)一起被传递到同一个循环神经元，重复上述过程直到最后一个时间步。最后，该层只输出最后一个值：在现在的数据示例中，序列步长为56，所以最后一个值是y55。所有这些都是针对批次中的每个序列（在本例中，每个批次有32个序列）同时执行的。"
   ],
   "id": "ac05f4c4c93cd3cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "注意：Keras中的循环层仅返回最终输出。要使它们在每个时间步返回一个输出，必须设置return_sequences=True\n",
    "\n",
    "这就是第一个应用到训练数据的循环模型！这是一个序列到向量的模型。由于只有一个输出神经元，因此输出向量的大小为1。现在，像之前一样编译、训练和评估这个模型："
   ],
   "id": "55739b71da05e162"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:40:44.710871Z",
     "start_time": "2025-10-10T07:40:44.703177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo： 随堂练习， 编译，训练，并在训练结束后在验证集评估这个模型\n",
    "def fit_and_evaluate(model, learning_rate, train_ds=train_ds, valid_ds=valid_ds):\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_ds, validation_data=valid_ds, epochs=500, callbacks=[early_stopping_cb])\n",
    "\n",
    "    print(\"验证集的误差: \" + str(model.evaluate(valid_ds)[-1] * 1e6))\n"
   ],
   "id": "f2a63f62738f0ed5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T07:42:57.502192Z",
     "start_time": "2025-10-10T07:41:47.268463Z"
    }
   },
   "cell_type": "code",
   "source": "fit_and_evaluate(model, 0.02)",
   "id": "9696a2d1b7298439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 0.0538 - mae: 0.2346 - val_loss: 0.0259 - val_mae: 0.1477\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0173 - mae: 0.1626 - val_loss: 0.0160 - val_mae: 0.1340\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0155 - mae: 0.1567 - val_loss: 0.0156 - val_mae: 0.1370\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.1540 - val_loss: 0.0153 - val_mae: 0.1404\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.1561 - val_loss: 0.0153 - val_mae: 0.1395\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0152 - mae: 0.1552 - val_loss: 0.0153 - val_mae: 0.1380\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.1563 - val_loss: 0.0156 - val_mae: 0.1342\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0151 - mae: 0.1542 - val_loss: 0.0152 - val_mae: 0.1389\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.1524 - val_loss: 0.0149 - val_mae: 0.1428\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.1545 - val_loss: 0.0151 - val_mae: 0.1374\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0148 - mae: 0.1527 - val_loss: 0.0148 - val_mae: 0.1418\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.1531 - val_loss: 0.0151 - val_mae: 0.1368\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.1532 - val_loss: 0.0149 - val_mae: 0.1388\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.1511 - val_loss: 0.0149 - val_mae: 0.1379\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.1517 - val_loss: 0.0147 - val_mae: 0.1399\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.1514 - val_loss: 0.0147 - val_mae: 0.1399\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.1504 - val_loss: 0.0147 - val_mae: 0.1384\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.1514 - val_loss: 0.0148 - val_mae: 0.1361\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.1512 - val_loss: 0.0146 - val_mae: 0.1381\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.1496 - val_loss: 0.0145 - val_mae: 0.1391\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.1503 - val_loss: 0.0146 - val_mae: 0.1363\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.1479 - val_loss: 0.0144 - val_mae: 0.1391\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.1504 - val_loss: 0.0146 - val_mae: 0.1348\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.1489 - val_loss: 0.0144 - val_mae: 0.1366\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.1479 - val_loss: 0.0144 - val_mae: 0.1359\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.1475 - val_loss: 0.0143 - val_mae: 0.1373\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.1484 - val_loss: 0.0144 - val_mae: 0.1333\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.1472 - val_loss: 0.0142 - val_mae: 0.1355\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.1474 - val_loss: 0.0142 - val_mae: 0.1350\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.1463 - val_loss: 0.0142 - val_mae: 0.1347\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.1471 - val_loss: 0.0142 - val_mae: 0.1340\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0139 - mae: 0.1463 - val_loss: 0.0141 - val_mae: 0.1340\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.1455 - val_loss: 0.0140 - val_mae: 0.1345\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.1459 - val_loss: 0.0140 - val_mae: 0.1343\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.1448 - val_loss: 0.0140 - val_mae: 0.1324\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.1457 - val_loss: 0.0140 - val_mae: 0.1317\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.1452 - val_loss: 0.0139 - val_mae: 0.1329\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.1446 - val_loss: 0.0137 - val_mae: 0.1341\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.1437 - val_loss: 0.0139 - val_mae: 0.1301\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.1432 - val_loss: 0.0136 - val_mae: 0.1337\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.1445 - val_loss: 0.0138 - val_mae: 0.1296\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.1419 - val_loss: 0.0137 - val_mae: 0.1305\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.1437 - val_loss: 0.0136 - val_mae: 0.1309\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.1413 - val_loss: 0.0135 - val_mae: 0.1322\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.1431 - val_loss: 0.0135 - val_mae: 0.1306\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.1417 - val_loss: 0.0134 - val_mae: 0.1313\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.1416 - val_loss: 0.0135 - val_mae: 0.1279\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.1415 - val_loss: 0.0133 - val_mae: 0.1310\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.1405 - val_loss: 0.0134 - val_mae: 0.1285\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.1408 - val_loss: 0.0132 - val_mae: 0.1293\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.1404 - val_loss: 0.0133 - val_mae: 0.1271\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.1402 - val_loss: 0.0132 - val_mae: 0.1283\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.1400 - val_loss: 0.0131 - val_mae: 0.1276\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.1392 - val_loss: 0.0131 - val_mae: 0.1281\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.1397 - val_loss: 0.0130 - val_mae: 0.1277\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.1381 - val_loss: 0.0130 - val_mae: 0.1272\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.1386 - val_loss: 0.0130 - val_mae: 0.1262\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.1372 - val_loss: 0.0129 - val_mae: 0.1256\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.1380 - val_loss: 0.0129 - val_mae: 0.1259\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.1379 - val_loss: 0.0129 - val_mae: 0.1242\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.1373 - val_loss: 0.0127 - val_mae: 0.1260\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.1371 - val_loss: 0.0128 - val_mae: 0.1238\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.1359 - val_loss: 0.0127 - val_mae: 0.1241\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.1357 - val_loss: 0.0126 - val_mae: 0.1238\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.1349 - val_loss: 0.0126 - val_mae: 0.1235\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.1367 - val_loss: 0.0125 - val_mae: 0.1233\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.1358 - val_loss: 0.0125 - val_mae: 0.1229\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.1341 - val_loss: 0.0124 - val_mae: 0.1227\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.1346 - val_loss: 0.0124 - val_mae: 0.1223\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.1341 - val_loss: 0.0124 - val_mae: 0.1216\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.1340 - val_loss: 0.0123 - val_mae: 0.1217\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.1331 - val_loss: 0.0123 - val_mae: 0.1210\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.1331 - val_loss: 0.0122 - val_mae: 0.1214\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.1328 - val_loss: 0.0122 - val_mae: 0.1209\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.1320 - val_loss: 0.0121 - val_mae: 0.1209\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.1324 - val_loss: 0.0120 - val_mae: 0.1208\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.1316 - val_loss: 0.0120 - val_mae: 0.1200\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.1315 - val_loss: 0.0120 - val_mae: 0.1201\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.1306 - val_loss: 0.0120 - val_mae: 0.1193\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.1315 - val_loss: 0.0119 - val_mae: 0.1196\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.1304 - val_loss: 0.0118 - val_mae: 0.1193\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.1294 - val_loss: 0.0118 - val_mae: 0.1189\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.1293 - val_loss: 0.0118 - val_mae: 0.1187\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.1298 - val_loss: 0.0117 - val_mae: 0.1189\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.1292 - val_loss: 0.0116 - val_mae: 0.1186\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.1291 - val_loss: 0.0116 - val_mae: 0.1184\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.1277 - val_loss: 0.0116 - val_mae: 0.1178\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.1279 - val_loss: 0.0115 - val_mae: 0.1181\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.1277 - val_loss: 0.0115 - val_mae: 0.1177\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.1277 - val_loss: 0.0114 - val_mae: 0.1175\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.1270 - val_loss: 0.0114 - val_mae: 0.1170\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.1271 - val_loss: 0.0113 - val_mae: 0.1173\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.1266 - val_loss: 0.0113 - val_mae: 0.1164\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.1255 - val_loss: 0.0112 - val_mae: 0.1167\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.1265 - val_loss: 0.0112 - val_mae: 0.1164\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.1254 - val_loss: 0.0112 - val_mae: 0.1158\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.1249 - val_loss: 0.0111 - val_mae: 0.1160\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.1255 - val_loss: 0.0111 - val_mae: 0.1156\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.1242 - val_loss: 0.0111 - val_mae: 0.1151\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.1240 - val_loss: 0.0110 - val_mae: 0.1150\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.1237 - val_loss: 0.0110 - val_mae: 0.1147\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.1235 - val_loss: 0.0109 - val_mae: 0.1147\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.1232 - val_loss: 0.0109 - val_mae: 0.1142\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.1229 - val_loss: 0.0109 - val_mae: 0.1139\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.1231 - val_loss: 0.0108 - val_mae: 0.1138\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.1219 - val_loss: 0.0108 - val_mae: 0.1131\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.1222 - val_loss: 0.0107 - val_mae: 0.1132\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.1217 - val_loss: 0.0107 - val_mae: 0.1126\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.1217 - val_loss: 0.0107 - val_mae: 0.1124\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.1208 - val_loss: 0.0107 - val_mae: 0.1119\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.1205 - val_loss: 0.0107 - val_mae: 0.1116\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.1206 - val_loss: 0.0106 - val_mae: 0.1112\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.1204 - val_loss: 0.0106 - val_mae: 0.1112\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.1198 - val_loss: 0.0106 - val_mae: 0.1107\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.1197 - val_loss: 0.0106 - val_mae: 0.1103\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.1194 - val_loss: 0.0105 - val_mae: 0.1100\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.1187 - val_loss: 0.0105 - val_mae: 0.1096\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.1194 - val_loss: 0.0105 - val_mae: 0.1096\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1186 - val_loss: 0.0105 - val_mae: 0.1089\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1182 - val_loss: 0.0105 - val_mae: 0.1086\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.1178 - val_loss: 0.0104 - val_mae: 0.1085\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1181 - val_loss: 0.0104 - val_mae: 0.1084\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1174 - val_loss: 0.0104 - val_mae: 0.1080\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.1175 - val_loss: 0.0104 - val_mae: 0.1079\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1170 - val_loss: 0.0104 - val_mae: 0.1076\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.1167 - val_loss: 0.0104 - val_mae: 0.1074\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.1172 - val_loss: 0.0103 - val_mae: 0.1073\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1167 - val_loss: 0.0103 - val_mae: 0.1071\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1164 - val_loss: 0.0103 - val_mae: 0.1068\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1162 - val_loss: 0.0103 - val_mae: 0.1066\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1160 - val_loss: 0.0103 - val_mae: 0.1063\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1155 - val_loss: 0.0104 - val_mae: 0.1061\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1158 - val_loss: 0.0103 - val_mae: 0.1061\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1157 - val_loss: 0.0103 - val_mae: 0.1060\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1155 - val_loss: 0.0103 - val_mae: 0.1057\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1152 - val_loss: 0.0103 - val_mae: 0.1055\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1153 - val_loss: 0.0103 - val_mae: 0.1055\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1153 - val_loss: 0.0103 - val_mae: 0.1054\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1148 - val_loss: 0.0103 - val_mae: 0.1051\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1145 - val_loss: 0.0103 - val_mae: 0.1050\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1150 - val_loss: 0.0103 - val_mae: 0.1049\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1148 - val_loss: 0.0103 - val_mae: 0.1049\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1147 - val_loss: 0.0103 - val_mae: 0.1047\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1144 - val_loss: 0.0103 - val_mae: 0.1046\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0103 - val_mae: 0.1045\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1145 - val_loss: 0.0103 - val_mae: 0.1044\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1144 - val_loss: 0.0103 - val_mae: 0.1043\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1143 - val_loss: 0.0103 - val_mae: 0.1043\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0103 - val_mae: 0.1042\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1143 - val_loss: 0.0102 - val_mae: 0.1042\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0103 - val_mae: 0.1041\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0103 - val_mae: 0.1040\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1141 - val_loss: 0.0103 - val_mae: 0.1040\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0103 - val_mae: 0.1039\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0103 - val_mae: 0.1038\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1038\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1140 - val_loss: 0.0103 - val_mae: 0.1037\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1137 - val_loss: 0.0103 - val_mae: 0.1037\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0102 - val_mae: 0.1036\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0102 - val_mae: 0.1037\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1036\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1035\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1035\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1139 - val_loss: 0.0102 - val_mae: 0.1035\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1034\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1034\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1034\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1033\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1034\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1033\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0103 - val_mae: 0.1033\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1033\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1136 - val_loss: 0.0103 - val_mae: 0.1032\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1134 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1033\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0103 - val_mae: 0.1031\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1031\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1033\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1032\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1030\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1132 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 272/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1135 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 273/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1129 - val_loss: 0.0102 - val_mae: 0.1029\n",
      "Epoch 274/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 275/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 276/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 277/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 278/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 279/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 280/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 281/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 282/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.1130 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 283/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1133 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 284/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1029\n",
      "Epoch 285/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1131 - val_loss: 0.0102 - val_mae: 0.1030\n",
      "Epoch 286/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "Epoch 287/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.1128 - val_loss: 0.0103 - val_mae: 0.1028\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0103 - mae: 0.1028\n",
      "验证集的误差: 102789.93844985962\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "它的验证MAE大于100000！这是意料之中的，原因有二：\n",
    "1. 该模型只有一个循环神经元，因此它在每个时间步可以用来进行预测的唯一数据是当前时间步的输入值和前一个时间步的输出值。换句话说，RNN的记忆极其有限：它只记忆一个数字，即它之前的输出。让我们数一数这个模型有多少个参数：因为该循环神经元只有2个输入值，所以整个模型只有3个参数（2个权重加上1个偏置项）。对于这个时间序列来说，这还远远不够。相比之下，我们之前的模型可以一次查看56个先前的值，它总共有57个参数。\n",
    "2. 时间序列包含从0到大约1.4的值，但由于默认激活函数是tanh，因此循环层只能输出-1到+1之间的值。它无法预测1.0到1.4之间的值。让我们来解决这两个问题：我们将创建一个具有更大循环层（包含32个循环神经元）的模型，并在其顶部添加一个密集输出层（具有一个输出神经元且没有激活函数）。循环层能够将更多信息从一个时间步携带到下一个时间步，密集输出层将最终输出从32维投影到一维，没有任何值范围限制："
   ],
   "id": "c5d19a1bddf5644a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T08:11:08.988184Z",
     "start_time": "2025-10-10T08:10:03.855957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# todo: 随堂练习，用这个解决方案搭建模型，并编译，训练，在训练结束后在验证集评估这个模型，\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "fit_and_evaluate(model, 0.02)"
   ],
   "id": "583a1404806c6038",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 0.0285 - mae: 0.1757 - val_loss: 0.0046 - val_mae: 0.0732\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0741 - val_loss: 0.0033 - val_mae: 0.0572\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0646 - val_loss: 0.0027 - val_mae: 0.0523\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0604 - val_loss: 0.0029 - val_mae: 0.0531\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0025 - val_mae: 0.0488\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0558 - val_loss: 0.0024 - val_mae: 0.0477\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0545 - val_loss: 0.0024 - val_mae: 0.0475\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0545 - val_loss: 0.0022 - val_mae: 0.0410\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0528 - val_loss: 0.0020 - val_mae: 0.0410\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - mae: 0.0511 - val_loss: 0.0025 - val_mae: 0.0440\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0493 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0483 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - mae: 0.0519 - val_loss: 0.0021 - val_mae: 0.0349\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0482 - val_loss: 0.0026 - val_mae: 0.0443\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0448 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0456 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0486 - val_loss: 0.0022 - val_mae: 0.0433\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0461 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0446 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0445 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0029 - mae: 0.0458 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0473 - val_loss: 0.0020 - val_mae: 0.0342\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0451 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0439 - val_loss: 0.0021 - val_mae: 0.0354\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0449 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0464 - val_loss: 0.0018 - val_mae: 0.0307\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0026 - mae: 0.0432 - val_loss: 0.0019 - val_mae: 0.0312\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0442 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0467 - val_loss: 0.0023 - val_mae: 0.0361\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0441 - val_loss: 0.0021 - val_mae: 0.0340\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0440 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0422 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0434 - val_loss: 0.0020 - val_mae: 0.0311\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0447 - val_loss: 0.0020 - val_mae: 0.0372\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0422 - val_loss: 0.0018 - val_mae: 0.0306\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0460 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0451 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0424 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0430 - val_loss: 0.0021 - val_mae: 0.0409\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0440 - val_loss: 0.0021 - val_mae: 0.0345\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0428 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0338\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0419 - val_loss: 0.0021 - val_mae: 0.0358\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0426 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0425 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0442 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0300\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0453 - val_loss: 0.0023 - val_mae: 0.0406\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0444 - val_loss: 0.0021 - val_mae: 0.0338\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0413 - val_loss: 0.0019 - val_mae: 0.0304\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0418 - val_loss: 0.0020 - val_mae: 0.0360\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0436 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 0.0018 - val_mae: 0.0307\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0408 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0421 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0026 - mae: 0.0423 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0025 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0026 - mae: 0.0420 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0417 - val_loss: 0.0022 - val_mae: 0.0411\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0424 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0443 - val_loss: 0.0019 - val_mae: 0.0304\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0401 - val_loss: 0.0021 - val_mae: 0.0369\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0418 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0439 - val_loss: 0.0021 - val_mae: 0.0367\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0431 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0423 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0426 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0423 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0417 - val_loss: 0.0018 - val_mae: 0.0324\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0408 - val_loss: 0.0018 - val_mae: 0.0295\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0430 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0410 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0407 - val_loss: 0.0018 - val_mae: 0.0306\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0409 - val_loss: 0.0021 - val_mae: 0.0394\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0449 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0411 - val_loss: 0.0018 - val_mae: 0.0308\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0434 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0416 - val_loss: 0.0018 - val_mae: 0.0302\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0409 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0408 - val_loss: 0.0018 - val_mae: 0.0324\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0425 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0433 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0404 - val_loss: 0.0020 - val_mae: 0.0370\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 0.0018 - val_mae: 0.0305\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0350\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0429 - val_loss: 0.0019 - val_mae: 0.0310\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0407 - val_loss: 0.0020 - val_mae: 0.0370\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0410 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0394 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0018 - val_mae: 0.0307\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0392 - val_loss: 0.0022 - val_mae: 0.0418\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0425 - val_loss: 0.0021 - val_mae: 0.0384\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0417 - val_loss: 0.0020 - val_mae: 0.0353\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0410 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0020 - val_mae: 0.0358\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0417 - val_loss: 0.0020 - val_mae: 0.0343\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0410 - val_loss: 0.0021 - val_mae: 0.0414\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0020 - val_mae: 0.0377\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0025 - mae: 0.0401 - val_loss: 0.0020 - val_mae: 0.0370\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0020 - val_mae: 0.0359\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0022 - val_mae: 0.0388\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0404 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0311\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0435 - val_loss: 0.0020 - val_mae: 0.0368\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0409 - val_loss: 0.0017 - val_mae: 0.0314\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0392 - val_loss: 0.0020 - val_mae: 0.0347\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0021 - val_mae: 0.0382\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0404 - val_loss: 0.0018 - val_mae: 0.0330\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0420 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0409 - val_loss: 0.0019 - val_mae: 0.0367\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0392 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0417 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0402 - val_loss: 0.0017 - val_mae: 0.0292\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0393 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0394 - val_loss: 0.0018 - val_mae: 0.0332\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0382 - val_loss: 0.0018 - val_mae: 0.0343\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0404 - val_loss: 0.0018 - val_mae: 0.0311\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0427 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0439 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0408 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0020 - val_mae: 0.0365\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0410 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0419 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0398 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0411 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0020 - val_mae: 0.0364\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0018 - val_mae: 0.0332\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0404 - val_loss: 0.0021 - val_mae: 0.0358\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0400 - val_loss: 0.0019 - val_mae: 0.0340\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0388 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0403 - val_loss: 0.0018 - val_mae: 0.0305\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0404 - val_loss: 0.0020 - val_mae: 0.0362\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0328\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0018 - val_mae: 0.0347\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0386 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0407 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0406 - val_loss: 0.0017 - val_mae: 0.0315\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0018 - val_mae: 0.0306\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0378 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0393 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0379 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0388 - val_loss: 0.0017 - val_mae: 0.0316\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0387 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0378 - val_loss: 0.0017 - val_mae: 0.0315\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0426 - val_loss: 0.0019 - val_mae: 0.0352\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0392 - val_loss: 0.0017 - val_mae: 0.0291\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0386 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0399 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0379 - val_loss: 0.0018 - val_mae: 0.0314\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0393 - val_loss: 0.0017 - val_mae: 0.0288\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0018 - val_mae: 0.0304\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0402 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0383 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0394 - val_loss: 0.0017 - val_mae: 0.0288\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0017 - val_mae: 0.0319\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0382 - val_loss: 0.0018 - val_mae: 0.0323\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0404 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0387 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0408 - val_loss: 0.0019 - val_mae: 0.0369\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0407 - val_loss: 0.0017 - val_mae: 0.0289\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0361\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0017 - val_mae: 0.0282\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0381 - val_loss: 0.0017 - val_mae: 0.0316\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 0.0019 - val_mae: 0.0373\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0402 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0017 - val_mae: 0.0292\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0017 - val_mae: 0.0318\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0388 - val_loss: 0.0020 - val_mae: 0.0343\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0020 - val_mae: 0.0365\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0412 - val_loss: 0.0020 - val_mae: 0.0341\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0388 - val_loss: 0.0020 - val_mae: 0.0382\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0018 - val_mae: 0.0330\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0386 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0383 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0378 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0023 - mae: 0.0409 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0384 - val_loss: 0.0017 - val_mae: 0.0299\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0388 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0018 - val_mae: 0.0331\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0378 - val_loss: 0.0019 - val_mae: 0.0365\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0383 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0377 - val_loss: 0.0018 - val_mae: 0.0332\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0377 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0375 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0380 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0379 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0384 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0400 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 0.0019 - val_mae: 0.0352\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0401 - val_loss: 0.0019 - val_mae: 0.0358\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0397 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0374 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0377 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0376 - val_loss: 0.0018 - val_mae: 0.0311\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0387 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0017 - val_mae: 0.0284\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 0.0017 - val_mae: 0.0319\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0391 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0413 - val_loss: 0.0018 - val_mae: 0.0356\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0395 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0387 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0398 - val_loss: 0.0017 - val_mae: 0.0300\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0382 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0282\n",
      "验证集的误差: 28161.155059933662\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T08:11:12.297378Z",
     "start_time": "2025-10-10T08:11:12.102356Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(valid_ds.take(1)).shape",
   "id": "fa469b6fac22c70f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "会发现它的验证MAE击败了朴素预测和线性回归，是迄今训练过的最好模型",
   "id": "916dd685c3b551f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用深度RNN进行预测",
   "id": "1f974f61a79e53ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "堆叠多层单元可以产生深度RNN\n",
    "\n",
    "![深度RNN随时间展开](./images/RNN/p4.png)\n",
    "\n",
    "使用Keras实现深度RNN非常简单：只需堆叠循环层即可。在下面的示例中，使用3个SimpleRNN层,前两个是序列到序列的层，最后一个是序列到向量的层。最后，Dense层（可以将其视为向量到向量的层）生成模型的预测值。所以，这个模型就像图中表示的模型一样，只不过输出Ŷ(0)到Ŷ(t-1)被忽略，并且在Ŷ(t)之上有一个密集层，它输出实际的预测值："
   ],
   "id": "3ffecb8d3db33645"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T08:58:15.770663Z",
     "start_time": "2025-10-10T08:58:15.588901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ],
   "id": "26a65802af3a3476",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "确保为所有循环层设置return_sequences=True（最后一层除外）。如果你忘记为某个循环层设置此参数，它将输出一个仅包含最后一个时间步的输出的二维数组，而不是包含所有时间步的输出的三维数组。下一个循环层会报错：没有以预期的三维格式为其提供序列。\n",
    "\n",
    "如果训练并评估这个模型，它并没有打败“较浅”的RNN。看起来这个RNN对于我们的任务来说有点太大了。"
   ],
   "id": "7b098862a97daa90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:00:02.593693Z",
     "start_time": "2025-10-10T08:58:46.636613Z"
    }
   },
   "cell_type": "code",
   "source": "fit_and_evaluate(deep_model, 0.02)",
   "id": "4cb691a17b46d209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 3s 26ms/step - loss: 0.0152 - mae: 0.1402 - val_loss: 0.0030 - val_mae: 0.0575\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0052 - mae: 0.0707 - val_loss: 0.0023 - val_mae: 0.0457\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0049 - mae: 0.0663 - val_loss: 0.0022 - val_mae: 0.0405\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0046 - mae: 0.0640 - val_loss: 0.0035 - val_mae: 0.0647\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0055 - mae: 0.0757 - val_loss: 0.0042 - val_mae: 0.0710\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0048 - mae: 0.0684 - val_loss: 0.0021 - val_mae: 0.0403\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.0046 - mae: 0.0669 - val_loss: 0.0058 - val_mae: 0.0902\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0039 - mae: 0.0566 - val_loss: 0.0022 - val_mae: 0.0390\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0040 - mae: 0.0594 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0037 - mae: 0.0566 - val_loss: 0.0022 - val_mae: 0.0389\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0041 - mae: 0.0617 - val_loss: 0.0034 - val_mae: 0.0587\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0036 - mae: 0.0559 - val_loss: 0.0026 - val_mae: 0.0491\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0036 - mae: 0.0559 - val_loss: 0.0024 - val_mae: 0.0458\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0036 - mae: 0.0565 - val_loss: 0.0021 - val_mae: 0.0367\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0510 - val_loss: 0.0038 - val_mae: 0.0656\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0531 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0509 - val_loss: 0.0025 - val_mae: 0.0495\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0518 - val_loss: 0.0021 - val_mae: 0.0361\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0496 - val_loss: 0.0022 - val_mae: 0.0372\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0499 - val_loss: 0.0028 - val_mae: 0.0478\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0034 - mae: 0.0554 - val_loss: 0.0022 - val_mae: 0.0373\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0035 - mae: 0.0565 - val_loss: 0.0021 - val_mae: 0.0363\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0501 - val_loss: 0.0023 - val_mae: 0.0413\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0524 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0456 - val_loss: 0.0020 - val_mae: 0.0358\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0032 - mae: 0.0526 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0526 - val_loss: 0.0032 - val_mae: 0.0614\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0031 - mae: 0.0503 - val_loss: 0.0028 - val_mae: 0.0531\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0543 - val_loss: 0.0023 - val_mae: 0.0436\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0504 - val_loss: 0.0020 - val_mae: 0.0353\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0471 - val_loss: 0.0023 - val_mae: 0.0437\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0029 - mae: 0.0480 - val_loss: 0.0023 - val_mae: 0.0405\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0033 - mae: 0.0544 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - mae: 0.0528 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0501 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0027 - mae: 0.0458 - val_loss: 0.0025 - val_mae: 0.0453\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0499 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0029 - mae: 0.0486 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0026 - mae: 0.0433 - val_loss: 0.0026 - val_mae: 0.0523\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0035 - mae: 0.0583 - val_loss: 0.0042 - val_mae: 0.0758\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0035 - mae: 0.0593 - val_loss: 0.0051 - val_mae: 0.0842\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0032 - mae: 0.0529 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0027 - mae: 0.0448 - val_loss: 0.0019 - val_mae: 0.0364\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0027 - mae: 0.0469 - val_loss: 0.0020 - val_mae: 0.0384\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0025 - mae: 0.0427 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0502 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0027 - mae: 0.0471 - val_loss: 0.0020 - val_mae: 0.0370\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0026 - mae: 0.0446 - val_loss: 0.0020 - val_mae: 0.0363\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0448 - val_loss: 0.0019 - val_mae: 0.0365\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0025 - mae: 0.0422 - val_loss: 0.0020 - val_mae: 0.0397\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0027 - mae: 0.0469 - val_loss: 0.0029 - val_mae: 0.0562\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0524 - val_loss: 0.0018 - val_mae: 0.0358\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0025 - mae: 0.0414 - val_loss: 0.0018 - val_mae: 0.0332\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0432 - val_loss: 0.0020 - val_mae: 0.0396\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0027 - mae: 0.0480 - val_loss: 0.0021 - val_mae: 0.0381\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0480 - val_loss: 0.0025 - val_mae: 0.0474\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0434 - val_loss: 0.0021 - val_mae: 0.0397\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0358\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0495 - val_loss: 0.0025 - val_mae: 0.0479\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0483 - val_loss: 0.0018 - val_mae: 0.0331\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0026 - mae: 0.0452 - val_loss: 0.0025 - val_mae: 0.0503\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0028 - mae: 0.0488 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0407\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0025 - mae: 0.0440 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0426 - val_loss: 0.0023 - val_mae: 0.0453\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0419 - val_loss: 0.0023 - val_mae: 0.0436\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0430 - val_loss: 0.0019 - val_mae: 0.0355\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0440 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0443 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0030 - mae: 0.0510 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0423 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0422 - val_loss: 0.0020 - val_mae: 0.0397\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0409 - val_loss: 0.0018 - val_mae: 0.0360\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0412 - val_loss: 0.0020 - val_mae: 0.0399\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0453 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0429 - val_loss: 0.0019 - val_mae: 0.0385\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0375\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0448 - val_loss: 0.0036 - val_mae: 0.0651\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0027 - mae: 0.0469 - val_loss: 0.0018 - val_mae: 0.0357\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0411 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0023 - mae: 0.0416 - val_loss: 0.0018 - val_mae: 0.0348\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0023 - mae: 0.0424 - val_loss: 0.0018 - val_mae: 0.0329\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0024 - mae: 0.0426 - val_loss: 0.0018 - val_mae: 0.0357\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0025 - mae: 0.0443 - val_loss: 0.0019 - val_mae: 0.0391\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0026 - mae: 0.0482 - val_loss: 0.0024 - val_mae: 0.0439\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0434 - val_loss: 0.0018 - val_mae: 0.0345\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0403 - val_loss: 0.0020 - val_mae: 0.0378\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0425 - val_loss: 0.0020 - val_mae: 0.0395\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0413 - val_loss: 0.0018 - val_mae: 0.0353\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0441 - val_loss: 0.0025 - val_mae: 0.0498\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0440 - val_loss: 0.0019 - val_mae: 0.0383\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0426 - val_loss: 0.0018 - val_mae: 0.0363\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0447 - val_loss: 0.0020 - val_mae: 0.0416\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0407 - val_loss: 0.0019 - val_mae: 0.0392\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0419 - val_loss: 0.0020 - val_mae: 0.0403\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0409 - val_loss: 0.0017 - val_mae: 0.0341\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0409 - val_loss: 0.0019 - val_mae: 0.0375\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0433 - val_loss: 0.0018 - val_mae: 0.0343\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0409 - val_loss: 0.0019 - val_mae: 0.0372\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0433 - val_loss: 0.0018 - val_mae: 0.0349\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0407 - val_loss: 0.0018 - val_mae: 0.0328\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0432 - val_loss: 0.0027 - val_mae: 0.0550\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0024 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0366\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0408 - val_loss: 0.0021 - val_mae: 0.0412\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0426 - val_loss: 0.0018 - val_mae: 0.0376\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0023 - mae: 0.0422 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0022 - mae: 0.0401 - val_loss: 0.0021 - val_mae: 0.0420\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0017 - val_mae: 0.0334\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0021 - mae: 0.0380 - val_loss: 0.0018 - val_mae: 0.0377\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0409 - val_loss: 0.0019 - val_mae: 0.0398\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0403 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0021 - mae: 0.0391 - val_loss: 0.0017 - val_mae: 0.0341\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0022 - mae: 0.0392 - val_loss: 0.0020 - val_mae: 0.0375\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0431 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0022 - mae: 0.0410 - val_loss: 0.0018 - val_mae: 0.0360\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0021 - mae: 0.0390 - val_loss: 0.0018 - val_mae: 0.0346\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0023 - mae: 0.0437 - val_loss: 0.0019 - val_mae: 0.0367\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0024 - mae: 0.0430 - val_loss: 0.0019 - val_mae: 0.0367\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0022 - mae: 0.0402 - val_loss: 0.0018 - val_mae: 0.0367\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0396 - val_loss: 0.0019 - val_mae: 0.0390\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0025 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0443\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0022 - mae: 0.0410 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0025 - mae: 0.0454 - val_loss: 0.0019 - val_mae: 0.0390\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0403 - val_loss: 0.0020 - val_mae: 0.0409\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0406 - val_loss: 0.0018 - val_mae: 0.0344\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0023 - mae: 0.0417 - val_loss: 0.0017 - val_mae: 0.0348\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0400 - val_loss: 0.0018 - val_mae: 0.0353\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0021 - mae: 0.0404 - val_loss: 0.0018 - val_mae: 0.0359\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0026 - mae: 0.0476 - val_loss: 0.0019 - val_mae: 0.0399\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0022 - mae: 0.0397 - val_loss: 0.0021 - val_mae: 0.0449\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0017 - mae: 0.0305\n",
      "验证集的误差: 30527.882277965546\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T04:24:05.576112Z",
     "start_time": "2025-10-08T04:24:05.470917Z"
    }
   },
   "cell_type": "code",
   "source": "deep_model.evaluate(valid_ds)",
   "id": "48c7a48191e895fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0017 - mae: 0.0301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0017450390150770545, 0.030073534697294235]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 多元时间序列预测",
   "id": "a84bc663ef14d20d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "神经网络的一大优点是它们非常灵活，特别是，它们可以处理多元时间序列而几乎无须改变它们的架构。例如，尝试使用公共汽车和铁路数据作为输入来预测铁路时间序列。事实上，还可以加入日期类型，由于可以提前知道明天是工作日、周末还是假期，因们可以将日期类型序列偏移一天，这样模型就可以将“明天”的日期类型作为输入了。为了简单起见，将使用Pandas进行此处理：",
   "id": "1d2d248e8651594c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:05:12.563105Z",
     "start_time": "2025-10-10T09:05:12.460541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6\n",
    "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)\n",
    "df_mulvar\n",
    "\n",
    "df_mulvar = pd.get_dummies(df_mulvar, dtype=float)\n",
    "df_mulvar"
   ],
   "id": "d3d33133d2a75e37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 bus      rail  next_day_type_A  next_day_type_U  \\\n",
       "date                                                               \n",
       "2001-01-01  0.297192  0.126455              0.0              0.0   \n",
       "2001-01-02  0.780827  0.501952              0.0              0.0   \n",
       "2001-01-03  0.824923  0.536432              0.0              0.0   \n",
       "2001-01-04  0.870021  0.550011              0.0              0.0   \n",
       "2001-01-05  0.890426  0.557917              1.0              0.0   \n",
       "...              ...       ...              ...              ...   \n",
       "2021-11-26  0.257700  0.189694              1.0              0.0   \n",
       "2021-11-27  0.237839  0.187065              0.0              1.0   \n",
       "2021-11-28  0.184817  0.147830              0.0              0.0   \n",
       "2021-11-29  0.421322  0.276090              0.0              0.0   \n",
       "2021-11-30  0.450230  0.302349              0.0              0.0   \n",
       "\n",
       "            next_day_type_W  \n",
       "date                         \n",
       "2001-01-01              1.0  \n",
       "2001-01-02              1.0  \n",
       "2001-01-03              1.0  \n",
       "2001-01-04              1.0  \n",
       "2001-01-05              0.0  \n",
       "...                     ...  \n",
       "2021-11-26              0.0  \n",
       "2021-11-27              0.0  \n",
       "2021-11-28              1.0  \n",
       "2021-11-29              1.0  \n",
       "2021-11-30              0.0  \n",
       "\n",
       "[7639 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bus</th>\n",
       "      <th>rail</th>\n",
       "      <th>next_day_type_A</th>\n",
       "      <th>next_day_type_U</th>\n",
       "      <th>next_day_type_W</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.297192</td>\n",
       "      <td>0.126455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>0.780827</td>\n",
       "      <td>0.501952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>0.824923</td>\n",
       "      <td>0.536432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>0.870021</td>\n",
       "      <td>0.550011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>0.890426</td>\n",
       "      <td>0.557917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-26</th>\n",
       "      <td>0.257700</td>\n",
       "      <td>0.189694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-27</th>\n",
       "      <td>0.237839</td>\n",
       "      <td>0.187065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-28</th>\n",
       "      <td>0.184817</td>\n",
       "      <td>0.147830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29</th>\n",
       "      <td>0.421322</td>\n",
       "      <td>0.276090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>0.450230</td>\n",
       "      <td>0.302349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7639 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在df_mulvar是一个包含5列的DataFrame，这5列分别是公共汽车数据列、铁路数据列，以及包含第二天类型的独热编码的3列（有3种可能的日期类型W、A和U）。接下来可以重复之前的操作。首先，将数据分成训练、验证和测试：",
   "id": "a15fc79638814b40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:08:25.158159Z",
     "start_time": "2025-10-10T09:08:25.145581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
    "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
    "mulvar_test = df_mulvar[\"2019-06\":]"
   ],
   "id": "ff2728ec859c86b7",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:09:47.584710Z",
     "start_time": "2025-10-10T09:09:47.439970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),  # 使用5列作为输入\n",
    "    targets=mulvar_train[\"rail\"][seq_length:],  # 只预测铁路序列\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=mulvar_valid[\"rail\"][seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ],
   "id": "68c5ecaad0306337",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:09:59.245398Z",
     "start_time": "2025-10-10T09:09:59.139045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "mulvar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ],
   "id": "5e16e0a080123b62",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:11:54.923269Z",
     "start_time": "2025-10-10T09:10:59.261647Z"
    }
   },
   "cell_type": "code",
   "source": "fit_and_evaluate(mulvar_model, 0.02, train_ds = train_mulvar_ds, valid_ds = valid_mulvar_ds)",
   "id": "af6bf43188629f14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0572 - mae: 0.2551 - val_loss: 0.0034 - val_mae: 0.0601\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0664 - val_loss: 0.0014 - val_mae: 0.0376\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0024 - mae: 0.0472 - val_loss: 0.0015 - val_mae: 0.0433\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0438 - val_loss: 0.0019 - val_mae: 0.0517\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0018 - mae: 0.0411 - val_loss: 0.0012 - val_mae: 0.0380\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0017 - mae: 0.0402 - val_loss: 0.0015 - val_mae: 0.0465\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0017 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0378\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.0013 - val_mae: 0.0431\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0015 - mae: 0.0376 - val_loss: 0.0010 - val_mae: 0.0356\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0375 - val_loss: 0.0012 - val_mae: 0.0398\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0014 - mae: 0.0370 - val_loss: 0.0017 - val_mae: 0.0501\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 9.9767e-04 - val_mae: 0.0355\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 6.9023e-04 - val_mae: 0.0272\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0363 - val_loss: 0.0013 - val_mae: 0.0422\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0368 - val_loss: 0.0012 - val_mae: 0.0398\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0356 - val_loss: 9.0558e-04 - val_mae: 0.0329\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 0.0014 - val_mae: 0.0448\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0014 - mae: 0.0372 - val_loss: 0.0020 - val_mae: 0.0561\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 8.2707e-04 - val_mae: 0.0307\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0344 - val_loss: 7.9922e-04 - val_mae: 0.0303\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0344 - val_loss: 8.7194e-04 - val_mae: 0.0316\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0348 - val_loss: 9.8270e-04 - val_mae: 0.0346\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0339 - val_loss: 9.4930e-04 - val_mae: 0.0335\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0350 - val_loss: 0.0012 - val_mae: 0.0393\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0338 - val_loss: 0.0011 - val_mae: 0.0390\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0354 - val_loss: 9.4244e-04 - val_mae: 0.0335\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0336 - val_loss: 8.1029e-04 - val_mae: 0.0296\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0337 - val_loss: 7.8813e-04 - val_mae: 0.0277\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 7.2925e-04 - val_mae: 0.0278\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0333 - val_loss: 8.1027e-04 - val_mae: 0.0290\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0335 - val_loss: 9.4937e-04 - val_mae: 0.0335\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0339 - val_loss: 7.1895e-04 - val_mae: 0.0266\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 9.4919e-04 - val_mae: 0.0332\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0334 - val_loss: 7.4529e-04 - val_mae: 0.0274\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 8.3672e-04 - val_mae: 0.0309\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 7.8481e-04 - val_mae: 0.0285\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0345 - val_loss: 6.8763e-04 - val_mae: 0.0257\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 7.5087e-04 - val_mae: 0.0273\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0320 - val_loss: 9.5915e-04 - val_mae: 0.0336\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0346\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 0.0012 - val_mae: 0.0406\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0330 - val_loss: 8.2280e-04 - val_mae: 0.0301\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0327 - val_loss: 0.0012 - val_mae: 0.0404\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 7.5562e-04 - val_mae: 0.0273\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0324 - val_loss: 9.0539e-04 - val_mae: 0.0320\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0335 - val_loss: 6.7643e-04 - val_mae: 0.0256\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 6.8016e-04 - val_mae: 0.0259\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 8.3211e-04 - val_mae: 0.0300\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 7.0000e-04 - val_mae: 0.0257\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0340 - val_loss: 0.0013 - val_mae: 0.0425\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 7.0003e-04 - val_mae: 0.0264\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 9.1473e-04 - val_mae: 0.0318\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0323 - val_loss: 7.4018e-04 - val_mae: 0.0269\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0314 - val_loss: 6.8750e-04 - val_mae: 0.0259\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0324 - val_loss: 9.5274e-04 - val_mae: 0.0334\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 6.6979e-04 - val_mae: 0.0254\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0331 - val_loss: 8.1137e-04 - val_mae: 0.0295\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 6.4121e-04 - val_mae: 0.0248\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0316 - val_loss: 8.5375e-04 - val_mae: 0.0307\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0315 - val_loss: 7.4962e-04 - val_mae: 0.0279\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0308 - val_loss: 8.6127e-04 - val_mae: 0.0308\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0325 - val_loss: 8.8533e-04 - val_mae: 0.0314\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 6.9016e-04 - val_mae: 0.0261\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0309 - val_loss: 9.0050e-04 - val_mae: 0.0323\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0315 - val_loss: 7.1456e-04 - val_mae: 0.0263\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 7.4955e-04 - val_mae: 0.0278\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0304 - val_loss: 7.5104e-04 - val_mae: 0.0281\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0301 - val_loss: 6.9000e-04 - val_mae: 0.0264\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0297 - val_loss: 7.7725e-04 - val_mae: 0.0279\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0303 - val_loss: 8.3283e-04 - val_mae: 0.0298\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0305 - val_loss: 9.7514e-04 - val_mae: 0.0345\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0343 - val_loss: 8.9833e-04 - val_mae: 0.0316\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0355 - val_loss: 8.8428e-04 - val_mae: 0.0306\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0345 - val_loss: 7.0946e-04 - val_mae: 0.0259\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0310 - val_loss: 6.8328e-04 - val_mae: 0.0257\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8986e-04 - mae: 0.0294 - val_loss: 6.6016e-04 - val_mae: 0.0249\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 0.0012 - val_mae: 0.0391\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 7.6361e-04 - val_mae: 0.0279\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 7.5438e-04 - val_mae: 0.0271\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.9540e-04 - mae: 0.0297 - val_loss: 7.0917e-04 - val_mae: 0.0264\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0313 - val_loss: 8.4754e-04 - val_mae: 0.0303\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0319 - val_loss: 6.3775e-04 - val_mae: 0.0244\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0373\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.9764e-04 - mae: 0.0301 - val_loss: 7.1905e-04 - val_mae: 0.0269\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0299 - val_loss: 6.8112e-04 - val_mae: 0.0255\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0302 - val_loss: 6.7121e-04 - val_mae: 0.0252\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0356\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0307 - val_loss: 7.0139e-04 - val_mae: 0.0258\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9939e-04 - mae: 0.0300 - val_loss: 7.3033e-04 - val_mae: 0.0273\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.6799e-04 - mae: 0.0289 - val_loss: 8.6428e-04 - val_mae: 0.0310\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8355e-04 - mae: 0.0295 - val_loss: 9.3111e-04 - val_mae: 0.0321\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8032e-04 - mae: 0.0294 - val_loss: 6.8487e-04 - val_mae: 0.0252\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.6505e-04 - mae: 0.0291 - val_loss: 7.1690e-04 - val_mae: 0.0263\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.6341e-04 - mae: 0.0292 - val_loss: 7.7159e-04 - val_mae: 0.0284\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8456e-04 - mae: 0.0293 - val_loss: 6.5157e-04 - val_mae: 0.0245\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0304 - val_loss: 6.7094e-04 - val_mae: 0.0250\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.9150e-04 - mae: 0.0299 - val_loss: 8.3360e-04 - val_mae: 0.0304\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0326 - val_loss: 9.3558e-04 - val_mae: 0.0324\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0312 - val_loss: 6.7174e-04 - val_mae: 0.0256\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0303 - val_loss: 8.3853e-04 - val_mae: 0.0296\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.9556e-04 - mae: 0.0303 - val_loss: 7.5681e-04 - val_mae: 0.0279\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0302 - val_loss: 7.2871e-04 - val_mae: 0.0269\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 9.8480e-04 - mae: 0.0290 - val_loss: 7.2637e-04 - val_mae: 0.0272\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0010 - mae: 0.0312 - val_loss: 6.7704e-04 - val_mae: 0.0267\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0329 - val_loss: 7.4283e-04 - val_mae: 0.0280\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8264e-04 - mae: 0.0298 - val_loss: 7.1450e-04 - val_mae: 0.0264\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.3393e-04 - mae: 0.0283 - val_loss: 6.9639e-04 - val_mae: 0.0269\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.6570e-04 - mae: 0.0294 - val_loss: 6.5210e-04 - val_mae: 0.0251\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.5748e-04 - mae: 0.0285 - val_loss: 7.9744e-04 - val_mae: 0.0289\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0303 - val_loss: 7.6992e-04 - val_mae: 0.0279\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0299 - val_loss: 6.6884e-04 - val_mae: 0.0253\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0306 - val_loss: 8.1018e-04 - val_mae: 0.0299\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.9591e-04 - mae: 0.0292 - val_loss: 6.7815e-04 - val_mae: 0.0252\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.3106e-04 - mae: 0.0285 - val_loss: 7.5398e-04 - val_mae: 0.0281\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.5424e-04 - mae: 0.0289 - val_loss: 7.9622e-04 - val_mae: 0.0291\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8685e-04 - mae: 0.0304 - val_loss: 7.2914e-04 - val_mae: 0.0273\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7901e-04 - mae: 0.0300 - val_loss: 6.5857e-04 - val_mae: 0.0250\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7395e-04 - mae: 0.0301 - val_loss: 7.5004e-04 - val_mae: 0.0283\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9748e-04 - mae: 0.0304 - val_loss: 8.3880e-04 - val_mae: 0.0307\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4750e-04 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0365\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7851e-04 - mae: 0.0294 - val_loss: 6.7268e-04 - val_mae: 0.0251\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4339e-04 - mae: 0.0284 - val_loss: 9.3246e-04 - val_mae: 0.0337\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0305 - val_loss: 6.5427e-04 - val_mae: 0.0249\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8924e-04 - mae: 0.0302 - val_loss: 8.6375e-04 - val_mae: 0.0313\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.8612e-04 - mae: 0.0303 - val_loss: 6.3252e-04 - val_mae: 0.0242\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.2160e-04 - mae: 0.0282 - val_loss: 7.3947e-04 - val_mae: 0.0275\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3551e-04 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0370\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0308 - val_loss: 9.2993e-04 - val_mae: 0.0318\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0305 - val_loss: 8.1034e-04 - val_mae: 0.0295\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.7798e-04 - mae: 0.0298 - val_loss: 7.8893e-04 - val_mae: 0.0289\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.6138e-04 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0365\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9045e-04 - mae: 0.0296 - val_loss: 6.8870e-04 - val_mae: 0.0263\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3566e-04 - mae: 0.0288 - val_loss: 6.6038e-04 - val_mae: 0.0256\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.6714e-04 - mae: 0.0302 - val_loss: 6.8226e-04 - val_mae: 0.0257\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1727e-04 - mae: 0.0278 - val_loss: 6.6830e-04 - val_mae: 0.0251\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9918e-04 - mae: 0.0304 - val_loss: 6.6498e-04 - val_mae: 0.0252\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0310 - val_loss: 6.6582e-04 - val_mae: 0.0253\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.3625e-04 - mae: 0.0290 - val_loss: 6.8755e-04 - val_mae: 0.0259\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.6153e-04 - mae: 0.0291 - val_loss: 8.2098e-04 - val_mae: 0.0297\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0318 - val_loss: 0.0018 - val_mae: 0.0520\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0313 - val_loss: 6.3318e-04 - val_mae: 0.0244\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0312 - val_loss: 0.0013 - val_mae: 0.0434\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0334 - val_loss: 8.0618e-04 - val_mae: 0.0291\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0304 - val_loss: 6.8238e-04 - val_mae: 0.0261\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0313 - val_loss: 6.8388e-04 - val_mae: 0.0258\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.7468e-04 - mae: 0.0297 - val_loss: 0.0014 - val_mae: 0.0438\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0011 - mae: 0.0333 - val_loss: 7.5792e-04 - val_mae: 0.0279\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4060e-04 - mae: 0.0293 - val_loss: 7.3754e-04 - val_mae: 0.0273\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3153e-04 - mae: 0.0285 - val_loss: 6.2987e-04 - val_mae: 0.0245\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4246e-04 - mae: 0.0289 - val_loss: 6.9316e-04 - val_mae: 0.0265\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1271e-04 - mae: 0.0279 - val_loss: 7.8716e-04 - val_mae: 0.0285\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2259e-04 - mae: 0.0283 - val_loss: 7.1582e-04 - val_mae: 0.0265\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2156e-04 - mae: 0.0282 - val_loss: 6.3818e-04 - val_mae: 0.0245\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4264e-04 - mae: 0.0283 - val_loss: 6.9076e-04 - val_mae: 0.0262\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1848e-04 - mae: 0.0282 - val_loss: 7.4057e-04 - val_mae: 0.0272\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.2566e-04 - mae: 0.0284 - val_loss: 6.6376e-04 - val_mae: 0.0250\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.3967e-04 - mae: 0.0294 - val_loss: 6.9455e-04 - val_mae: 0.0256\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1002e-04 - mae: 0.0281 - val_loss: 6.6678e-04 - val_mae: 0.0252\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1461e-04 - mae: 0.0279 - val_loss: 7.7536e-04 - val_mae: 0.0289\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0307 - val_loss: 8.1823e-04 - val_mae: 0.0303\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4758e-04 - mae: 0.0292 - val_loss: 7.9132e-04 - val_mae: 0.0294\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4985e-04 - mae: 0.0288 - val_loss: 6.5708e-04 - val_mae: 0.0254\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2491e-04 - mae: 0.0290 - val_loss: 6.2898e-04 - val_mae: 0.0241\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1894e-04 - mae: 0.0282 - val_loss: 6.2383e-04 - val_mae: 0.0241\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4504e-04 - mae: 0.0295 - val_loss: 6.3438e-04 - val_mae: 0.0243\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0310 - val_loss: 6.8969e-04 - val_mae: 0.0256\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.9003e-04 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0454\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0312 - val_loss: 6.7413e-04 - val_mae: 0.0255\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1579e-04 - mae: 0.0281 - val_loss: 8.3798e-04 - val_mae: 0.0308\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2812e-04 - mae: 0.0287 - val_loss: 8.9408e-04 - val_mae: 0.0323\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1375e-04 - mae: 0.0282 - val_loss: 6.1286e-04 - val_mae: 0.0238\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.2324e-04 - mae: 0.0281 - val_loss: 6.9583e-04 - val_mae: 0.0261\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1072e-04 - mae: 0.0285 - val_loss: 6.9114e-04 - val_mae: 0.0260\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.0295e-04 - mae: 0.0276 - val_loss: 7.3453e-04 - val_mae: 0.0271\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1040e-04 - mae: 0.0288 - val_loss: 6.7458e-04 - val_mae: 0.0260\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1998e-04 - mae: 0.0285 - val_loss: 6.4829e-04 - val_mae: 0.0249\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.8929e-04 - mae: 0.0274 - val_loss: 7.3747e-04 - val_mae: 0.0270\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.0730e-04 - mae: 0.0281 - val_loss: 6.7518e-04 - val_mae: 0.0257\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.0946e-04 - mae: 0.0280 - val_loss: 7.4245e-04 - val_mae: 0.0275\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4591e-04 - mae: 0.0300 - val_loss: 6.8636e-04 - val_mae: 0.0260\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.5714e-04 - mae: 0.0293 - val_loss: 6.8762e-04 - val_mae: 0.0265\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.2553e-04 - mae: 0.0286 - val_loss: 6.8123e-04 - val_mae: 0.0255\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.1585e-04 - mae: 0.0282 - val_loss: 8.2584e-04 - val_mae: 0.0300\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8870e-04 - mae: 0.0278 - val_loss: 8.0066e-04 - val_mae: 0.0293\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.5752e-04 - mae: 0.0295 - val_loss: 6.7778e-04 - val_mae: 0.0258\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.6449e-04 - mae: 0.0298 - val_loss: 6.7145e-04 - val_mae: 0.0253\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.5973e-04 - mae: 0.0290 - val_loss: 9.3410e-04 - val_mae: 0.0326\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.8121e-04 - mae: 0.0298 - val_loss: 6.7317e-04 - val_mae: 0.0259\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3344e-04 - mae: 0.0287 - val_loss: 6.5849e-04 - val_mae: 0.0251\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8232e-04 - mae: 0.0275 - val_loss: 7.5517e-04 - val_mae: 0.0281\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.9520e-04 - mae: 0.0280 - val_loss: 6.5424e-04 - val_mae: 0.0250\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.4007e-04 - mae: 0.0286 - val_loss: 6.3654e-04 - val_mae: 0.0247\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3649e-04 - mae: 0.0292 - val_loss: 6.8533e-04 - val_mae: 0.0259\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.0337e-04 - mae: 0.0283 - val_loss: 7.2622e-04 - val_mae: 0.0276\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.0238e-04 - mae: 0.0279 - val_loss: 8.5368e-04 - val_mae: 0.0301\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2293e-04 - mae: 0.0288 - val_loss: 6.9031e-04 - val_mae: 0.0256\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2875e-04 - mae: 0.0290 - val_loss: 6.7122e-04 - val_mae: 0.0254\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.2926e-04 - mae: 0.0286 - val_loss: 7.4403e-04 - val_mae: 0.0275\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.8547e-04 - mae: 0.0274 - val_loss: 6.3836e-04 - val_mae: 0.0247\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.8442e-04 - mae: 0.0282 - val_loss: 7.7658e-04 - val_mae: 0.0287\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1614e-04 - mae: 0.0281 - val_loss: 6.4060e-04 - val_mae: 0.0247\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.3677e-04 - mae: 0.0286 - val_loss: 7.0353e-04 - val_mae: 0.0262\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8452e-04 - mae: 0.0275 - val_loss: 7.0087e-04 - val_mae: 0.0266\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.9880e-04 - mae: 0.0308 - val_loss: 8.8836e-04 - val_mae: 0.0321\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9794e-04 - mae: 0.0280 - val_loss: 6.3690e-04 - val_mae: 0.0246\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.5446e-04 - mae: 0.0294 - val_loss: 9.8018e-04 - val_mae: 0.0347\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4432e-04 - mae: 0.0296 - val_loss: 7.2895e-04 - val_mae: 0.0266\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9615e-04 - mae: 0.0279 - val_loss: 9.3236e-04 - val_mae: 0.0333\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9418e-04 - mae: 0.0280 - val_loss: 6.7766e-04 - val_mae: 0.0254\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8778e-04 - mae: 0.0275 - val_loss: 6.4700e-04 - val_mae: 0.0247\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7804e-04 - mae: 0.0277 - val_loss: 7.7748e-04 - val_mae: 0.0288\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 9.7236e-04 - mae: 0.0299 - val_loss: 6.4983e-04 - val_mae: 0.0243\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 8.8442e-04 - mae: 0.0278 - val_loss: 6.5401e-04 - val_mae: 0.0251\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.4105e-04 - mae: 0.0293 - val_loss: 8.5383e-04 - val_mae: 0.0314\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0010 - mae: 0.0316 - val_loss: 6.4491e-04 - val_mae: 0.0257\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.8277e-04 - mae: 0.0275 - val_loss: 9.3344e-04 - val_mae: 0.0335\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0328 - val_loss: 6.5390e-04 - val_mae: 0.0253\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1641e-04 - mae: 0.0285 - val_loss: 7.0140e-04 - val_mae: 0.0271\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.9660e-04 - mae: 0.0279 - val_loss: 6.6401e-04 - val_mae: 0.0253\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 8.7770e-04 - mae: 0.0275 - val_loss: 7.2740e-04 - val_mae: 0.0275\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 9.1091e-04 - mae: 0.0283 - val_loss: 6.3077e-04 - val_mae: 0.0242\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.1286e-04 - mae: 0.0238\n",
      "验证集的误差: 23753.607645630836\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "它与univar_model RNN的唯一区别是输入形状不同：在每个时间步，该模型接收5个输入而不是1个。该模型实际的验证MAE达到了23000左右。 取得了很大的进步！\n",
    "\n",
    "让RNN同时预测公共汽车和铁路客运量并不难，只需要在创建数据集时更改目标，针对训练集将它们设置为mulvar_train[[\"bus\"，\"rail\"]][seq_length：]，针对验证集设置为mulvar_valid[[\"bus\"，\"rail\"]][seq_length：]。还必须在输出Dense层中添加一个额外的神经元，因为它现在必须进行两项预测：一项针对明天的公共汽车客运量，另一项针对铁路客运量\n",
    "\n",
    "对多个相关任务使用单个模型可能会比对每个任务使用单独的模型产生更好的性能，不仅因为针对一个任务学习的特征可能对其他任务也有用，而且还因为必须跨多个任务表现良好可以防止模型过拟合"
   ],
   "id": "6bac5624f7813e23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:17:36.292229Z",
     "start_time": "2025-10-10T09:17:18.857318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "seq_length = 56\n",
    "train_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),\n",
    "    targets=mulvar_train[[\"bus\", \"rail\"]][seq_length:],  # 2个目标\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=mulvar_valid[[\"bus\", \"rail\"]][seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "multask_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "fit_and_evaluate(multask_model, 0.02, train_multask_ds, valid_multask_ds)"
   ],
   "id": "76370e20c497bdbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 2s 24ms/step - loss: 0.0379 - mae: 0.1828 - val_loss: 0.0039 - val_mae: 0.0712\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0569 - val_loss: 0.0018 - val_mae: 0.0486\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0023 - mae: 0.0467 - val_loss: 9.6673e-04 - val_mae: 0.0322\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0450 - val_loss: 0.0019 - val_mae: 0.0514\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0442 - val_loss: 7.7440e-04 - val_mae: 0.0286\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0018 - mae: 0.0416 - val_loss: 0.0010 - val_mae: 0.0336\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0017 - mae: 0.0409 - val_loss: 7.7338e-04 - val_mae: 0.0285\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0016 - mae: 0.0399 - val_loss: 9.8471e-04 - val_mae: 0.0336\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0016 - mae: 0.0393 - val_loss: 9.7319e-04 - val_mae: 0.0334\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0391 - val_loss: 7.5522e-04 - val_mae: 0.0282\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0395 - val_loss: 7.3803e-04 - val_mae: 0.0281\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0394 - val_loss: 8.3742e-04 - val_mae: 0.0303\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0015 - mae: 0.0388 - val_loss: 6.4330e-04 - val_mae: 0.0260\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0014 - mae: 0.0377 - val_loss: 9.7969e-04 - val_mae: 0.0338\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0376 - val_loss: 7.3805e-04 - val_mae: 0.0283\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0014 - mae: 0.0371 - val_loss: 6.9304e-04 - val_mae: 0.0278\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0380 - val_loss: 0.0012 - val_mae: 0.0395\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0385 - val_loss: 8.9844e-04 - val_mae: 0.0318\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 6.5838e-04 - val_mae: 0.0265\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0366 - val_loss: 6.7834e-04 - val_mae: 0.0278\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 8.5999e-04 - val_mae: 0.0312\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0365 - val_loss: 0.0012 - val_mae: 0.0382\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0369 - val_loss: 7.2361e-04 - val_mae: 0.0285\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 7.1365e-04 - val_mae: 0.0279\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 8.2428e-04 - val_mae: 0.0304\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0373 - val_loss: 9.1001e-04 - val_mae: 0.0327\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 6.7468e-04 - val_mae: 0.0276\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 6.6629e-04 - val_mae: 0.0273\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0368 - val_loss: 7.2150e-04 - val_mae: 0.0281\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 7.1955e-04 - val_mae: 0.0286\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 8.5423e-04 - val_mae: 0.0311\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0363 - val_loss: 6.5923e-04 - val_mae: 0.0272\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 8.1309e-04 - val_mae: 0.0301\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0356 - val_loss: 8.2833e-04 - val_mae: 0.0305\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0356 - val_loss: 8.1630e-04 - val_mae: 0.0304\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0364 - val_loss: 6.7901e-04 - val_mae: 0.0274\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 7.2885e-04 - val_mae: 0.0283\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0359 - val_loss: 6.9953e-04 - val_mae: 0.0275\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 7.6654e-04 - val_mae: 0.0291\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 8.8843e-04 - val_mae: 0.0321\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0357 - val_loss: 0.0011 - val_mae: 0.0382\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0013 - mae: 0.0367 - val_loss: 9.6301e-04 - val_mae: 0.0337\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 8.3191e-04 - val_mae: 0.0308\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 7.3051e-04 - val_mae: 0.0286\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0354 - val_loss: 6.7505e-04 - val_mae: 0.0270\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 7.0546e-04 - val_mae: 0.0277\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0362 - val_loss: 7.7901e-04 - val_mae: 0.0295\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0352 - val_loss: 7.0200e-04 - val_mae: 0.0275\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0348 - val_loss: 7.8556e-04 - val_mae: 0.0296\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 0.0010 - val_mae: 0.0351\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0351 - val_loss: 6.9379e-04 - val_mae: 0.0281\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0346 - val_loss: 7.9951e-04 - val_mae: 0.0300\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0347 - val_loss: 6.8249e-04 - val_mae: 0.0275\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 9.0751e-04 - val_mae: 0.0327\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0343 - val_loss: 8.2562e-04 - val_mae: 0.0305\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0349 - val_loss: 7.7529e-04 - val_mae: 0.0296\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0345 - val_loss: 7.2722e-04 - val_mae: 0.0283\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0353 - val_loss: 8.0439e-04 - val_mae: 0.0303\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 7.6099e-04 - val_mae: 0.0292\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0343 - val_loss: 7.3110e-04 - val_mae: 0.0287\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0342 - val_loss: 7.6335e-04 - val_mae: 0.0290\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0340 - val_loss: 7.4776e-04 - val_mae: 0.0289\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0012 - mae: 0.0344 - val_loss: 7.8206e-04 - val_mae: 0.0297\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 6.4330e-04 - mae: 0.0260\n",
      "验证集的误差: 26037.04109787941\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:20:59.871653Z",
     "start_time": "2025-10-10T09:20:59.490401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 评估多任务RNN的预测\n",
    "Y_preds_valid = multask_model.predict(valid_multask_ds)\n",
    "Y_preds_valid\n",
    "for idx, name in enumerate([\"bus\", \"rail\"]):\n",
    "    mae = 1e6 * tf.keras.metrics.MeanAbsoluteError()(\n",
    "        mulvar_valid[name][seq_length:], Y_preds_valid[:, idx])\n",
    "    print(name, int(mae))"
   ],
   "id": "678170cb1745cc2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "bus 25608\n",
      "rail 26465\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 预测未来多个时间步",
   "id": "c692db3f975339c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "到目前为止，只预测了下一个时间步的值，但通过适当地改变目标我们可以预测未来多个时间步的值（例如，要预测未来2周的客运量，只需将目标更改为未来14天的值而不是1天后的值）\n",
    "\n",
    "训练RNN一次性预测未来的14个值。仍然可以使用序列到向量的模型，但它会输出14个值而不是1个值。但是，首先需要将目标更改为包含接下来的14个值的向量。为此，可以再次使用timeseries_dataset_from_array()，但这次要求它创建没有目标(targets=None)且更长的序列的数据集，长度为seq_length+14。然后，可以使用数据集的map()方法将自定义函数应用于每批序列，将它们拆分为输入和目标值。在这个例子中，使用多元时间序列作为输入（使用所有5列），预测未来14天的铁路客运量"
   ],
   "id": "3c94f232a0597c38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:29:37.050568Z",
     "start_time": "2025-10-10T09:29:36.914401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_inputs_and_targets(mulvar_series, ahead=14, target_col=1):\n",
    "    # (32, 70, 5)\n",
    "    return mulvar_series[:, :-ahead], mulvar_series[:, -ahead:, target_col]\n",
    "\n",
    "\n",
    "ahead_train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length+14,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ").map(split_inputs_and_targets)\n",
    "\n",
    "ahead_valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length+14,\n",
    "    batch_size=32).map(split_inputs_and_targets)"
   ],
   "id": "8aad9aabbfcaea9",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:30:41.984887Z",
     "start_time": "2025-10-10T09:30:41.911546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出用14个单元\n",
    "ahead_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ],
   "id": "ee96620ddc353597",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T09:31:50.328358Z",
     "start_time": "2025-10-10T09:30:42.253026Z"
    }
   },
   "cell_type": "code",
   "source": "fit_and_evaluate(ahead_model, 0.02, ahead_train_ds, ahead_valid_ds)",
   "id": "9093cbe192934815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 0.0964 - mae: 0.3233 - val_loss: 0.0238 - val_mae: 0.1617\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.1504 - val_loss: 0.0137 - val_mae: 0.1234\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.1314 - val_loss: 0.0112 - val_mae: 0.1123\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.1213 - val_loss: 0.0092 - val_mae: 0.1041\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.1141 - val_loss: 0.0085 - val_mae: 0.0963\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.1076 - val_loss: 0.0074 - val_mae: 0.0916\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.1022 - val_loss: 0.0068 - val_mae: 0.0876\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0983 - val_loss: 0.0063 - val_mae: 0.0845\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0947 - val_loss: 0.0059 - val_mae: 0.0816\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0912 - val_loss: 0.0055 - val_mae: 0.0784\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0881 - val_loss: 0.0052 - val_mae: 0.0756\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0858 - val_loss: 0.0048 - val_mae: 0.0735\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0846 - val_loss: 0.0049 - val_mae: 0.0735\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0817 - val_loss: 0.0044 - val_mae: 0.0696\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0803 - val_loss: 0.0041 - val_mae: 0.0670\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0786 - val_loss: 0.0040 - val_mae: 0.0663\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0771 - val_loss: 0.0040 - val_mae: 0.0660\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0754 - val_loss: 0.0037 - val_mae: 0.0634\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0744 - val_loss: 0.0035 - val_mae: 0.0619\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0732 - val_loss: 0.0036 - val_mae: 0.0625\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0723 - val_loss: 0.0033 - val_mae: 0.0595\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0713 - val_loss: 0.0032 - val_mae: 0.0590\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0703 - val_loss: 0.0033 - val_mae: 0.0598\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0698 - val_loss: 0.0033 - val_mae: 0.0605\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0690 - val_loss: 0.0030 - val_mae: 0.0565\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0682 - val_loss: 0.0029 - val_mae: 0.0560\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0673 - val_loss: 0.0030 - val_mae: 0.0577\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0666 - val_loss: 0.0027 - val_mae: 0.0541\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0659 - val_loss: 0.0028 - val_mae: 0.0547\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0655 - val_loss: 0.0025 - val_mae: 0.0516\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0653 - val_loss: 0.0026 - val_mae: 0.0532\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0642 - val_loss: 0.0026 - val_mae: 0.0530\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0639 - val_loss: 0.0025 - val_mae: 0.0517\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0636 - val_loss: 0.0025 - val_mae: 0.0518\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0631 - val_loss: 0.0026 - val_mae: 0.0531\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0630 - val_loss: 0.0024 - val_mae: 0.0511\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0623 - val_loss: 0.0022 - val_mae: 0.0490\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0623 - val_loss: 0.0025 - val_mae: 0.0528\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0619 - val_loss: 0.0023 - val_mae: 0.0506\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0614 - val_loss: 0.0024 - val_mae: 0.0514\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0609 - val_loss: 0.0023 - val_mae: 0.0499\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0608 - val_loss: 0.0023 - val_mae: 0.0506\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0604 - val_loss: 0.0021 - val_mae: 0.0475\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0608 - val_loss: 0.0024 - val_mae: 0.0519\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0601 - val_loss: 0.0023 - val_mae: 0.0506\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0598 - val_loss: 0.0023 - val_mae: 0.0504\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0596 - val_loss: 0.0023 - val_mae: 0.0497\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0593 - val_loss: 0.0021 - val_mae: 0.0480\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0591 - val_loss: 0.0021 - val_mae: 0.0472\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0588 - val_loss: 0.0020 - val_mae: 0.0469\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0587 - val_loss: 0.0020 - val_mae: 0.0467\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0587 - val_loss: 0.0021 - val_mae: 0.0478\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0581 - val_loss: 0.0020 - val_mae: 0.0457\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0591 - val_loss: 0.0022 - val_mae: 0.0485\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0581 - val_loss: 0.0021 - val_mae: 0.0479\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0578 - val_loss: 0.0020 - val_mae: 0.0465\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0040 - mae: 0.0578 - val_loss: 0.0021 - val_mae: 0.0482\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0577 - val_loss: 0.0021 - val_mae: 0.0481\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0573 - val_loss: 0.0020 - val_mae: 0.0459\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0573 - val_loss: 0.0019 - val_mae: 0.0446\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0568 - val_loss: 0.0019 - val_mae: 0.0450\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0571 - val_loss: 0.0021 - val_mae: 0.0471\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0565 - val_loss: 0.0019 - val_mae: 0.0450\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0565 - val_loss: 0.0021 - val_mae: 0.0473\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0039 - mae: 0.0565 - val_loss: 0.0021 - val_mae: 0.0471\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0562 - val_loss: 0.0018 - val_mae: 0.0428\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0572 - val_loss: 0.0022 - val_mae: 0.0493\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0561 - val_loss: 0.0021 - val_mae: 0.0471\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0561 - val_loss: 0.0020 - val_mae: 0.0456\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0555 - val_loss: 0.0019 - val_mae: 0.0441\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0559 - val_loss: 0.0022 - val_mae: 0.0489\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0556 - val_loss: 0.0019 - val_mae: 0.0447\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0553 - val_loss: 0.0018 - val_mae: 0.0442\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0552 - val_loss: 0.0020 - val_mae: 0.0460\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0551 - val_loss: 0.0020 - val_mae: 0.0459\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0548 - val_loss: 0.0020 - val_mae: 0.0465\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0549 - val_loss: 0.0019 - val_mae: 0.0451\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0547 - val_loss: 0.0020 - val_mae: 0.0466\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0545 - val_loss: 0.0019 - val_mae: 0.0442\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0545 - val_loss: 0.0020 - val_mae: 0.0469\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0542 - val_loss: 0.0017 - val_mae: 0.0412\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0550 - val_loss: 0.0020 - val_mae: 0.0457\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0542 - val_loss: 0.0019 - val_mae: 0.0447\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0541 - val_loss: 0.0020 - val_mae: 0.0468\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0537 - val_loss: 0.0018 - val_mae: 0.0436\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0539 - val_loss: 0.0017 - val_mae: 0.0410\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0542 - val_loss: 0.0020 - val_mae: 0.0458\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0535 - val_loss: 0.0018 - val_mae: 0.0428\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0017 - val_mae: 0.0420\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0531 - val_loss: 0.0017 - val_mae: 0.0412\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0534 - val_loss: 0.0018 - val_mae: 0.0431\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0529 - val_loss: 0.0019 - val_mae: 0.0447\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0526 - val_loss: 0.0016 - val_mae: 0.0403\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0530 - val_loss: 0.0017 - val_mae: 0.0419\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0530 - val_loss: 0.0017 - val_mae: 0.0421\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0523 - val_loss: 0.0017 - val_mae: 0.0421\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0526 - val_loss: 0.0019 - val_mae: 0.0439\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0526 - val_loss: 0.0017 - val_mae: 0.0422\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0019 - val_mae: 0.0441\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0522 - val_loss: 0.0016 - val_mae: 0.0397\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0524 - val_loss: 0.0017 - val_mae: 0.0417\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0520 - val_loss: 0.0019 - val_mae: 0.0448\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0035 - mae: 0.0524 - val_loss: 0.0016 - val_mae: 0.0397\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0017 - val_mae: 0.0420\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0516 - val_loss: 0.0017 - val_mae: 0.0413\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0512 - val_loss: 0.0016 - val_mae: 0.0393\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0516 - val_loss: 0.0018 - val_mae: 0.0432\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0519 - val_loss: 0.0017 - val_mae: 0.0411\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0420\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0016 - val_mae: 0.0406\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0515 - val_loss: 0.0015 - val_mae: 0.0386\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0514 - val_loss: 0.0016 - val_mae: 0.0407\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0507 - val_loss: 0.0017 - val_mae: 0.0420\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0016 - val_mae: 0.0396\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0016 - val_mae: 0.0395\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0015 - val_mae: 0.0381\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0516 - val_loss: 0.0015 - val_mae: 0.0389\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0508 - val_loss: 0.0015 - val_mae: 0.0389\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0015 - val_mae: 0.0388\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0500 - val_loss: 0.0015 - val_mae: 0.0389\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0017 - val_mae: 0.0419\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0500 - val_loss: 0.0016 - val_mae: 0.0390\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0501 - val_loss: 0.0015 - val_mae: 0.0384\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0016 - val_mae: 0.0404\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0016 - val_mae: 0.0391\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0500 - val_loss: 0.0015 - val_mae: 0.0373\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0014 - val_mae: 0.0375\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0500 - val_loss: 0.0018 - val_mae: 0.0429\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0015 - val_mae: 0.0380\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0502 - val_loss: 0.0015 - val_mae: 0.0384\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0015 - val_mae: 0.0384\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0494 - val_loss: 0.0016 - val_mae: 0.0392\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0016 - val_mae: 0.0395\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0017 - val_mae: 0.0406\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0014 - val_mae: 0.0378\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0487 - val_loss: 0.0015 - val_mae: 0.0379\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0016 - val_mae: 0.0390\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0015 - val_mae: 0.0378\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0015 - val_mae: 0.0377\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0015 - val_mae: 0.0384\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0499 - val_loss: 0.0015 - val_mae: 0.0380\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0032 - mae: 0.0487 - val_loss: 0.0014 - val_mae: 0.0369\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0014 - val_mae: 0.0370\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0016 - val_mae: 0.0387\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0014 - val_mae: 0.0373\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0014 - val_mae: 0.0375\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0491 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0014 - val_mae: 0.0370\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0015 - val_mae: 0.0376\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0015 - val_mae: 0.0374\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0014 - val_mae: 0.0366\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0014 - val_mae: 0.0369\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0015 - val_mae: 0.0378\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0014 - val_mae: 0.0371\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0014 - val_mae: 0.0375\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0015 - val_mae: 0.0377\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0015 - val_mae: 0.0377\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0369\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0014 - val_mae: 0.0358\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0014 - val_mae: 0.0366\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0014 - val_mae: 0.0358\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0365\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0015 - val_mae: 0.0362\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0016 - val_mae: 0.0401\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0506 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0015 - val_mae: 0.0370\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0480 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0367\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0364\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0014 - val_mae: 0.0358\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0482 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0361\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0352\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0016 - val_mae: 0.0378\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0493 - val_loss: 0.0015 - val_mae: 0.0373\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0014 - val_mae: 0.0369\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0483 - val_loss: 0.0013 - val_mae: 0.0351\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0361\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0013 - val_mae: 0.0351\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0354\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0015 - val_mae: 0.0380\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0484 - val_loss: 0.0014 - val_mae: 0.0371\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0348\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0374\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0353\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0017 - val_mae: 0.0403\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0019 - val_mae: 0.0443\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0494 - val_loss: 0.0013 - val_mae: 0.0351\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0013 - val_mae: 0.0351\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0353\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0478 - val_loss: 0.0013 - val_mae: 0.0355\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0353\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 9ms/step - loss: 0.0030 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0360\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0013 - val_mae: 0.0351\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0013 - val_mae: 0.0348\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0016 - val_mae: 0.0385\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0347\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0013 - val_mae: 0.0355\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0451 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0455 - val_loss: 0.0013 - val_mae: 0.0349\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0348\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0352\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0015 - val_mae: 0.0379\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0013 - val_mae: 0.0342\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0351\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0453 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0013 - val_mae: 0.0353\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0013 - val_mae: 0.0352\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0447 - val_loss: 0.0019 - val_mae: 0.0450\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0488 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0349\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0014 - val_mae: 0.0350\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0014 - val_mae: 0.0361\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0451 - val_loss: 0.0014 - val_mae: 0.0364\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0357\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0355\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0348\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0013 - val_mae: 0.0347\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0472 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0451 - val_loss: 0.0013 - val_mae: 0.0344\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0013 - val_mae: 0.0347\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0447 - val_loss: 0.0013 - val_mae: 0.0349\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0347\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0449 - val_loss: 0.0014 - val_mae: 0.0365\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0015 - val_mae: 0.0388\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0451 - val_loss: 0.0014 - val_mae: 0.0356\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0350\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0013 - val_mae: 0.0349\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0345\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0448 - val_loss: 0.0014 - val_mae: 0.0371\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0017 - val_mae: 0.0407\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0013 - val_mae: 0.0353\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0016 - val_mae: 0.0403\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0014 - val_mae: 0.0362\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0352\n",
      "Epoch 272/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0452 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 273/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0014 - val_mae: 0.0361\n",
      "Epoch 274/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0451 - val_loss: 0.0015 - val_mae: 0.0378\n",
      "Epoch 275/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0455 - val_loss: 0.0013 - val_mae: 0.0344\n",
      "Epoch 276/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0451 - val_loss: 0.0014 - val_mae: 0.0349\n",
      "Epoch 277/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0013 - val_mae: 0.0345\n",
      "Epoch 278/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0018 - val_mae: 0.0413\n",
      "Epoch 279/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "Epoch 280/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0349\n",
      "Epoch 281/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0029 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0347\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0342\n",
      "验证集的误差: 34221.287816762924\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T05:20:53.541279Z",
     "start_time": "2025-10-08T05:20:53.410813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练好后 一次预测接下来的14个值\n",
    "import numpy as np\n",
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]  # shape [1, 56, 5]\n",
    "Y_pred = ahead_model.predict(X)  # shape [1, 14]"
   ],
   "id": "385e5f4a89959bbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用序列到序列模型进行预测",
   "id": "9bdc320e6ded34a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "与其训练模型仅在最后一个时间步预测接下来的14个值，不如训练它在每个时间步预测接下来的14个值。换句话说，可以将这个序列到向量的循环神经网络转变为序列到序列的循环神经网络。这种技术的优点是损失将包含RNN在每个时间步的输出的损失项，而不仅仅包含最后一个时间步的输出的损失项。\n",
    "\n",
    "这意味着将有更多的误差梯度流过模型，并且它们不必在时间中流动那么多，因为它们来自每个时间步的输出，而不仅仅是来自最后一个时间步。这既能稳定训练，又能加速训练。\n",
    "\n",
    "需要明确的是，在时间步0，模型将输出一个向量，其中包含时间步1到14的预测值。在时间步1，模型将预测时间步2到15的值，以此类推。换句话说，目标是连续窗口的序列，在每个时间步移动一个时间步。目标不再是向量，而是与输入长度相同的序列，每一步都包含一个14维向量。\n",
    "\n",
    "准备数据集并不简单，因为每个实例都有一个作为输入的窗口和一个作为输出的窗口序列。一种方法是使用之前创建的to_windows()实用函数，连续两次，获取连续窗口的窗口。例如，将数字0到6的序列转换为包含4个连续窗口的序列的数据集，每个窗口的长度为3："
   ],
   "id": "a0a51680c9ef8c8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:04:39.507770Z",
     "start_time": "2025-10-08T07:04:39.464238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_series = tf.data.Dataset.range(7)\n",
    "dataset = to_windows(to_windows(my_series, 3), 4)\n",
    "list(dataset)"
   ],
   "id": "cb22cec6d4814c16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
       " array([[0, 1, 2],\n",
       "        [1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5]], dtype=int64)>,\n",
       " <tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5],\n",
       "        [4, 5, 6]], dtype=int64)>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:04:39.667360Z",
     "start_time": "2025-10-08T07:04:39.621172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 可以使用map()方法将这些窗口的窗口拆分为输入和目标\n",
    "dataset = dataset.map(lambda S: (S[:, 0], S[:, 1:]))\n",
    "list(dataset)"
   ],
   "id": "2c3c2ee59dc477be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "  array([[1, 2],\n",
       "         [2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5]], dtype=int64)>),\n",
       " (<tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 2, 3, 4], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "  array([[2, 3],\n",
       "         [3, 4],\n",
       "         [4, 5],\n",
       "         [5, 6]], dtype=int64)>)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在数据集包含长度为4的序列作为输入，目标是包含每个时间步的接下来两个步骤的序列。例如，第一个输入序列是[0，1，2，3]，它对应的目标是[[1，2]，[2，3]，[3，4]，[4，5]]，即每个时间步的下两个值。",
   "id": "9ba16f5b1a87668c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:12:52.188061Z",
     "start_time": "2025-10-08T07:12:52.175544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建辅助函数为序列到序列模型准备数据集。\n",
    "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1, batch_size=32, shuffle=False, seed=None):\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series), ahead+1)\n",
    "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, 0], S[:, 1:, 1]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)\n"
   ],
   "id": "e644d357e4fc9e1c",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:30:04.370643Z",
     "start_time": "2025-10-08T07:30:04.266115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建数据集\n",
    "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
    "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)\n",
    "\n",
    "# 构建序列模型\n",
    "seq2seq_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ],
   "id": "9c4beac583b23dd4",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "它与之前的模型几乎相同：唯一的区别是我们在SimpleRNN层中设置了return_sequences=True。这样，它将输出一个向量（每个大小为32）序列，而不是在最后一个时间步输出单个向量。Dense层足够智能，可以将序列作为输入处理：它将在每个时间步应用，将32维向量作为输入并输出14维向量。事实上，另一种获得完全相同结果的方法是使用核大小为1的Conv1D层：Conv1D(14，kernel_size=1)。",
   "id": "feee2c769d4cc225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:30:05.151654Z",
     "start_time": "2025-10-08T07:30:05.126654Z"
    }
   },
   "cell_type": "code",
   "source": "seq2seq_model.summary()",
   "id": "75b1b8ce2699e14a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_12 (SimpleRNN)   (None, None, 32)          1216      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, None, 14)          462       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1678 (6.55 KB)\n",
      "Trainable params: 1678 (6.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "训练代码和平时一样。在训练过程中，模型的所有输出都会被使用，但训练后只有最后一个时间步的输出很重要，其余的可以忽略。",
   "id": "31dcd14bb70b3058"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:34:15.651794Z",
     "start_time": "2025-10-08T07:33:02.333165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "seq2seq_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "history = seq2seq_model.fit(seq2seq_train, validation_data=seq2seq_valid, epochs=500, callbacks=[early_stopping_cb])"
   ],
   "id": "e34832ff964e4efb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "33/33 [==============================] - 1s 11ms/step - loss: 0.0681 - mae: 0.2645 - val_loss: 0.0142 - val_mae: 0.1272\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.1002 - val_loss: 0.0069 - val_mae: 0.0811\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0785 - val_loss: 0.0057 - val_mae: 0.0707\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0707 - val_loss: 0.0052 - val_mae: 0.0661\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0664 - val_loss: 0.0048 - val_mae: 0.0621\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0645 - val_loss: 0.0048 - val_mae: 0.0632\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0628 - val_loss: 0.0047 - val_mae: 0.0618\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0611 - val_loss: 0.0043 - val_mae: 0.0578\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0607 - val_loss: 0.0043 - val_mae: 0.0574\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0594 - val_loss: 0.0044 - val_mae: 0.0590\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0593 - val_loss: 0.0043 - val_mae: 0.0581\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0584 - val_loss: 0.0044 - val_mae: 0.0588\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0567 - val_loss: 0.0043 - val_mae: 0.0580\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0565 - val_loss: 0.0045 - val_mae: 0.0605\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0563 - val_loss: 0.0041 - val_mae: 0.0553\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0555 - val_loss: 0.0041 - val_mae: 0.0558\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0554 - val_loss: 0.0042 - val_mae: 0.0564\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0547 - val_loss: 0.0043 - val_mae: 0.0580\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0550 - val_loss: 0.0043 - val_mae: 0.0594\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0544 - val_loss: 0.0042 - val_mae: 0.0570\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0538 - val_loss: 0.0042 - val_mae: 0.0574\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0551 - val_loss: 0.0042 - val_mae: 0.0576\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0555 - val_loss: 0.0040 - val_mae: 0.0545\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0544 - val_loss: 0.0039 - val_mae: 0.0521\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0562 - val_loss: 0.0040 - val_mae: 0.0545\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0545 - val_loss: 0.0038 - val_mae: 0.0520\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0542 - val_loss: 0.0038 - val_mae: 0.0513\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0548 - val_loss: 0.0038 - val_mae: 0.0508\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0538 - val_loss: 0.0038 - val_mae: 0.0507\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0529 - val_loss: 0.0037 - val_mae: 0.0503\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0527 - val_loss: 0.0038 - val_mae: 0.0515\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0524 - val_loss: 0.0038 - val_mae: 0.0504\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0522 - val_loss: 0.0038 - val_mae: 0.0506\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0524 - val_loss: 0.0038 - val_mae: 0.0505\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0517 - val_loss: 0.0038 - val_mae: 0.0509\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0037 - val_mae: 0.0501\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0533 - val_loss: 0.0037 - val_mae: 0.0501\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0517 - val_loss: 0.0038 - val_mae: 0.0505\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0520 - val_loss: 0.0038 - val_mae: 0.0506\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0522 - val_loss: 0.0037 - val_mae: 0.0499\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0037 - val_mae: 0.0499\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0523 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0514 - val_loss: 0.0038 - val_mae: 0.0502\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0511 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0515 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0517 - val_loss: 0.0037 - val_mae: 0.0494\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0519 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0513 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0037 - val_mae: 0.0493\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0504 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0504 - val_loss: 0.0038 - val_mae: 0.0499\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0507 - val_loss: 0.0037 - val_mae: 0.0493\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0504 - val_loss: 0.0037 - val_mae: 0.0495\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0037 - val_mae: 0.0495\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0514 - val_loss: 0.0037 - val_mae: 0.0498\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0037 - val_mae: 0.0490\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0504 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0499 - val_loss: 0.0038 - val_mae: 0.0500\n",
      "Epoch 60/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0037 - val_mae: 0.0496\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0037 - val_mae: 0.0490\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0498 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0492\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0496 - val_loss: 0.0038 - val_mae: 0.0499\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0038 - val_mae: 0.0513\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0511 - val_loss: 0.0037 - val_mae: 0.0487\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0037 - val_mae: 0.0487\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0500 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0498 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0500 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0502 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0505 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0508 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0507 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0501 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0486 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0487 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0497 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0498 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0488 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0485 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0485 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0491 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0510 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0493 - val_loss: 0.0037 - val_mae: 0.0492\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0479\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0487 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0488 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0037 - val_mae: 0.0479\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0037 - val_mae: 0.0479\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0037 - val_mae: 0.0478\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0037 - val_mae: 0.0479\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0475\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0490 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0037 - val_mae: 0.0475\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0037 - val_mae: 0.0477\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0037 - val_mae: 0.0482\n",
      "Epoch 117/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0037 - val_mae: 0.0476\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0492 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0037 - val_mae: 0.0476\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0037 - val_mae: 0.0478\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0037 - val_mae: 0.0475\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0478 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0037 - val_mae: 0.0476\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0037 - val_mae: 0.0477\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0037 - val_mae: 0.0477\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0489 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0481 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0037 - val_mae: 0.0475\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0479 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0482 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0483 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0475 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0037 - val_mae: 0.0478\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0037 - val_mae: 0.0476\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0037 - val_mae: 0.0478\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0486 - val_loss: 0.0037 - val_mae: 0.0483\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0037 - val_mae: 0.0481\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0473 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 178/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0477 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0480 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0474 - val_loss: 0.0036 - val_mae: 0.0482\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0469 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0485\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0037 - val_mae: 0.0510\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0483\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 239/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0479\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0037 - val_mae: 0.0490\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0467 - val_loss: 0.0037 - val_mae: 0.0495\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0471 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0037 - val_mae: 0.0490\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0479\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0465 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0484\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0037 - val_mae: 0.0501\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0466 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 272/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 273/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0486\n",
      "Epoch 274/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0464 - val_loss: 0.0036 - val_mae: 0.0479\n",
      "Epoch 275/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 276/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 277/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0482\n",
      "Epoch 278/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 279/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 280/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0482\n",
      "Epoch 281/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 282/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 283/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 284/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 285/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 286/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0036 - val_mae: 0.0482\n",
      "Epoch 287/500\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 288/500\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0487\n",
      "Epoch 289/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0037 - val_mae: 0.0497\n",
      "Epoch 290/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0462 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 291/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 292/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 293/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0037 - val_mae: 0.0506\n",
      "Epoch 294/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 295/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0455 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 296/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0478\n",
      "Epoch 297/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 298/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 299/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 300/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0479\n",
      "Epoch 301/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 302/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 303/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0469\n",
      "Epoch 304/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0037 - val_mae: 0.0491\n",
      "Epoch 305/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 306/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 307/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0473\n",
      "Epoch 308/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 309/500\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0454 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 310/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 311/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0459 - val_loss: 0.0037 - val_mae: 0.0494\n",
      "Epoch 312/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0482\n",
      "Epoch 313/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0455 - val_loss: 0.0036 - val_mae: 0.0477\n",
      "Epoch 314/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0479\n",
      "Epoch 315/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0461 - val_loss: 0.0036 - val_mae: 0.0481\n",
      "Epoch 316/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0457 - val_loss: 0.0036 - val_mae: 0.0472\n",
      "Epoch 317/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0476\n",
      "Epoch 318/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0460 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 319/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0456 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 320/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0455 - val_loss: 0.0036 - val_mae: 0.0475\n",
      "Epoch 321/500\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0458 - val_loss: 0.0036 - val_mae: 0.0478\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:36:13.433600Z",
     "start_time": "2025-10-08T07:36:13.363608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]\n",
    "y_pred_14 = seq2seq_model.predict(X)[0,-1] # 只需要最后一个时间步的输出"
   ],
   "id": "b872912f53e59117",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T07:45:44.130722Z",
     "start_time": "2025-10-08T07:45:44.071207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_pred_valid = seq2seq_model.predict(seq2seq_valid)\n",
    "for ahead in range(14):\n",
    "    preds = pd.Series(Y_pred_valid[:-1, -1, ahead],\n",
    "                      index=mulvar_valid.index[56 + ahead : -14 + ahead]) # 因为最后几个窗口没有完整 14 步预测（靠近结尾的数据不足），所以这里裁掉最后 14 步，保证索引与预测数组 Y_pred_valid[:-1] 长度匹配。\n",
    "    mae = (preds - mulvar_valid[\"rail\"]).abs().mean() * 1e6\n",
    "    print(f\"MAE for +{ahead + 1}: {mae:,.0f}\")\n"
   ],
   "id": "7cf3b25d2c34f9c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "MAE for +1: 23,222\n",
      "MAE for +2: 27,877\n",
      "MAE for +3: 32,001\n",
      "MAE for +4: 31,346\n",
      "MAE for +5: 31,939\n",
      "MAE for +6: 33,802\n",
      "MAE for +7: 33,435\n",
      "MAE for +8: 34,440\n",
      "MAE for +9: 33,686\n",
      "MAE for +10: 32,397\n",
      "MAE for +11: 36,805\n",
      "MAE for +12: 36,716\n",
      "MAE for +13: 34,703\n",
      "MAE for +14: 34,634\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 处理长序列",
   "id": "48fedcd49962c3c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "简单的RNN可以很好地预测时间序列或处理其他类型的序列，但它们在长时间序列上表现不佳。要在长序列上训练RNN，必须在许多时间步上运行它，使展开的RNN成为一个非常深的网络。就像所有深度神经网络一样，它可能会遇到不稳定梯度问题：训练可能需要很长时间，或者训练可能不稳定。此外，当RNN处理一个长序列时，它会逐渐忘记序列中的第一个输入。所以长序列的训练需要解决不稳定梯度和遗忘问题，先看看不稳定梯度问题",
   "id": "91672f9d608e4b13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 解决不稳定的梯度问题",
   "id": "47c4d60a401f7da2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在深度网络中用于缓解不稳定梯度问题的许多技巧也可用于RNN：良好的参数初始化、更快的优化器、dropout等。然而，非饱和激活函数（例如ReLU）在这里可能没有那么大的帮助。事实上，它们实际上可能导致RNN在训练过程中变得更加不稳定。为什么？假设梯度下降以一种在第一个时间步略微增加输出的方式更新权重。因为在每个时间步都使用相同的权重，所以第二个时间步的输出可能略有增加，第三个时间步的输出也可能略有增加，以此类推，直到输出爆炸——非饱和激活函数不会阻止这种情况的发生。\n",
    "\n",
    "我们可以通过较小的学习率来降低这种风险，或者可以使用像双曲正切函数这样的饱和激活函数（这解释了为什么它是默认值）。\n",
    "\n",
    "以几乎相同的方式，梯度本身也可能爆炸。如果你注意到训练不稳定，那么可能需要监控梯度的大小（例如使用TensorBoard）并使用梯度裁剪。\n",
    "\n",
    "此外，批量归一化不能像在深度前馈网络中那样有效地用于RNN。事实上，我们不能在时间步之间使用它，只能在循环层之间使用它。\n",
    "\n",
    "更准确地说，在技术上可以将BN层添加到记忆单元，以便在每个时间步（在该时间步的输入和上一步的隐藏状态上）应用它。然而，无论输入和隐藏状态的实际尺度和偏移量如何，每个时间步都将使用相同的BN层（具有相同的参数）。实际上，这并没有产生好的结果，2015年的论文发现BN仅在应用于层的输入而不是隐藏状态时才略微有益。换句话说，在循环层之间（垂直方向）应用它比没有应用效果稍微好一点，但不应在循环层内（水平方向）应用。在Keras中，可以通过在每个循环层之前添加BatchNormalization层来简单地在层之间应用BN，但这会减慢训练速度，而且可能没有太大帮助。\n",
    "\n",
    "另一种形式的归一化通常更适用于RNN：层归一化。它与批量归一化非常相似，但层归一化不是跨批量维度归一化，而是跨特征维度归一化。它的一个优点是可以在每个时间步独立地为每个实例即时计算所需的统计数据。这也意味着它在训练和测试期间的行为方式相同（与BN不同），并且它不需要像BN那样使用指数移动平均来估计训练集中所有实例的特征统计量。与BN一样，层归一化为每个输入学习一个尺度和一个偏移参数。在RNN中，它通常在输入和隐藏状态的线性组合之后立即使用。"
   ],
   "id": "bc041ca664a81fd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T08:34:27.729481Z",
     "start_time": "2025-10-08T08:34:27.714485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 回顾作业10的一道题，理解 层归一化的代码实现\n",
    "class MyLayerNormalization(tf.keras.layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.alpha = tf.ones(input_shape[-1:])\n",
    "        self.beta = tf.zeros(input_shape[-1:])\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, var = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(var) + 1e-7) + self.beta\n",
    "\n"
   ],
   "id": "807ce2c301f3978b",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T08:34:27.929899Z",
     "start_time": "2025-10-08T08:34:27.904893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_random = tf.random.normal([32, 56, 5])\n",
    "# MyLayerNormalization()(tensor_random)\n",
    "\n",
    "a1 = tf.keras.layers.LayerNormalization(epsilon=1e-7)(tensor_random).numpy()\n",
    "a2 = MyLayerNormalization()(tensor_random).numpy()\n",
    "\n",
    "np.max(np.abs(a1-a2))"
   ],
   "id": "9cbacf75d6d6652e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.556511e-06"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "请注意，states参数是一个包含一个或多个张量的列表。在简单的RNN单元下，它包含一个等于前一个时间步的输出的张量，但其他单元可能有多个状态张量（例如，LSTMCell有一个长期状态和一个短期状态）。单元还必须具有state_size属性和output_size属性。在简单的RNN中，两者都等于单元数。以下代码实现了一个自定义记忆单元，其行为类似于SimpleRNNCell，只不过它还会在每个时间步应用层归一化：",
   "id": "cb1bb05fa5644f20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T08:57:33.558586Z",
     "start_time": "2025-10-08T08:57:33.542975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units, activation=None)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ],
   "id": "cac62f618c91272c",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- LNSimpleRNNCell类继承自tf.keras.layers.Layer类，就像其他自定义层一样。\n",
    "- 构造函数接受单元数和所需的激活函数并设置state_size和output_size属性，然后创建一个没有激活函数的SimpleRNNCell（因为想在线性操作之后、激活函数之前执行层归一化）。\n",
    "- 之后，构造函数创建LayerNormalization层，最后它获取所需的激活函数。\n",
    "- call()方法首先应用SimpleRNNCell，它计算当前输入和先前隐藏状态的线性组合，并返回结果两次（实际上，在SimpleRNNCell中，输出正好等于隐藏状态，换句话说，new_states[0]等于outputs，所以可以忽略call()方法其余部分中的new_states）。接下来，call()方法应用层归一化，然后应用激活函数。\n",
    "- 最后，它返回输出两次：一次作为输出，一次作为新的隐藏状态。要使用这个自定义单元，需要做的就是创建一个tf.keras.layers.RNN层，并向它传递一个单元实例："
   ],
   "id": "a83042ad8ce58866"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T08:57:35.913920Z",
     "start_time": "2025-10-08T08:57:35.789624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "custom_ln_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True,\n",
    "                        input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ],
   "id": "4f25aa54e0b112fe",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T08:58:24.080102Z",
     "start_time": "2025-10-08T08:58:20.597901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "custom_ln_model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "history = custom_ln_model.fit(seq2seq_train, validation_data=seq2seq_valid, epochs=5, callbacks=[early_stopping_cb])"
   ],
   "id": "c45d75ee5dc87099",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0881 - mae: 0.2984 - val_loss: 0.0199 - val_mae: 0.1515\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0153 - mae: 0.1467 - val_loss: 0.0161 - val_mae: 0.1339\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0132 - mae: 0.1361 - val_loss: 0.0149 - val_mae: 0.1268\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0122 - mae: 0.1291 - val_loss: 0.0142 - val_mae: 0.1228\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0113 - mae: 0.1224 - val_loss: 0.0129 - val_mae: 0.1179\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "同样，可以创建一个自定义单元以在每个时间步之间应用dropout。但是，有一个更简单的方法：Keras提供的大多数循环层和单元都有dropout和recurrent_dropout超参数：前者定义应用于输入的dropout率，后者定义时间步之间隐藏状态的dropout率。因此，无须创建自定义单元来在RNN的每个时间步应用dropout。使用这些技术，可以缓解不稳定的梯度问题并有效地训练RNN",
   "id": "634bd381de07bae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 处理短期记忆问题",
   "id": "236429169d70d1ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "由于数据在遍历RNN时会经历转换，因此在每个时间步都会丢失一些信息。一段时间后，RNN的状态几乎不包含第一个输入的踪迹。为了解决这个问题，人们引入了具有长期记忆的各种类型的单元。它们已被证明非常成功，以至于基本单元不再被大量使用。首先看看这些长期记忆单元中最受欢迎的LSTM单元。",
   "id": "ff30af13c1ae26d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### LSTM单元",
   "id": "156e91bc5b3ac111"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "长短期记忆(Long Short-Term Memory，LSTM)单元于1997年首次提出，多年来由研究人员逐步改进。如果将LSTM单元视为黑盒，它可以像基本单元一样使用，但性能要好得多：训练会收敛得更快，并且能够检测数据中的长期模式。在Keras中，可以简单地使用LSTM层而不是SimpleRNN层：",
   "id": "5141e71ba6b83745"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T09:15:23.562976Z",
     "start_time": "2025-10-08T09:15:22.750253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ],
   "id": "d5a5c525d4abb93",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T09:19:34.521446Z",
     "start_time": "2025-10-08T09:19:31.150580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "history = model.fit(seq2seq_train, validation_data=seq2seq_valid, epochs=5, callbacks=[early_stopping_cb])"
   ],
   "id": "f01211eae5bf7c64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 2s 18ms/step - loss: 0.0579 - mae: 0.2612 - val_loss: 0.0189 - val_mae: 0.1695\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0175 - mae: 0.1594 - val_loss: 0.0178 - val_mae: 0.1472\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0159 - mae: 0.1523 - val_loss: 0.0169 - val_mae: 0.1441\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0152 - mae: 0.1485 - val_loss: 0.0163 - val_mae: 0.1403\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0146 - mae: 0.1449 - val_loss: 0.0158 - val_mae: 0.1370\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LSTM单元架构如图所示。如果不看黑盒里面的东西，LSTM单元看起来就像一个普通单元，除了它的状态被分成两个向量：h(t)和c(t)［“c”代表“单元”(cell)］。可以将h(t)视为短期状态，将c(t)视为长期状态。\n",
    "\n",
    "![LSTM单元](./images/RNN/p5.png)"
   ],
   "id": "2fcd9443bcab141a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "关键思想是网络可以学习在长期状态中存储什么，丢弃什么，以及从中读取什么。当长期状态c(t-1)从左到右遍历网络时，它首先通过遗忘门，丢弃一些记忆，然后通过加法运算添加一些新记忆（添加由输入门选择的记忆）。结果c(t)直接被发送出去，没有进行进一步的转换。因此，在每个时间步，都会删除一些记忆并添加一些记忆。而且，在加法运算之后，复制长期状态并使用tanh函数，然后通过输出门对结果进行过滤。这会产生短期状态h(t)（等于此时间步的单元输出）。\n",
    "\n",
    "现在看看新的记忆是从哪里来的，以及这些门是如何工作的。首先，当前输入向量x(t)和先前的短期状态h(t-1)被馈送到4个不同的全连接层。它们都有不同的用途：\n",
    "- 主要的层是输出g(t)的层。它具有分析当前输入x(t)和先前（短期）状态h(t-1)的作用。在基本单元中，除了这一层外别无其他，它的输出直接输出到ŷ(t)和h(t)。但是，在LSTM单元中，该层的输出不会直接输出，相反，它最重要的部分存储在长期状态中（其余部分被丢弃）。\n",
    "- 其他三层是门控制器。由于它们使用逻辑(logistic)激活函数，输出范围为0～1。门控制器的输出被馈送到逐元素乘法运算单元：如果它们输出0，则关闭门；如果输出1，则打开门。具体来说：\n",
    "\n",
    "◆ 遗忘门（由f(t)控制）控制应擦除长期状态的哪些部分。\n",
    "\n",
    "◆ 输入门（由i(t)控制）控制g(t)的哪些部分应添加到长期状态。\n",
    "\n",
    "◆ 输出门（由o(t)控制）控制应在该时间步读取和输出长期状态的哪些部分，包括h(t)和y(t)。"
   ],
   "id": "a2a3fd5d14aa21d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "简而言之，LSTM单元可以学习识别重要输入（这是输入门的作用），将其存储在长期状态中，在需要时保留它（这是遗忘门的作用），并在需要时提取它。这就解释了为什么这些单元在捕捉时间序列、长文本、录音等的长期模式方面取得了惊人的成功。\n",
    "\n",
    "下面公式总结了如何计算单元的长期状态，短期状态以及单个实例在每个时间步的输出。\n",
    "\n",
    "公式：LSTM的计算\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "i_{(t)} &= \\sigma\\left(W_{xi}^{\\top} x_{(t)} + W_{hi}^{\\top} h_{(t-1)} + b_i \\right) \\\\\n",
    "f_{(t)} &= \\sigma\\left(W_{xf}^{\\top} x_{(t)} + W_{hf}^{\\top} h_{(t-1)} + b_f \\right) \\\\\n",
    "o_{(t)} &= \\sigma\\left(W_{xo}^{\\top} x_{(t)} + W_{ho}^{\\top} h_{(t-1)} + b_o \\right) \\\\\n",
    "g_{(t)} &= \\tanh\\left(W_{xg}^{\\top} x_{(t)} + W_{hg}^{\\top} h_{(t-1)} + b_g \\right) \\\\\n",
    "c_{(t)} &= f_{(t)} \\otimes c_{(t-1)} + i_{(t)} \\otimes g_{(t)} \\\\\n",
    "h_{(t)} &= o_{(t)} \\otimes \\tanh\\left(c_{(t)}\\right) \\\\\n",
    "y_{(t)} &= h_{(t)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "在这个等式中：\n",
    "- Wxi、Wxf、Wxo和Wxg是4个层连接到输入向量x(t)的权重矩阵。\n",
    "- Whi、Whf、Who和Whg是4个层的权重矩阵，用于连接到先前的短期状态h(t-1)。\n",
    "- bi、bf、bo和bg是4个层的偏置项。请注意，TensorFlow将bf初始化为一个全1而不是全0的向量。这可以防止在训练开始时忘记一切。\n"
   ],
   "id": "2b27a278a675b299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T09:52:07.410628Z",
     "start_time": "2025-10-08T09:52:07.399366Z"
    }
   },
   "cell_type": "code",
   "source": "# todo: 随堂练习：LSTM的前向传播实现，见其他文件夹",
   "id": "5da8f0449496cba9",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GRU单元",
   "id": "362696008c465e9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "GRU单元是LSTM单元的简化版本，它的表现和LSTM差不多，以下是主要的简化：\n",
    "\n",
    "- 两个状态向量合并为一个向量h(t)。\n",
    "- 单个门控制器z(t)控制遗忘门和输入门。如果门控制器输出1，则遗忘门打开(=1)，输入门关闭(1-1=0)。如果它输出0，则相反。换句话说，每当必须存储记忆时，将首先擦除存储它的位置。这实际上是LSTM单元本身的常见变体。\n",
    "- 没有输出门，在每个时间步输出完整的状态向量。但是，有一个新的门控制器r(t)，它控制先前状态的哪一部分将显示给主要的层(g(t))。\n",
    "\n",
    "![GRU单元](./images/RNN/p6.png)\n",
    "\n",
    "公式：GRU计算\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_{(t)} &= \\sigma\\left(W_{xz}^{\\top} x_{(t)} + W_{hz}^{\\top} h_{(t-1)} + b_z\\right) \\\\\n",
    "r_{(t)} &= \\sigma\\left(W_{xr}^{\\top} x_{(t)} + W_{hr}^{\\top} h_{(t-1)} + b_r\\right) \\\\\n",
    "g_{(t)} &= \\tanh\\left(W_{xg}^{\\top} x_{(t)} + W_{hg}^{\\top} \\left(r_{(t)} \\otimes h_{(t-1)}\\right) + b_g\\right) \\\\\n",
    "h_{(t)} &= z_{(t)} \\otimes h_{(t-1)} + \\left(1 - z_{(t)}\\right) \\otimes g_{(t)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Keras提供了一个tf.keras.layers.GRU层，使用它只是用GRU替换SimpleRNN或LSTM，非常方便；还提供了一个tf.keras.layers.GRUCell, 可以基于它来创建自定义单元"
   ],
   "id": "cba2c469061d45e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4325f62ee7b817b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
