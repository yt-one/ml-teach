机器学习考试试卷（机器学习入门，线性回归，SVM, 决策树，随机森林等）

-------------------------
一、选择题（每题2分，共40分）
1. 以下哪个不是机器学习的典型应用场景？  
   A. 垃圾邮件过滤  
   B. 房价预测  
   C. 浏览器渲染网页  
   D. 图像分类  

2. 在监督学习中，训练数据包含：  
   A. 只有输入特征  
   B. 输入特征和对应的目标标签  
   C. 只有目标标签  
   D. 无任何标注  

3. 以下哪个算法是非参数化模型？  
   A. 线性回归  
   B. 逻辑回归  
   C. 决策树  
   D. Lasso 回归  

4. 决策树在选择划分特征时，常用的指标是：  
   A. 均方误差 (MSE)  
   B. 信息增益/基尼指数  
   C. 学习率  
   D. 正则化系数  

5. 随机森林中每棵树的训练样本是如何获得的？  
   A. 使用完整训练集  
   B. 使用部分特征子集  
   C. 使用自举采样（Bootstrap）  
   D. 使用验证集  

6. 训练集和测试集的主要区别是：  
   A. 训练集用于评估模型性能，测试集用于训练模型  
   B. 训练集用于训练模型，测试集用于评估模型性能  
   C. 训练集和测试集完全相同  
   D. 测试集必须比训练集大  

7. 假阴性 (False Negative, FN) 的含义是：  
   A. 实际为正例，预测也为正例  
   B. 实际为负例，预测也为负例  
   C. 实际为正例，预测为负例  
   D. 实际为负例，预测为正例  

8. 以下哪个性能指标更适合类别极度不平衡的数据集？  
   A. 准确率 (Accuracy)  
   B. 精确率 (Precision) 和召回率 (Recall)  
   C. 均方误差 (MSE)  
   D. AUC分数

9. 在线性可分情况下，支持向量机 (SVM) 的决策边界是：  
   A. 任意一条能分开的直线  
   B. 能最大化间隔的超平面  
   C. 所有点的均值形成的平面  
   D. 最近邻居决定的平面  

10. 在SVM中，参数C的作用是：  
    A. 控制核函数的类型  
    B. 控制正则化强度，对误分类的惩罚程度  
    C. 控制学习率  
    D. 控制树的深度  

11. 在使用核SVM时，核函数的作用是：  
    A. 降低模型复杂度  
    B. 将输入映射到高维空间以实现线性可分  
    C. 减少数据噪声  
    D. 代替交叉验证  

12. 在批量梯度下降 (Batch GD) 中：  
    A. 每次迭代使用一个样本更新梯度  
    B. 每次迭代使用全部训练集更新梯度  
    C. 每次迭代使用一部分训练集更新梯度  
    D. 不需要计算梯度  

13. 随机梯度下降 (SGD) 的主要优点是：  
    A. 总是收敛到全局最优  
    B. 每次迭代计算速度快，可处理大数据集  
    C. 无需超参数  
    D. 不会过拟合  

14. SGD 在训练过程中常用的“学习率调度”的作用是：  
    A. 保证训练集和测试集划分公平  
    B. 逐渐降低学习率以保证收敛  
    C. 增加数据多样性  
    D. 提高模型容量  

15. Bagging 与 Boosting 的区别在于：  
    A. Bagging 使用有放回采样，Boosting 不使用  
    B. Bagging 并行训练弱学习器，Boosting 串行训练弱学习器  
    C. Bagging 只用于回归，Boosting 只用于分类  
    D. Bagging 一定比 Boosting 准确  

16. 在AdaBoost中，每一轮弱分类器的权重是基于：  
    A. 分类器的运行时间  
    B. 分类器的准确率  
    C. 特征的重要性  
    D. 学习率参数  

17. 梯度提升 (Gradient Boosting) 与 AdaBoost 的主要不同点是：  
    A. AdaBoost 每一轮根据分类错误率更新权重，梯度提升是基于梯度下降最小化损失  
    B. AdaBoost 只能处理分类问题，梯度提升只能处理回归问题  
    C. 梯度提升不需要弱学习器  
    D. 两者完全相同  

18. 在梯度提升树中，学习率过小会导致：  
    A. 模型过拟合  
    B. 模型欠拟合，训练时间变长  
    C. 提前停止训练  
    D. 准确率下降且计算更快  

19. 随机森林相比单棵决策树的优势是：  
    A. 更容易过拟合  
    B. 更快预测速度  
    C. 泛化性能更好  
    D. 不需要特征选择  

20. 在随机森林中，节点分裂时随机选择特征子集的主要目的是什么？  
    A. 提高计算速度  
    B. 增加树之间的差异，减少相关性  
    C. 降低树的深度  
    D. 提高每棵树的准确率  

-------------------------
二、填空题（每题2分，共20分）
1. 机器学习的两个主要分支是 ______ 和 ______。  
2. 线性回归的目标是最小化 ______。  
3. 岭回归通过在损失函数中加入 ______ 范数作为正则项来防止过拟合。  
4. Bagging 的全称是 ______。  
5. 在随机森林中，每次分裂节点时，不是使用所有特征，而是随机选择一个 ______。  
6. Lasso回归对不重要的特征的权重起到 _________  效果。
7. 将二分类器扩展到多分类问题，常用的方法有 ______ 和 ______。
8. SVM 回归的目标是让预测值尽量落在 ______ 范围内。
9. 在分类任务中，Precision 衡量的是预测为正类中有多少是真正例，而 Recall（召回率）衡量的是 ______。
10. 一个完整的机器学习项目流程包括：获取数据、探索和清理数据、选择模型、训练模型、调参、评估模型，最后是 ______。

-------------------------
三、判断题（每题2分，共10分）

( ) KNN （K邻近邻居）属于参数化模型。

( ) 在极度不平衡的数据集上，高准确率一定代表模型效果好。

( ) ROC 曲线下面积 (AUC) 越大，模型性能越好。

( ) 决策树越深越好，因为它可以拟合更多训练样本。

( ) 梯度提升中的每棵树都尝试拟合前一棵树的残差。

-------------------------
三、简答题（每题5分，共30分）
1. 描述一下Scikit-Learn绘制的学习曲线（learning_curve(...)), 并说明怎么用这个学习曲线判断模型过拟合/欠拟合

2. 如果你的训练集里特征的数值大小迥异，那么哪些算法可能会受到影响？受影响程度如何？你应该怎么做？

3. 请简述下机器学习库Scikit-Learn里的LinearRegression类的fit方法如何实现的？

4. 为什么决策树容易过拟合，以及可以采取哪些方法来缓解。  

5. 解释下随机森林为什么可以得出每个特征的重要性。 

6. 解释集成学习中“弱学习器”和“强学习器”的区别，并说明为什么弱学习器也能通过集成得到强性能。  

-------------------------
四、综合题（每题10分，共50分）
1. 线性回归实现  
   使用 `scikit-learn` 训练一个线性回归模型，预测房价（假设数据集是 `sklearn.datasets.fetch_california_housing`），并输出均方误差 (MSE)。  

2. 使用Softmax回归，在 iris 数据集上进行多分类，并输出5折交叉验证的的准确率。

3. 结合数学公式，解释下为什么SVM分类最大化间隔，是在使用l2正则化

4. 随机森林与Bagging比较  
   使用 `sklearn.ensemble` 里的 `BaggingClassifier` 和 `RandomForestClassifier` 在同一数据集（如 `iris`）上比较准确率。  

5    用递归方式手写实现完整的决策树划分逻辑（最小化基尼指数或 最大化信息增益）。
 
tree = []  # 用于记录树的节点（打印/检查）
代码体现：1. 计算基尼值 
                   2. 选择最佳阈值划分 
                   3. 递归构建决策树，树的生成靠深度限制就可以

def build_tree_recursive(X, y, node_indices, max_depth, current_depth):
    """
    递归构建树
    参数:
        X (ndarray): 特征矩阵
        y (ndarray): 标签数组
        node_indices (ndarray): 当前节点样本索引
        max_depth (int): 最大深度
        current_depth (int): 当前深度
    """

-------------------------
总分：150分
